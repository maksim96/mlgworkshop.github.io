<!DOCTYPE html>
<html lang="en">

<head>

    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="MLG 2017, 13th International Workshop on Mining and Learning with Graphs, co-located with KDD 2017, Halifax, Nova Scotia, Canada">
    <meta name="author" content="Shobeir Fakhraei">

    <title>13th International Workshop on Mining and Learning with Graphs (MLG 2017)</title>

    <!-- Bootstrap Core CSS -->
    <link href="css/bootstrap.min.css" rel="stylesheet">

    <!-- Custom CSS -->
    <link href="css/agency.css" rel="stylesheet">

    <!-- Custom Fonts -->
    <link href="font-awesome/css/font-awesome.min.css" rel="stylesheet" type="text/css">
    <link href="https://fonts.googleapis.com/css?family=Montserrat:400,700" rel="stylesheet" type="text/css">
    <link href='https://fonts.googleapis.com/css?family=Kaushan+Script' rel='stylesheet' type='text/css'>
    <link href='https://fonts.googleapis.com/css?family=Droid+Serif:400,700,400italic,700italic' rel='stylesheet' type='text/css'>
    <link href='https://fonts.googleapis.com/css?family=Roboto+Slab:400,100,300,700' rel='stylesheet' type='text/css'>

    <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
        <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
    <![endif]-->

    <style type="text/css">
    .tg  {border-collapse:collapse;border-spacing:0; width: 520px}
    .tg td{font-family:Arial, sans-serif;font-size:14px;padding:12px 12px;border-style:solid;border-width:0px;overflow:hidden;word-break:normal;border-top-width:1px;border-bottom-width:1px;}
    .tg th{font-family:Arial, sans-serif;font-size:14px;font-weight:normal;padding:12px 12px;border-style:solid;border-width:0px;overflow:hidden;word-break:normal;border-top-width:1px;border-bottom-width:1px;}
    .tg .tg-lqy6{text-align:right;vertical-align:top; width: 100px}
    .tg .tg-odj0{font-weight:bold;background-color:#ffcb2f;vertical-align:top}
    .tg .tg-yw4l{vertical-align:top}
    .tg .tg-l2oz{font-weight:bold;text-align:right;vertical-align:top}
    .tg .tg-9hbo{font-weight:bold;vertical-align:top}
    .tg .tg-xr8r{background-color:#ffffc7;text-align:right;vertical-align:top; width: 100px}
    .tg .tg-kjho{background-color:#ffffc7;vertical-align:top}
    </style>


</head>

<body id="page-top" class="index">
    <!-- Google Analytics -->
    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-75238067-1', 'auto');
      ga('require', 'linkid');
      ga('send', 'pageview');

    </script>

    <!-- Navigation -->
    <nav class="navbar navbar-default navbar-fixed-top">
        <div class="container">
            <!-- Brand and toggle get grouped for better mobile display -->
            <div class="navbar-header page-scroll">
                <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1">
                    <span class="sr-only">Toggle navigation</span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                </button>
                <a class="navbar-brand page-scroll" href="#page-top"><img src="img/mlg-logo.gif" style="margin:0px; padding:0px; height:30px"/></a>
            </div>

            <!-- Collect the nav links, forms, and other content for toggling -->
            <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
                <ul class="nav navbar-nav navbar-right">
                    <li class="hidden">
                        <a href="#page-top"></a>
                    </li>
                    <li>
                        <a class="page-scroll" href="#introduction">Intro</a>
                    </li>
                    <li>
                        <a class="page-scroll" href="#program">Schedule</a>
                    </li>
                    <li>
                        <a class="page-scroll" href="#keynote">Keynotes</a>
                    </li>
                    <li>
                        <a class="page-scroll" href="#papers">Accepted Papers</a>
                    </li>
                    <li>
                        <a class="page-scroll" href="#call">CFP</a>
                    </li>
                    <li>
                        <a class="page-scroll" href="#dates">Dates</a>
                    </li>
                    <li>
                        <a class="page-scroll" href="#organization">Organization</a>
                    </li>
                    <li>
                        <a class="page-scroll" href="#history">History</a>
                    </li>
                    <li>
                      <a href="https://twitter.com/mlgworkshop" target=_blank><i class="fa fa-twitter" style="font-size:20px;"></i></a>
                    </li>
                </ul>
            </div>
            <!-- /.navbar-collapse -->
        </div>
        <!-- /.container-fluid -->
    </nav>

    <!-- Header -->
    <header>
        <div class="container">
            <div class="intro-text">
                <div class="intro-lead-in">Held in conjunction with <a href="http://www.kdd.org/kdd2017/" target=_blank>KDD'17</a></br>
                Aug 14, 2017 - Halifax, Nova Scotia, Canada</div>
                <div class="intro-heading">13th International Workshop on<br/>Mining and Learning with Graphs</div>
                <a href="http://www.mlgworkshop.org/2018/" target=_blank class="page-scroll btn btn-xl">Join us at MLG 2018</a>
            </div>
        </div>
    </header>

    <!-- Introduction Section -->
    <section id="introduction"> <!--class="bg-mid-gray"-->
        <div class="container">
            <div class="row">
                <div class="col-lg-12 text-center">
                    <h2 class="section-heading">Introduction</h2>
                    <!--h3 class="section-subheading text-muted">Lorem ipsum dolor sit amet consectetur.</h3-->
                </div>
            </div>
            <div class="row text-justify">
                <div class="col-md-12">
                    <p class="large text-muted">
                      There is a great deal of interest in analyzing data that is best represented as a graph. Examples include the WWW, social networks, biological networks, communication networks, transportation networks, energy grids, and many others. These graphs are typically multi-modal, multi-relational and dynamic. In the era of big data, the importance of being able to effectively mine and learn from such data is growing, as more and more structured and semi-structured data is becoming available. The workshop serves as a forum for researchers from a variety of fields working on mining and learning from graphs to share and discuss their latest findings.
                      <br/>
                      There are many challenges involved in effectively mining and learning from this kind of data, including:
                    </p>
                      <ul class="large text-muted">
                          <li>Understanding the different techniques applicable, including graph mining algorithms, graphical models, latent variable models, matrix factorization methods and more.</li>
                          <li>Dealing with the heterogeneity of the data.</li>
                          <li>The common need for information integration and alignment.</li>
                          <li>Handling dynamic and changing data.</li>
                          <li>Addressing each of these issues at scale.</li>
                      </ul>
                    <p class="large text-muted">
                      Traditionally, a number of subareas have contributed to this space: communities in graph mining, learning from structured data, statistical relational learning, inductive logic programming, and, moving beyond subdisciplines in computer science, social network analysis, and, more broadly network science.
                    </p>
                </div>
            </div>
        </div>
    </section>

    <!-- Program Section -->
    <section id="program" class="bg-mid-gray">
        <div class="container">
            <div class="row">
                <div class="col-lg-12 text-center">
                    <h2 class="section-heading">Schedule</h2>
                    <h3 class="section-subheading text-muted"><!--Hilton San Francisco Union Square, Plaza Room A/B - Aug 14, 2016--><br/><br/>
                      <strong><a href="http://videolectures.net/kdd2017_workshops/" target=_balnk>--- Video Recordings ---</a></strong>
                    </h3>

                </div>
            </div>
            <div class="row">
              <div class="col-lg-6 text-left">

                <table class="tg">
                  <tr>
                    <th class="tg-odj0"></th>
                    <th class="tg-odj0">Morning Sessions</th>
                  </tr>
                <tr>
                  <th class="tg-lqy6">8:50 am</th>
                  <th class="tg-yw4l">Opening Remarks</th>
                </tr>
                <tr>
                  <td class="tg-l2oz">9:00 am</td>
                  <td class="tg-9hbo">Keynote: Nitesh Chawla<br/>Representing, Modeling, and Visualizing Higher Order Networks</td>
                </tr>
                <tr>
                  <td class="tg-lqy6">9:40 am</td>
                  <td class="tg-yw4l">Paper Spotlights 1</td>
                </tr>
                <tr>
                  <td class="tg-xr8r">10:00 am</td>
                  <td class="tg-kjho">Coffee Break</td>
                </tr>
                <tr>
                  <td class="tg-lqy6">10:30 am</td>
                  <td class="tg-yw4l">Paper Spotlights 2</td>
                </tr>
                <tr>
                  <td class="tg-l2oz">10:50 am</td>
                  <td class="tg-9hbo">Keynote: Vahab Mirrokni<br/>Distributed Graph Mining: Theory and Practice</td>
                </tr>
                <tr>
                  <td class="tg-lqy6">11:30 am</td>
                  <td class="tg-yw4l">Poster Session</td>
                </tr>
                <tr>
                  <td class="tg-xr8r">12:00 pm</td>
                  <td class="tg-kjho">Lunch<br/>(+ Poster Session)</td>
                </tr>
              </table>

            </div>
            <div class="col-lg-6 text-left">
              <table class="tg">
                <tr>
                  <th class="tg-odj0"></th>
                  <th class="tg-odj0">Afternoon Sessions</th>
                </tr>
                <tr>
                  <td class="tg-l2oz">1:00 pm</td>
                  <td class="tg-9hbo">Keynote: Elena Zheleva<br/>Sharing and Gifting Online</td>
                </tr>
                <tr>
                  <td class="tg-lqy6">1:40 pm</td>
                  <td class="tg-yw4l">
                    Contributed Talks 1:<br/>
                  - HARP: Hierarchical Representation Learning for Networks (Bryan Perozzi)<br/>
                  - Neural Embeddings of Graphs in Hyperbolic Space (Ben Chamberlain)                  
                  </td>
                </tr>
                <tr>
                  <td class="tg-l2oz">2:00 pm</td>
                  <td class="tg-9hbo">Keynote: Yan Liu<br/>Robust Diffusion Network Inference</td>
                </tr>
                <tr>
                  <td class="tg-lqy6">2:40 pm</td>
                  <td class="tg-yw4l">
                    Contributed Talks 2:<br/>
                    - A/B Testing in Networks with Adversarial Members (Kaleigh Clary)<br/>
                    - A task-driven approach to time scale detection in dynamic networks (Benjamin Fish)
                  </td>
                </tr>
                <tr>
                  <td class="tg-xr8r">3:00 pm</td>
                  <td class="tg-kjho">Coffee Break</td>
                </tr>
                <tr>
                  <td class="tg-l2oz">3:30 pm</td>
                  <td class="tg-9hbo">Keynote: Jiliang Tang<br/>Node Relevance in Signed Networks: Measurements and Applications</td>
                </tr>
                <tr>
                  <td class="tg-l2oz">4:10 pm</td>
                  <td class="tg-9hbo">Keynote: Zhenhui Jessie Li<br/>Mining Mobility Flow for Urban Computing</td>
                </tr>
                <tr>
                  <td class="tg-lqy6">4:50 pm</td>
                  <td class="tg-yw4l">Closing Remarks</td>
                </tr>
                </table>

              </div>
              <div class="col-lg-3 text-left">
                &nbsp;
              </div>
          </div>
        </div>
    </section>
  
    <!-- Keynote Section no abstract -->
    <section id="keynote"> <!--class="bg-mid-gray"-->
        <div class="container">
            <div class="row">
                <div class="col-lg-12 text-center">
                    <h2 class="section-heading">Keynote Speakers</h2>
                    <!--h3 class="section-subheading text-muted">More keynote speakers will be announced soon!</h3-->
                </div>
            </div>
            <div class="row">

                <div class="col-sm-2">
                    <div class="team-member">
                        <img src="img/speakers/Nitesh.jpg" class="img-responsive img-circle" alt="Nitesh Chawla">
                        <h4>Nitesh Chawla</h4>
                        <p class="text-muted">Professor<br/>University of Notre Dame</p>
                          <ul class="list-inline social-buttons-team">
                              <li><a target=_blank href="http://www3.nd.edu/~nchawla/"><i class="fa fa-home"></i></a>
                              </li>
                              <li><a target=_blank href="https://twitter.com/nvchawla"><i class="fa fa-twitter"></i></a>
                              </li>
                              <li><a target=_blank href="https://www.linkedin.com/in/nitesh-chawla-606795/"><i class="fa fa-linkedin"></i></a>
                              </li>
                              <li><a target=_blank href="https://scholar.google.com/citations?user=hDLBEhkAAAAJ"><i class="fa fa-graduation-cap"></i></a>
                              </li>
                          </ul>
                    </div>
                </div>

                <div class="col-sm-2">
                    <div class="team-member">
                        <img src="img/speakers/jessie.png" class="img-responsive img-circle" alt="Zhenhui Jessie Li">
                        <h4>Zhenhui Jessie Li</h4>
                        <p class="text-muted">Associate Professor<br/>Pennsylvania State University</p>
                          <ul class="list-inline social-buttons-team">
                              <li><a target=_blank href="https://faculty.ist.psu.edu/jessieli/Site/index.html"><i class="fa fa-home"></i></a>
                              </li>
                              <li><a class="inactive" href="#keynote"><i class="fa fa-twitter"></i></a>
                              </li>
                              <li><a class="inactive" href="#keynote"><i class="fa fa-linkedin"></i></a>
                              </li>
                              <li><a target=_blank href="https://scholar.google.com/citations?user=r0nnyGYAAAAJ"><i class="fa fa-graduation-cap"></i></a>
                              </li>
                          </ul>
                    </div>
                </div>

                <div class="col-sm-2">
                    <div class="team-member">
                        <img src="img/speakers/yan.jpg" class="img-responsive img-circle" alt="Yan Liu">
                        <h4>Yan Liu</h4>
                        <p class="text-muted">Associate Professor<br/>University of Southern California</p>
                          <ul class="list-inline social-buttons-team">
                              <li><a target=_blank href="http://www-bcf.usc.edu/~liu32/"><i class="fa fa-home"></i></a>
                              </li>
                              <li><a target=_blank href="https://twitter.com/yanliu_usc"><i class="fa fa-twitter"></i></a>
                              </li>
                              <li><a target=_blank href="https://www.linkedin.com/in/yan-liu-b1a86127/"><i class="fa fa-linkedin"></i></a>
                              </li>
                              <li><a target=_blank href="https://scholar.google.com/citations?user=UUKLPMYAAAAJ"><i class="fa fa-graduation-cap"></i></a>
                              </li>
                          </ul>
                    </div>
                </div>

                <div class="col-sm-2">
                    <div class="team-member">
                        <img src="img/speakers/vahab.jpg" class="img-responsive img-circle" alt="Vahab Mirrokni">
                        <h4>Vahab Mirrokni</h4>
                        <p class="text-muted">Principal Scientist &amp; Research Director<br/>Google Research</p>
                          <ul class="list-inline social-buttons-team">
                              <li><a target=_blank href="http://people.csail.mit.edu/mirrokni/"><i class="fa fa-home"></i></a>
                              </li>
                              <li><a target=_blank href="https://twitter.com/mirrokni"><i class="fa fa-twitter"></i></a>
                              </li>
                              <li><a target=_blank href="https://www.linkedin.com/in/vahab-mirrokni-49774112/"><i class="fa fa-linkedin"></i></a>
                              </li>
                              <li><a target=_blank href="https://scholar.google.com/citations?user=opbZfw0AAAAJ"><i class="fa fa-graduation-cap"></i></a>
                              </li>
                          </ul>
                    </div>
                </div>

                <div class="col-sm-2">
                    <div class="team-member">
                        <img src="img/speakers/jiliang.jpg" class="img-responsive img-circle" alt="Jiliang Tang">
                        <h4>Jiliang Tang</h4>
                        <p class="text-muted">Assistant Professor<br/> Michigan State University</p>
                          <ul class="list-inline social-buttons-team">
                              <li><a target=_blank href="http://www.cse.msu.edu/~tangjili/"><i class="fa fa-home"></i></a>
                              </li>
                              <li><a target=_blank href="https://twitter.com/tangjiliang"><i class="fa fa-twitter"></i></a>
                              </li>
                              <li><a target=_blank href="https://www.linkedin.com/in/jiliang-tang-04172953/"><i class="fa fa-linkedin"></i></a>
                              </li>
                              <li><a target=_blank href="https://scholar.google.com/citations?user=WtzKMWAAAAAJ&hl=en"><i class="fa fa-graduation-cap"></i></a>
                              </li>
                          </ul>
                    </div>
                </div>

                <div class="col-sm-2">
                    <div class="team-member">
                        <img src="img/speakers/elena.jpg" class="img-responsive img-circle" alt="Elena Zheleva">
                        <h4>Elena Zheleva</h4>
                        <p class="text-muted">Assistant Professor<br/>University of Illinois at Chicago</p>
                          <ul class="list-inline social-buttons-team">
                              <li><a target=_blank href="https://www.cs.uic.edu/~elena/"><i class="fa fa-home"></i></a>
                              </li>
                              <li><a target=_blank href="https://twitter.com/elenadata"><i class="fa fa-twitter"></i></a>
                              </li>
                              <li><a target=_blank href="https://www.linkedin.com/in/elena-zheleva-19438a28/"><i class="fa fa-linkedin"></i></a>
                              </li>
                              <li><a target=_blank href="https://scholar.google.com/citations?user=Ug7VoyQAAAAJ"><i class="fa fa-graduation-cap"></i></a>
                              </li>
                          </ul>
                    </div>
                </div>

            </div>
        </div>
    </section>

    <!-- Accepted Papers Section -->
    <section id="papers" class="bg-mid-gray">
        <div class="container">
            <div class="row">
                <div class="col-lg-12 text-center">
                    <h2 class="section-heading">Accepted Papers</h2>
                    <!--h3 class="section-subheading text-muted">Accepted papers will be announced by the end of June.</h3-->
                </div>
            </div>
            <div class="row">

            <div class="col-lg-1 text-center">
                &nbsp;
            </div>

            <div class="col-lg-11 text-justify">
                  <!-- Begin Paper List -->

                  <p class="large text-muted">
                  <strong>HARP: Hierarchical Representation Learning for Networks</strong> 
                  <button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#pid10">Abstract</button> 
                  <button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#bib10">BibTex</button> 
                  <a href="paper/MLG2017_paper_10.pdf" target=_blank class="btn btn-primary btn-xs" role="button">PDF</a> 
                  <br/>
                  <i>Haochen Chen, Bryan Perozzi, Yifan Hu and Steven Skiena</i><br/>

                  <div id="pid10" class="collapse">
                  <strong>Abstract:</strong> We present HARP, a novel method for learning low dimensional embeddings of a graph's nodes which preserves higher-order structural features. Our proposed method achieves this by compressing the input graph prior to embedding it, effectively avoiding troublesome embedding configurations (i.e. local minima) which can pose problems to non-convex optimization.
                  HARP works by finding a smaller graph which approximates the global structure of its input. This simplified graph is used to learn a set of initial representations, which serve as good initializations for learning representations in the original, detailed graph. We inductively extend this idea, by decomposing a graph in a series of levels, and then embed the hierarchy of graphs from the coarsest one to the original graph. 
                  HARP is a general meta-strategy to improve all of the state-of-the-art neural algorithms for embedding graphs, including DeepWalk, LINE, and Node2vec. Indeed, we demonstrate that applying HARP's hierarchical paradigm yields improved implementations for all three of these methods, as evaluated on both classification tasks on real-world graphs such as DBLP, BlogCatalog, CiteSeer, and Arxiv, where we achieve a performance gain over the original implementations by up to 14% Macro F1.
                  <br/><br/><strong>Keywords:</strong> social networks, feature learning, latent representations, graph embeddings, multilevel optimization
                  <hr/>
                  </div>

                  <div id="bib10" class="collapse">
                  @inproceedings{mlg2017_10,<br/>
                  title={HARP: Hierarchical Representation Learning for Networks},<br/>
                  author={Haochen Chen, Bryan Perozzi, Yifan Hu and Steven Skiena},<br/>
                  booktitle={Proceedings of the 13th International Workshop on Mining and Learning with Graphs (MLG)},<br/>
                  year={2017}<br/>
                  }
                  <hr/>
                  </div>

                  </p>

                  <p class="large text-muted">
                  <strong>Neural Embeddings of Graphs in Hyperbolic Space</strong> 
                  <button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#pid6">Abstract</button> 
                  <button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#bib6">BibTex</button> 
                  <a href="paper/MLG2017_paper_6.pdf" target=_blank class="btn btn-primary btn-xs" role="button">PDF</a> 
                  <br/>
                  <i>Ben Chamberlain, Marc Deisenroth and James Clough</i><br/>

                  <div id="pid6" class="collapse">
                  <strong>Abstract:</strong> Neural embeddings have been used with great success in Natural Language Processing (NLP). They provide compact representations that encapsulate word similarity and attain state-of-the-art performance in a range of linguistic tasks. The success of neural embeddings has prompted significant amounts of research into applications in domains other than language. One such domain is graph-structured data, where embeddings of vertices can be learned that encapsulate vertex similarity and improve performance on tasks including edge prediction and vertex labelling. For both NLP and graph based tasks, embeddings have been learned in high-dimensional Euclidean spaces.
                  However, recent work has shown that the appropriate isometric space for embedding complex networks is not the flat Euclidean space, but negatively curved, hyperbolic space. We present a new concept that exploits these recent insights and propose learning neural embeddings of graphs in hyperbolic space. We provide experimental evidence that embedding graphs in their natural geometry significantly improves performance on downstream tasks for several real-world public datasets.
                  <br/><br/><strong>Keywords:</strong> neural networks, embeddings, graphs, geometry
                  <hr/>
                  </div>

                  <div id="bib6" class="collapse">
                  @inproceedings{mlg2017_6,<br/>
                  title={Neural Embeddings of Graphs in Hyperbolic Space},<br/>
                  author={Ben Chamberlain, Marc Deisenroth and James Clough},<br/>
                  booktitle={Proceedings of the 13th International Workshop on Mining and Learning with Graphs (MLG)},<br/>
                  year={2017}<br/>
                  }
                  <hr/>
                  </div>

                  </p>

                  <p class="large text-muted">
                  <strong>A/B Testing in Networks with Adversarial Members</strong> 
                  <button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#pid27">Abstract</button> 
                  <button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#bib27">BibTex</button> 
                  <a href="paper/MLG2017_paper_27.pdf" target=_blank class="btn btn-primary btn-xs" role="button">PDF</a> 
                  <br/>
                  <i>Kaleigh Clary and David Jensen</i><br/>

                  <div id="pid27" class="collapse">
                  <strong>Abstract:</strong> Many researchers attempt to study the effects of interventions in network systems. To simplify experimental design and analysis in these environments, simple assumptions are made about the behavior of its members. However, nodes may not respond to treatment, or may respond maliciously. These adversarial nodes influence treatment topology by preventing or altering the expected network effect, but may not be known or detectable.  We characterize the influence of adversarial nodes and the bias these nodes introduce in average treatment effect estimates.

                  In particular, we derive expressions for the bias induced in average treatment effect using the linear estimator from Gui et al (2015). In addition to theoretical bounds, we  empirically demonstrate estimation bias through experiments on synthetically generated networks. We consider both the case in which adversarial nodes are dispersed randomly through the network and the case where adversarial node placement is targeted to the highest degree nodes. Our work demonstrates that peer influence makes causal estimates on networks susceptible to the actions of adversaries, and specific network structures are particularly vulnerable to to adversarial responses.
                  <br/><br/><strong>Keywords:</strong> causal effect estimation, relational data, social networks, adversarial analysis
                  <hr/>
                  </div>

                  <div id="bib27" class="collapse">
                  @inproceedings{mlg2017_27,<br/>
                  title={A/B Testing in Networks with Adversarial Members},<br/>
                  author={Kaleigh Clary and David Jensen},<br/>
                  booktitle={Proceedings of the 13th International Workshop on Mining and Learning with Graphs (MLG)},<br/>
                  year={2017}<br/>
                  }
                  <hr/>
                  </div>

                  </p>

                  <p class="large text-muted">
                  <strong>A task-driven approach to time scale detection in dynamic networks</strong> 
                  <button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#pid17">Abstract</button> 
                  <button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#bib17">BibTex</button> 
                  <a href="paper/MLG2017_paper_17.pdf" target=_blank class="btn btn-primary btn-xs" role="button">PDF</a> 
                  <br/>
                  <i>Benjamin Fish and Rajmonda S. Caceres</i><br/>

                  <div id="pid17" class="collapse">
                  <strong>Abstract:</strong> For any stream of time-stamped edges that form a dynamic network, an important choice is the aggregation granularity that an analyst uses to bin the data.  Picking such a windowing of the data is often done by hand, or left up to the technology that is collecting the data.  However, the choice can make a big difference in the properties of the dynamic network.  Finding a good windowing is the time scale detection problem.  In previous work, this problem is often solved with an unsupervised heuristic.  As an unsupervised problem, it is difficult to measure how well a given windowing algorithm performs.  
                  In addition, we show that there is little correlation between the quality of a windowing across different tasks.   Therefore the time scale detection problem should not be handled independently from the rest of the analysis of the network.

                  Given this, in accordance with standard supervised machine learning practices, we introduce new windowing algorithms that automatically adapt to the task the analyst wants to perform by treating windowing as a hyperparameter for the task, rather than using heuristics.  This approach measures the quality of the windowing by how well a given task is accomplished on the resulting network.  This also allows us, for the first time, to directly compare different windowing algorithms to each other, by comparing how well the task is accomplished using that windowing algorithm.  We compare this approach to previous approaches and several baselines on real data.
                  <br/><br/><strong>Keywords:</strong> dynamic networks, time scale detection, supervised learning
                  <hr/>
                  </div>

                  <div id="bib17" class="collapse">
                  @inproceedings{mlg2017_17,<br/>
                  title={A task-driven approach to time scale detection in dynamic networks},<br/>
                  author={Benjamin Fish and Rajmonda S. Caceres},<br/>
                  booktitle={Proceedings of the 13th International Workshop on Mining and Learning with Graphs (MLG)},<br/>
                  year={2017}<br/>
                  }
                  <hr/>
                  </div>

                  </p>

                  <p class="large text-muted">
                  <strong>A Temporal Tree Decomposition for Generating Temporal Graphs</strong> 
                  <button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#pid7">Abstract</button> 
                  <button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#bib7">BibTex</button> 
                  <a href="paper/MLG2017_paper_7.pdf" target=_blank class="btn btn-primary btn-xs" role="button">PDF</a> 
                  <br/>
                  <i>Corey Pennycuff and Tim Weninger</i><br/>

                  <div id="pid7" class="collapse">
                  <strong>Abstract:</strong> Discovering the underlying structures present in large real world graphs is a fundamental scientific problem. Recent work at the intersection of formal language theory and graph theory has found that a Hyperedge Replacement Grammar (HRG) can be extracted from a tree decomposition of any graph. This HRG can be used to generate new graphs that share properties that are similar to the original graph. Because the extracted HRG is directly dependent on the shape and contents of the of tree decomposition, it is unlikely that informative graph-processes are actually being captured with the extraction algorithm. To address this problem, the current work presents a new extraction algorithm called temporal HRG (tHRG) that learns HRG production rules from a temporal tree decomposition of the graph. We observe problems with the assumptions that are made in a temporal HRG model. In experiments on large real world networks, we show and provide reasoning as to why tHRG does not perform as well as HRG and other graph generators.
                  <br/><br/><strong>Keywords:</strong> graph models, hyperedge replacement grammars, temporal graphs
                  <hr/>
                  </div>

                  <div id="bib7" class="collapse">
                  @inproceedings{mlg2017_7,<br/>
                  title={A Temporal Tree Decomposition for Generating Temporal Graphs},<br/>
                  author={Corey Pennycuff and Tim Weninger},<br/>
                  booktitle={Proceedings of the 13th International Workshop on Mining and Learning with Graphs (MLG)},<br/>
                  year={2017}<br/>
                  }
                  <hr/>
                  </div>

                  </p>

                  <p class="large text-muted">
                  <strong>Star sampling with and without replacement</strong> 
                  <button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#pid8">Abstract</button> 
                  <button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#bib8">BibTex</button> 
                  <a href="paper/MLG2017_paper_8.pdf" target=_blank class="btn btn-primary btn-xs" role="button">PDF</a> 
                  <br/>
                  <i>Jonathan Stokes and Steven Weber</i><br/>

                  <div id="pid8" class="collapse">
                  <strong>Abstract:</strong> Star sampling (SS) is a graph search mechanism wherein each sample consists of a vertex (the star center) and its one-hop neighbors (the star points).  We consider the use of star sampling to find any vertex in a specified target set in a large graph, where the figure of merit is the expected number of samples until a vertex in the target set is encountered, either as a star center or as a star point.  We analyze this performance measure on three related star sampling paradigms: SS with replacement (SS-R), SS without center replacement (SS-C), and SS without star replacement (SS-S).  Exact expressions for the average number of samples under SS-R and SS-C are easily obtained.  Much of the paper is focused on deriving an approximate expression for the performance of SS-S.  Experiments are run on both "synthetic" graphs, i.e., Erdos-Renyi (ER) graphs, as well as three "real-world" graphs.  The two contributions of the paper are: i) the analytical approximation for SS-S is seen to be quite accurate for both types of graphs, ii) we observe, perhaps surprisingly, there is little performance difference across the three sampling paradigms.  This performance insensitivity of SS-R relative to SS-S may be understood as the result of two competing factors: removing stars reduces the number of vertices outside the target set, but also removes the number of neighbors of the target set.
                  <br/><br/><strong>Keywords:</strong> star sampling, graph search, graph sampling, performance analysis
                  <hr/>
                  </div>

                  <div id="bib8" class="collapse">
                  @inproceedings{mlg2017_8,<br/>
                  title={Star sampling with and without replacement},<br/>
                  author={Jonathan Stokes and Steven Weber},<br/>
                  booktitle={Proceedings of the 13th International Workshop on Mining and Learning with Graphs (MLG)},<br/>
                  year={2017}<br/>
                  }
                  <hr/>
                  </div>

                  </p>

                  <p class="large text-muted">
                  <strong>Fast Algorithms for Learning Latent Variables in Graphical Models</strong> 
                  <button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#pid12">Abstract</button> 
                  <button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#bib12">BibTex</button> 
                  <a href="paper/MLG2017_paper_12.pdf" target=_blank class="btn btn-primary btn-xs" role="button">PDF</a> 
                  <br/>
                  <i>Mohammadreza Soltani and Chinmay Hegde</i><br/>

                  <div id="pid12" class="collapse">
                  <strong>Abstract:</strong> We study the problem of learning latent variables in Gaussian graphical
                  models. Existing methods for this problem assume that the
                  precision matrix of the observed variables is the superposition of a
                  sparse and a low-rank component. In this paper, we focus on the
                  estimation of the low-rank component, which encodes the effect of
                  marginalization over the latent variables. We introduce fast, proper
                  learning algorithms for this problem. In contrast with existing approaches,
                  our algorithms are manifestly non-convex. We support
                  their efficacy via a rigorous theoretical analysis, and show that our
                  algorithms match the best possible in terms of sample complexity,
                  while achieving computational speed-ups over existing methods.
                  We complement our theory with several numerical experiments.
                  <br/><br/><strong>Keywords:</strong> Latent variables, Fast Algorithm, Nonconvex Algorithm, Probabilistic Graphical Models
                  <hr/>
                  </div>

                  <div id="bib12" class="collapse">
                  @inproceedings{mlg2017_12,<br/>
                  title={Fast Algorithms for Learning Latent Variables in Graphical Models},<br/>
                  author={Mohammadreza Soltani and Chinmay Hegde},<br/>
                  booktitle={Proceedings of the 13th International Workshop on Mining and Learning with Graphs (MLG)},<br/>
                  year={2017}<br/>
                  }
                  <hr/>
                  </div>

                  </p>

                  <p class="large text-muted">
                  <strong>Parallel Graph Summarization for Knowledge Search</strong> 
                  <button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#pid16">Abstract</button> 
                  <button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#bib16">BibTex</button> 
                  <a href="paper/MLG2017_paper_16.pdf" target=_blank class="btn btn-primary btn-xs" role="button">PDF</a> 
                  <br/>
                  <i>Qi Song, Mohammad Hossein Namaki, Peng Lin and Yinghui Wu</i><br/>

                  <div id="pid16" class="collapse">
                  <strong>Abstract:</strong> Querying heterogeneous and large-scale knowledge graphs are typically expensive. This paper studies a parallel graph summarization framework to facilitate knowledge graph search. (1) We propose a class of reduced summaries characterized by graph patterns, which are capable of summarizing entities in terms of their neighborhood similarity up to a certain hop. (2) We study a bi-criteria diversified summarization problem. Given a knowledge graph G, it is to discover top-k diversified reduced summaries with maximized quality in terms of both informativeness and diversity. (3) We show that diversified summarization is feasible for large knowledge graphs,  by developing a parallel approximation algorithm with quality guarantees. We show that the algorithm is parallel scalable, which ensures the feasibility of summarization in large graphs. Using real-world graphs, we experimentally verify the efficiency of our parallel summarization algorithms, and query evaluation guided by summarization. 
                  <br/><br/><strong>Keywords:</strong> parallel computing, knowledge graph, graph summarization
                  <hr/>
                  </div>

                  <div id="bib16" class="collapse">
                  @inproceedings{mlg2017_16,<br/>
                  title={Parallel Graph Summarization for Knowledge Search},<br/>
                  author={Qi Song, Mohammad Hossein Namaki, Peng Lin and Yinghui Wu},<br/>
                  booktitle={Proceedings of the 13th International Workshop on Mining and Learning with Graphs (MLG)},<br/>
                  year={2017}<br/>
                  }
                  <hr/>
                  </div>

                  </p>

                  <p class="large text-muted">
                  <strong>GraphZip: Mining Graph Streams using Dictionary-based Compression</strong> 
                  <button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#pid18">Abstract</button> 
                  <button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#bib18">BibTex</button> 
                  <a href="paper/MLG2017_paper_18.pdf" target=_blank class="btn btn-primary btn-xs" role="button">PDF</a> 
                  <br/>
                  <i>Charles Packer and Larry Holder</i><br/>

                  <div id="pid18" class="collapse">
                  <strong>Abstract:</strong> A massive amount of data generated today on platforms such as 
                  social networks, telecommunication networks, and the internet 
                  in general can be represented as graph streams. Activity in a network’s 
                  underlying graph generates a sequence of edges in the form 
                  of a stream; for example, a social network may generate a graph 
                  stream based on the interactions (edges) between different users 
                  (nodes) over time. While many graph mining algorithms have already 
                  been developed for analyzing relatively small graphs, graphs 
                  that begin to approach the size of real-world networks stress the 
                  limitations of such methods due to their dynamic nature and the 
                  substantial number of nodes and connections involved. 
                  In this paper we present GraphZip, a scalable method for mining 
                  interesting patterns in graph streams. GraphZip is inspired by 
                  the Lempel-Ziv (LZ) class of compression algorithms, and uses a 
                  novel dictionary-based compression approach to discover maximally-compressing 
                  patterns in a graph stream. We experimentally show 
                  that GraphZip is able to retrieve both complex and insightful patterns 
                  from large real-world graphs and artificially-generated graphs 
                  with predefined (i.e., ground truth) patterns. Additionally, our results 
                  demonstrate that GraphZip is both highly efficient and highly 
                  effective compared to existing state-of-the-art methods for mining 
                  graph streams.
                  <br/><br/><strong>Keywords:</strong> Graph mining, Compression, Streaming data
                  <hr/>
                  </div>

                  <div id="bib18" class="collapse">
                  @inproceedings{mlg2017_18,<br/>
                  title={GraphZip: Mining Graph Streams using Dictionary-based Compression},<br/>
                  author={Charles Packer and Larry Holder},<br/>
                  booktitle={Proceedings of the 13th International Workshop on Mining and Learning with Graphs (MLG)},<br/>
                  year={2017}<br/>
                  }
                  <hr/>
                  </div>

                  </p>

                  <p class="large text-muted">
                  <strong>Matrix Factorization with Side and Higher Order Information</strong> 
                  <button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#pid19">Abstract</button> 
                  <button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#bib19">BibTex</button> 
                  <a href="paper/MLG2017_paper_19.pdf" target=_blank class="btn btn-primary btn-xs" role="button">PDF</a> 
                  <br/>
                  <i>Vatsal Shah, Nikhil Rao and Weicong Ding</i><br/>

                  <div id="pid19" class="collapse">
                  <strong>Abstract:</strong> The problem of predicting unobserved entries of a partially observed matrix has found wide applicability in several areas, such as recommender systems, computational biology, and computer vision. Many scalable methods with rigorous theoretical guarantees have been developed for algorithms where the matrix is factored into low-rank components, and embeddings are learned for the row and column variables. While there has been recent research on incorporating explicit side information in the low-rank matrix factorization setting, often implicit information can be gleaned from the data, via higher order interactions among variables. In this paper, we design a method to make use of this implicit information, via random walks on graphs. We show that the problem we intend to solve can be cast as factoring a nonlinear transform of the (partially) observed matrix and develop an efficient coordinate descent based algorithm for the same. Experiments on several datasets show that the method we propose outperforms vanilla matrix factorization, and also those methods that use explicitly available side information.
                  <br/><br/><strong>Keywords:</strong> Matrix Factorization, Recommender Systems, Alternating Minimization
                  <hr/>
                  </div>

                  <div id="bib19" class="collapse">
                  @inproceedings{mlg2017_19,<br/>
                  title={Matrix Factorization with Side and Higher Order Information},<br/>
                  author={Vatsal Shah, Nikhil Rao and Weicong Ding},<br/>
                  booktitle={Proceedings of the 13th International Workshop on Mining and Learning with Graphs (MLG)},<br/>
                  year={2017}<br/>
                  }
                  <hr/>
                  </div>

                  </p>

                  <p class="large text-muted">
                  <strong>graph2vec: Learning Distributed Representations of Graphs</strong> 
                  <button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#pid21">Abstract</button> 
                  <button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#bib21">BibTex</button> 
                  <a href="paper/MLG2017_paper_21.pdf" target=_blank class="btn btn-primary btn-xs" role="button">PDF</a> 
                  <br/>
                  <i>Annamalai Narayanan, Mahinthan Chandramohan, Rajasekar Venkatesan, Lihui Chen, Yang Liu and Shantanu Jaiswal</i><br/>

                  <div id="pid21" class="collapse">
                  <strong>Abstract:</strong> Recent works on representation learning for graph structured
                  data predominantly focus on learning distributed representations
                  of graph substructures such as nodes and subgraphs.
                  However, many graph analytics tasks such as
                  graph classification and clustering require representing entire
                  graphs as fixed length feature vectors. While the aforementioned
                  approaches are naturally unequipped to learn
                  such representations, graph kernels remain as the most effective
                  way of obtaining them. However, these graph kernels
                  use handcrafted features (e.g., shortest paths, graphlets,
                  etc.) and hence are hampered by problems such as poor
                  generalization. To address this limitation, in this work, we
                  propose a neural embedding framework named graph2vec
                  to learn data-driven distributed representations of arbitrary
                  sized graphs. graph2vec’s embeddings are learnt in an unsupervised
                  manner and are task agnostic. Hence, they could
                  be used for any downstream task such as graph classification,
                  clustering and even seeding supervised representation learning
                  approaches. Our experiments on several benchmark and
                  large real-world datasets show that graph2vec achieves significant
                  improvements in classification and clustering accuracies
                  over substructure representation learning approaches
                  and are competitive with state-of-the-art graph kernels.
                  <br/><br/><strong>Keywords:</strong> Representation Learning, Deep Learning, Graph Kernels, Neural Embedding
                  <hr/>
                  </div>

                  <div id="bib21" class="collapse">
                  @inproceedings{mlg2017_21,<br/>
                  title={graph2vec: Learning Distributed Representations of Graphs},<br/>
                  author={Annamalai Narayanan, Mahinthan Chandramohan, Rajasekar Venkatesan, Lihui Chen, Yang Liu and Shantanu Jaiswal},<br/>
                  booktitle={Proceedings of the 13th International Workshop on Mining and Learning with Graphs (MLG)},<br/>
                  year={2017}<br/>
                  }
                  <hr/>
                  </div>

                  </p>

                  <p class="large text-muted">
                  <strong>Graphs for Malware Detection: The Next Frontier</strong> 
                  <button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#pid23">Abstract</button> 
                  <button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#bib23">BibTex</button> 
                  <a href="paper/MLG2017_paper_23.pdf" target=_blank class="btn btn-primary btn-xs" role="button">PDF</a> 
                  <br/>
                  <i>Abhishek Sharma and B. Aditya Prakash</i><br/>

                  <div id="pid23" class="collapse">
                  <strong>Abstract:</strong> Machine Learning based approaches for malware detection have achieved a certain level of maturity as product offerings by Cybersecurity companies. VirusTotal recently included X by Invincea and MalwareScore by  Endgame as signature-less anti-virus scanners. In this position paper, we argue that the significant challenges related to information heterogeneity, noisy and uncertain inputs, and the demand (from cybersecurity professionals) to generalize beyond per-sample prediction are impeding further advancement in this field. These challenges cannot be addressed by standard supervised machine learning approaches. We highlight the fact that the current applications of machine learning for cybersecurity have focused on feature based learning and largely ignored identifying and learning from the underlying relationships between malware samples. Malware graphs are the obvious abstractions for representing such relationships. We briefly discuss potential approaches and outline further research that is needed  to build high-impact deployable cybersecurity solutions based on malware graphs.
                  <br/><br/><strong>Keywords:</strong> Malware Detection, Graph Mining, Heterogeneous Graphs
                  <hr/>
                  </div>

                  <div id="bib23" class="collapse">
                  @inproceedings{mlg2017_23,<br/>
                  title={Graphs for Malware Detection: The Next Frontier},<br/>
                  author={Abhishek Sharma and B. Aditya Prakash},<br/>
                  booktitle={Proceedings of the 13th International Workshop on Mining and Learning with Graphs (MLG)},<br/>
                  year={2017}<br/>
                  }
                  <hr/>
                  </div>

                  </p>

                  <p class="large text-muted">
                  <strong>Location-based Event Detection Using Geotagged Semantic Graphs</strong> 
                  <button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#pid24">Abstract</button> 
                  <button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#bib24">BibTex</button> 
                  <a href="paper/MLG2017_paper_24.pdf" target=_blank class="btn btn-primary btn-xs" role="button">PDF</a> 
                  <br/>
                  <i>Yifang Wei and Lisa Singh</i><br/>

                  <div id="pid24" class="collapse">
                  <strong>Abstract:</strong> Event detection using Twitter has attracted a significant amount of research attention. While the emphasis of the related literature has been on detecting events without considering geography information, this work regards an event as something occurring at a particular location and time. We take a system perspective, focusing on the process of event detection using a framework that highlights different steps needed for identifying events in this noisy domain. We also propose an algorithm which leverages geotagged bursty term graphs to detect events from a tweet stream.  Evaluating our approach on three large tweet streams from three different domains shows our approach significantly improves the detection precision and recall when compared to the state of the art approaches. In general, we find that simple modifications to existing algorithms improves location-based event detection across methods.
                  <br/><br/><strong>Keywords:</strong> Social Media, Text Event Detection, Location-based Graph Mining
                  <hr/>
                  </div>

                  <div id="bib24" class="collapse">
                  @inproceedings{mlg2017_24,<br/>
                  title={Location-based Event Detection Using Geotagged Semantic Graphs},<br/>
                  author={Yifang Wei and Lisa Singh},<br/>
                  booktitle={Proceedings of the 13th International Workshop on Mining and Learning with Graphs (MLG)},<br/>
                  year={2017}<br/>
                  }
                  <hr/>
                  </div>

                  </p>

                  <p class="large text-muted">
                  <strong>Compressive Sampling for Sparse Recovery in Networks</strong> 
                  <button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#pid29">Abstract</button> 
                  <button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#bib29">BibTex</button> 
                  <a href="paper/MLG2017_paper_29.pdf" target=_blank class="btn btn-primary btn-xs" role="button">PDF</a> 
                  <br/>
                  <i>Elahe Ghalebi K., Hamidreza Mahyar, Radu Grosu and Hamid R. Rabiee</i><br/>

                  <div id="pid29" class="collapse">
                  <strong>Abstract:</strong> This paper introduces CS-SRN, a general framework for recovering sparse vectors representing specific features of nodes/links in networks. We use compressive sampling (CS) to construct a feasible measurement matrix under network topological constraints which is motivated by network inference. CS-SRN addresses the problem of monitoring the network internal characteristics using indirect end-to-end (aggregated) measurements. We evaluate the performance of the proposed method by extensive simulations on both synthetic and real-world networks under several configurations. The experimental results indicate that this framework outperforms the state-of-the-art compressive sensing-based method and can be employed to efficiently and accurately infer a wide range of networks.
                  <br/><br/><strong>Keywords:</strong> Compressive Sampling, Sparse Recovery, Network Tomography, Graph Mining
                  <hr/>
                  </div>

                  <div id="bib29" class="collapse">
                  @inproceedings{mlg2017_29,<br/>
                  title={Compressive Sampling for Sparse Recovery in Networks},<br/>
                  author={Elahe Ghalebi K., Hamidreza Mahyar, Radu Grosu and Hamid R. Rabiee},<br/>
                  booktitle={Proceedings of the 13th International Workshop on Mining and Learning with Graphs (MLG)},<br/>
                  year={2017}<br/>
                  }
                  <hr/>
                  </div>

                  </p>

                  <p class="large text-muted">
                  <strong>Fraud Detection using Graph Topology and Temporal Spikes</strong> 
                  <button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#pid3">Abstract</button> 
                  <button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#bib3">BibTex</button> 
                  <a href="paper/MLG2017_paper_3.pdf" target=_blank class="btn btn-primary btn-xs" role="button">PDF</a> 
                  <br/>
                  <i>Shenghua Liu, Bryan Hooi and Christos Faloutsos</i><br/>

                  <div id="pid3" class="collapse">
                  <strong>Abstract:</strong> Fraud detection is facing more challenges when online fraudsters invest more resources, including purchasing large pools of fake user accounts and dedicated IPs, to make their attacks less obvious. Existing approaches such as average degree maximization in adjacency matrices or tensors, that aimed at finding the connections of maximum average degree density suffer from the bias of including more false positive nodes, resulting in lower accuracy and increased need for manual verification. Therefore, we propose HoloScope method to detect topology and spike suspiciousness simultaneously. A novel "contrast suspiciousness" is introduced for honoring contrast behaviors between fraudsters and normal users. In terms of graph topology, it allows us to more accurately detect fraudulent blocks, reducing the false positive nodes; In terms of temporal spikes, HoloScope takes into account the bursts caused by fraudsters' attacking, and the sudden drops due to the poor attractiveness of fake objects. In addition, we provide theoretical bounds for how much this increases the time cost needed for fraudsters to conduct adversarial attacks. Additionally, from the perspective of ratings, HoloScope incorporates the deviation of rating scores in order to catch fraudsters more accurately. Moreover, the HoloScope has a concise framework and sub-quadratic time complexity, which make our algorithm reproducible and scalable. In the experiments, HoloScope achieved significant accuracy improvements on both synthetic and real data, compared with the state-of-the-art baselines.
                  <br/><br/><strong>Keywords:</strong> Fraud Detection, Graph Mining, Contrast Suspiciousness, Scalable Algorithm
                  <hr/>
                  </div>

                  <div id="bib3" class="collapse">
                  @inproceedings{mlg2017_3,<br/>
                  title={Fraud Detection using Graph Topology and Temporal Spikes},<br/>
                  author={Shenghua Liu, Bryan Hooi and Christos Faloutsos},<br/>
                  booktitle={Proceedings of the 13th International Workshop on Mining and Learning with Graphs (MLG)},<br/>
                  year={2017}<br/>
                  }
                  <hr/>
                  </div>

                  </p>

                  <p class="large text-muted">
                  <strong>Adaptive Candidate Generation for Scalable Edge-discovery Tasks on Data Graphs</strong> 
                  <button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#pid14">Abstract</button> 
                  <button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#bib14">BibTex</button> 
                  <a href="paper/MLG2017_paper_14.pdf" target=_blank class="btn btn-primary btn-xs" role="button">PDF</a> 
                  <br/>
                  <i>Mayank Kejriwal</i><br/>

                  <div id="pid14" class="collapse">
                  <strong>Abstract:</strong> Several 'edge-discovery' applications over graph-based data models are known to have worst-case quadratic time complexity in the nodes, even if the discovered edges are sparse. One example is the generic link discovery problem between two graphs, which has invited research interest in several communities. Specific versions of this problem include link prediction in social networks, ontology alignment  between metadata-rich RDF data, approximate joins, and entity resolution between instance-rich data. As large datasets continue to proliferate, reducing quadratic complexity to make the task practical is an important research problem. Within the entity resolution community, the problem is commonly referred to as blocking. A particular class of learnable blocking schemes is known as Disjunctive Normal Form (DNF) blocking schemes, and has emerged as state-of-the art for homogeneous (i.e. same-schema) tabular data. Despite the promise of these schemes, a formalism or learning framework has not been developed for them when input data instances are generic, attributed graphs possessing both node and edge heterogeneity. With such a development, the complexity-reducing scope of DNF schemes becomes applicable to a variety of problems, including entity resolution and type alignment between heterogeneous graphs, and link prediction in networks represented as attributed graphs. This paper presents a graph-theoretic formalism for DNF schemes, and investigates their learnability in an optimization framework. We also briefly describe an empirical case study encapsulating some of the principles in this paper.
                  <br/><br/><strong>Keywords:</strong> Candidate Generation, Blocking, Heterogeneity, Link Discovery, DNF Schemes, Data Graphs
                  <hr/>
                  </div>

                  <div id="bib14" class="collapse">
                  @inproceedings{mlg2017_14,<br/>
                  title={Adaptive Candidate Generation for Scalable Edge-discovery Tasks on Data Graphs},<br/>
                  author={Mayank Kejriwal},<br/>
                  booktitle={Proceedings of the 13th International Workshop on Mining and Learning with Graphs (MLG)},<br/>
                  year={2017}<br/>
                  }
                  <hr/>
                  </div>

                  </p>

                  <p class="large text-muted">
                  <strong>Cluster Hire in a Network of Experts</strong> 
                  <button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#pid22">Abstract</button> 
                  <button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#bib22">BibTex</button> 
                  <a href="paper/MLG2017_paper_22.pdf" target=_blank class="btn btn-primary btn-xs" role="button">PDF</a> 
                  <br/>
                  <i>Meet Patel and Mehdi Kargar</i><br/>

                  <div id="pid22" class="collapse">
                  <strong>Abstract:</strong> Finding a group of experts is a natural way to perform a collection of tasks that needs a set of diversified skills.  This can be done by assigning skills to different experts with complementary expertise.  This allows organizations and big institutes to efficiently hire a group of experts with different skill sets to deliver a series of required tasks in order to finish a set of projects.  We are given a collection of projects, in which each of them needs a set of required skills.  Performing each project brings a profit to the organization.  We are also given a set of experts, each of them are equipped with a set of skills.  In order to hire an expert, the organization should provide her monetary cost (i.e., salary).  Furthermore, we are given a certain amount of budget to hire experts.  The goal is to hire a group of experts within the given budget to perform a subset of projects that maximizes the total profit.  This problem is called Cluster Hire and was introduced recently.   In this paper, we extend this problem by making the realistic assumption that there exist an underlying network among experts.  This network is built based on past collaboration among experts.  If two experts have past collaboration, they form a more collaborative and efficient team in the future.  In addition of maximizing the total profit, we are also interested to find the most collaborative group of experts by minimizing the communication cost between them.  We propose two greedy algorithms with different strategies to solve this problem.  Extensive experiments on real dataset show our proposed algorithms are able to find a group of experts that cover projects with high profit while experts are able to communicate with each other efficiently.
                  <br/><br/><strong>Keywords:</strong> Cluster Hire, Team Formation, Social Network
                  <hr/>
                  </div>

                  <div id="bib22" class="collapse">
                  @inproceedings{mlg2017_22,<br/>
                  title={Cluster Hire in a Network of Experts},<br/>
                  author={Meet Patel and Mehdi Kargar},<br/>
                  booktitle={Proceedings of the 13th International Workshop on Mining and Learning with Graphs (MLG)},<br/>
                  year={2017}<br/>
                  }
                  <hr/>
                  </div>

                  </p>

                  <p class="large text-muted">
                  <strong>On Generalizing Neural Node Embedding Methods to Multi-Network Problems</strong> 
                  <button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#pid26">Abstract</button> 
                  <button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#bib26">BibTex</button> 
                  <a href="paper/MLG2017_paper_26.pdf" target=_blank class="btn btn-primary btn-xs" role="button">PDF</a> 
                  <br/>
                  <i>Mark Heimann and Danai Koutra</i><br/>

                  <div id="pid26" class="collapse">
                  <strong>Abstract:</strong> Representation learning has attracted significant interest in the community and has been shown to be successful in tasks involving one graph, such as link prediction and node classification. In this paper, we conduct an empirical study of two leading deep learning based node embedding methods, node2vec and SDNE, to examine their suitability for problems that involve multiple graphs.Although the embeddings have been shown to preserve properties necessary for the success of graph mining tasks on a single graph,we find that different runs of the same algorithm even on the same graph yield different embeddings. For node embedding methods to apply to multi-graph problems, we note that this finding motivates additional work in learning how to embed different graphs similarly.
                  <br/><br/><strong>Keywords:</strong> representation learning, graph alignment, node embedding
                  <hr/>
                  </div>

                  <div id="bib26" class="collapse">
                  @inproceedings{mlg2017_26,<br/>
                  title={On Generalizing Neural Node Embedding Methods to Multi-Network Problems},<br/>
                  author={Mark Heimann and Danai Koutra},<br/>
                  booktitle={Proceedings of the 13th International Workshop on Mining and Learning with Graphs (MLG)},<br/>
                  year={2017}<br/>
                  }
                  <hr/>
                  </div>

                  </p>

                  <p class="large text-muted">
                  <strong>DeepInfer: Diffusion Network Inference through Representation Learning</strong> 
                  <button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#pid5">Abstract</button> 
                  <button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#bib5">BibTex</button> 
                  <a href="paper/MLG2017_paper_5.pdf" target=_blank class="btn btn-primary btn-xs" role="button">PDF</a> 
                  <br/>
                  <i>Zekarias Kefato, Nasrullah Sheikh and Alberto Montresor</i><br/>

                  <div id="pid5" class="collapse">
                  <strong>Abstract:</strong> The diffusion of a contagion (e.g. news, meme, virus) is a common event in  (online and offline) social networks. Unfortunately, such networks, known as diffusion networks, are often unknown: that is, one can observe when subjects are infected by a given contagion (e.g., when a piece of information arrives, when a product is adopted, when a virus is caught), but does not know through which connection the infection has been transmitted. The goal of this study is to infer such networks based on nodes infection contexts associated to diffusion events (cascades). Previous studies mostly relied on delay patterns between infection events of nodes to infer edges. It has been argued, however, that delay-agnostic approaches are also efficient for such inference. Motivated by this finding, we present a novel delay-agnostic algorithm that is largely inspired by representation learning of words in documents and nodes in networks. Moreover, unlike some delay-agnostic methods, we only consider infection context of nodes in a restricted window. After empirically observing a similarity between the distribution of words in documents and nodes in cascades, we employ the Skip-Gram model to learn a representation of nodes from cascades. The learned representation is then used to compute the probability that an edge exists between a pair of nodes. Through extensive experiments we validate the effectiveness of our algorithm, showing that it is able to recover up to ~95% of the hidden network in realistic datasets. We have also compared our algorithm to the state-of-the-art algorithm InfoPath, and achieved a large improvement on the quality of results.
                  <br/><br/><strong>Keywords:</strong> Network Inference, Cascades, Representation Learning
                  <hr/>
                  </div>

                  <div id="bib5" class="collapse">
                  @inproceedings{mlg2017_5,<br/>
                  title={DeepInfer: Diffusion Network Inference through Representation Learning},<br/>
                  author={Zekarias Kefato, Nasrullah Sheikh and Alberto Montresor},<br/>
                  booktitle={Proceedings of the 13th International Workshop on Mining and Learning with Graphs (MLG)},<br/>
                  year={2017}<br/>
                  }
                  <hr/>
                  </div>

                  </p>

                  <p class="large text-muted">
                  <strong>Exploiting Gaussian Embeddings for Directed Link Prediction</strong> 
                  <button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#pid9">Abstract</button> 
                  <button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#bib9">BibTex</button> 
                  <a href="paper/MLG2017_paper_9.pdf" target=_blank class="btn btn-primary btn-xs" role="button">PDF</a> 
                  <br/>
                  <i>Inzamam Rahaman and Patrick Hosein</i><br/>

                  <div id="pid9" class="collapse">
                  <strong>Abstract:</strong> Many systems can be represented as graphs where nodes represent components or actors in the system and edges represent interactions between said components and actors. Link Prediction refers to the task of using the current graphical representation of a system to to suggest which interactions might not be captured by the system or which interactions might occur in the future. In this position paper, we present preliminary results on the usage of Gaussian embeddings of nodes for the task of link prediction in directed graphs.
                  <br/><br/><strong>Keywords:</strong> Learning latent representations, Dimensionality reduction and manifold learning, Classification, Link Prediction
                  <hr/>
                  </div>

                  <div id="bib9" class="collapse">
                  @inproceedings{mlg2017_9,<br/>
                  title={Exploiting Gaussian Embeddings for Directed Link Prediction},<br/>
                  author={Inzamam Rahaman and Patrick Hosein},<br/>
                  booktitle={Proceedings of the 13th International Workshop on Mining and Learning with Graphs (MLG)},<br/>
                  year={2017}<br/>
                  }
                  <hr/>
                  </div>

                  </p>

                  <p class="large text-muted">
                  <strong>From Relational Data to Graphs: Inferring Significant Links using Generalized Hypergeometric Ensembles</strong> 
                  <button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#pid11">Abstract</button> 
                  <button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#bib11">BibTex</button> 
                  <a href="paper/MLG2017_paper_11.pdf" target=_blank class="btn btn-primary btn-xs" role="button">PDF</a> 
                  <br/>
                  <i>Giona Casiraghi, Vahan Nanumyan, Ingo Scholtes and Frank Schweitzer</i><br/>

                  <div id="pid11" class="collapse">
                  <strong>Abstract:</strong> The inference of network topologies from relational data is an important problem.
                  Exemplary applications include the reconstruction of social ties from data on human interactions, the inference of gene co-expression networks from DNA microarray data, or the learning of semantic relationships based on co-occurrences of words in documents.
                  Solving these problems requires techniques to infer significant links in noisy relational data.
                  In this position paper, we propose a new statistical modeling framework to address this challenge.
                  It builds on generalized hypergeometric ensembles, a class of generative stochastic models that give rise to analytically tractable probability spaces of directed, multi-edge graphs.
                  We show how this framework can be used to assess the significance of links in noisy relational data.
                  We illustrate our method in two data sets capturing spatio-temporal proximity relations between actors in a social system.
                  The results show that our theoretical framework provides a new approach to infer significant links from relational data, with interesting perspectives for mining and learning in graphs.
                  <br/><br/><strong>Keywords:</strong> statistical significance, network inference, noise filtering, link detection, graph mining, network analysis, statistical ensemble, stochastic modelling
                  <hr/>
                  </div>

                  <div id="bib11" class="collapse">
                  @inproceedings{mlg2017_11,<br/>
                  title={From Relational Data to Graphs: Inferring Significant Links using Generalized Hypergeometric Ensembles},<br/>
                  author={Giona Casiraghi, Vahan Nanumyan, Ingo Scholtes and Frank Schweitzer},<br/>
                  booktitle={Proceedings of the 13th International Workshop on Mining and Learning with Graphs (MLG)},<br/>
                  year={2017}<br/>
                  }
                  <hr/>
                  </div>

                  </p>

                  <p class="large text-muted">
                  <strong>Evaluating Social Networks Using Task-Focused Network Inference</strong> 
                  <button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#pid13">Abstract</button> 
                  <button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#bib13">BibTex</button> 
                  <a href="paper/MLG2017_paper_13.pdf" target=_blank class="btn btn-primary btn-xs" role="button">PDF</a> 
                  <br/>
                  <i>Ivan Brugere, Chris Kanich and Tanya Berger-Wolf</i><br/>

                  <div id="pid13" class="collapse">
                  <strong>Abstract:</strong> Networks are representations of complex underlying social processes. However, the same given network may be more suitable to model one behavior of individuals than another. In many cases, aggregate  population models may be more effective than modeling on the network. We present a general framework for evaluating the suitability of given networks for a set of predictive tasks of interest, compared against alternative, networks inferred from data. We present several interpretable network models and measures for our comparison. We apply this general framework to the case study on collective classification of music preferences in a newly available dataset of the Last.fm social network.
                  <br/><br/><strong>Keywords:</strong> network inference, statistical relational learning, model selection and validation
                  <hr/>
                  </div>

                  <div id="bib13" class="collapse">
                  @inproceedings{mlg2017_13,<br/>
                  title={Evaluating Social Networks Using Task-Focused Network Inference},<br/>
                  author={Ivan Brugere, Chris Kanich and Tanya Berger-Wolf},<br/>
                  booktitle={Proceedings of the 13th International Workshop on Mining and Learning with Graphs (MLG)},<br/>
                  year={2017}<br/>
                  }
                  <hr/>
                  </div>

                  </p>

                  <p class="large text-muted">
                  <strong>Using Partial Probes to Infer Network States</strong> 
                  <button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#pid25">Abstract</button> 
                  <button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#bib25">BibTex</button> 
                  <a href="paper/MLG2017_paper_25.pdf" target=_blank class="btn btn-primary btn-xs" role="button">PDF</a> 
                  <br/>
                  <i>Pavan Rangudu, Bijaya Adhikari, B. Aditya Prakash and Anil Vullikanti</i><br/>

                  <div id="pid25" class="collapse">
                  <strong>Abstract:</strong> In many applications, such as the Internet and infrastructure networks, nodes fail or get congested dynamically. We study the problem of inferring all the failed nodes, when only a sample of the failures is known, and there exist correlations between node failures/congestion in networks. We formalize this as the StateInf problem, using the the Minimum Description Length (MDL) principle. We propose a greedy algorithm for minimizing the MDL cost, and show that it gives an additive approximation, relative to the optimal. We evaluate our methods on synthetic and real datasets, which includes
                  one from WAZE which gives traffic incident reports for the city of Boston. We find that our method gives promising results in recovering the missing failures.
                  <br/><br/><strong>Keywords:</strong> missing data, mdl, infrastructure graphs
                  <hr/>
                  </div>

                  <div id="bib25" class="collapse">
                  @inproceedings{mlg2017_25,<br/>
                  title={Using Partial Probes to Infer Network States},<br/>
                  author={Pavan Rangudu, Bijaya Adhikari, B. Aditya Prakash and Anil Vullikanti},<br/>
                  booktitle={Proceedings of the 13th International Workshop on Mining and Learning with Graphs (MLG)},<br/>
                  year={2017}<br/>
                  }
                  <hr/>
                  </div>

                  </p>

                  <p class="large text-muted">
                  <strong>Compression of spatio-temporal networks via point-to-point process models</strong> 
                  <button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#pid30">Abstract</button> 
                  <button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#bib30">BibTex</button> 
                  <a href="paper/MLG2017_paper_30.pdf" target=_blank class="btn btn-primary btn-xs" role="button">PDF</a> 
                  <br/>
                  <i>Xiaoyue Li and James Sharpnack</i><br/>

                  <div id="pid30" class="collapse">
                  <strong>Abstract:</strong> A point-to-point process describes a dynamic network where a set of edge events are observed, each of which is associated with a time of occurrence and two vertices lying in their state spaces. 
                  This study intends to investigate one application of such processes, using NYC Taxi and Limousine Commission dataset that reports taxi trips between two locations at a certain time. 
                  Here a point-to-point process is formed with edge events being taxi trips and the vertices adjacent to the edge events are pick-up and drop-off locations, described by latitude and longitude pairs. 
                  The intensity of an edge event can have a temporal dependence in addition to being dependent on a latent, spatially-coherent community structure for the vertices.
                  To this end, we have developed a methodology that estimates a spatially smoothed community structure and localizes temporal change-points for point-to-point processes.  
                  By applying this to our dataset, we can explore the spatio-temporal dynamics of the demand of taxi trips.
                  More specifically, with reasonable assumptions, the latent community structure is estimated by spectral partitioning based on a low-rank reconstruction of aggregated taxi-trip network; and the temporal change-point localization can be carried out by solving a matrix group fused LASSO program.

                  <br/><br/><strong>Keywords:</strong> Point-to-point process, spatio-temporal networks, dynamic graph models
                  <hr/>
                  </div>

                  <div id="bib30" class="collapse">
                  @inproceedings{mlg2017_30,<br/>
                  title={Compression of spatio-temporal networks via point-to-point process models},<br/>
                  author={Xiaoyue Li and James Sharpnack},<br/>
                  booktitle={Proceedings of the 13th International Workshop on Mining and Learning with Graphs (MLG)},<br/>
                  year={2017}<br/>
                  }
                  <hr/>
                  </div>

                  </p>

                  <p class="large text-muted">
                  <strong>GECS: Graph Embedding Using Connection Subgraphs</strong> 
                  <button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#pid28">Abstract</button> 
                  <button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#bib28">BibTex</button> 
                  <a href="paper/MLG2017_paper_28.pdf" target=_blank class="btn btn-primary btn-xs" role="button">PDF</a> 
                  <br/>
                  <i>Saba Al-Sayouri, Pravallika Devineni, Sarah Lam, Vagelis Papalexakis and Danai Koutra</i><br/>

                  <div id="pid28" class="collapse">
                  <strong>Abstract:</strong> This paper studies the problem of learning large-scale graph representations (a.k.a. embeddings). Such representations encode the relations among distinct nodes on the continuous feature space. The learned representations generalize over various tasks, such as node classification, link prediction, and recommendation. Learning nodes representations aims to map proximate nodes close to one another in the low-dimension vector space. Thus, embedding algorithms pursue to preserve local and global network structure by identifying nodes neighborhood notions. However, the means proposed methods have been employed in order to identify nodes neighborhoods fail to precisely capture network structure. In this paper, we propose a novel scalable graph embedding algorithmic framework called GECS, which aims to learn graph representations using connection subgraphs, where analogy with electrical circuits has been employed. The connection subgraphs are created to address the proximity among each two non-adjacent nodes, which are abundant in real-world networks, by maximizing the amount of flow between them. Although a subgraph captures proximity between two non-adjacent nodes, the formation of the subgraph addresses the direct connections with immediate neighbors as well. Therefore, our algorithm better preserves the local and global structure of a network. Further, despite the fact that non-adjacent nodes are numerous in real-world networks, our algorithm can scale to large-scale graphs, because we do not deal with the graph as a whole, instead, with much more smaller extracted subgraphs.

                  Since our algorithm is not yet empirically examined, we here introduce a potential solution that can better learn graph representations comparing to existing embedding methods accompanied by rational reasoning.
                  <br/><br/><strong>Keywords:</strong> information networks, network flow, learning graph representations, node embedding
                  <hr/>
                  </div>

                  <div id="bib28" class="collapse">
                  @inproceedings{mlg2017_28,<br/>
                  title={GECS: Graph Embedding Using Connection Subgraphs},<br/>
                  author={Saba Al-Sayouri, Pravallika Devineni, Sarah Lam, Vagelis Papalexakis and Danai Koutra},<br/>
                  booktitle={Proceedings of the 13th International Workshop on Mining and Learning with Graphs (MLG)},<br/>
                  year={2017}<br/>
                  }
                  <hr/>
                  </div>

                  </p>


                  <!-- End Paper List -->
            </div>
          </div>
        </div>
    </section>

    <!-- Call for Papers Section -->
    <section id="call"> <!--class="bg-mid-gray"-->
        <div class="container">
            <div class="row">
                <div class="col-lg-12 text-center">
                    <h2 class="section-heading">Call for Papers</h2>
                    <!--h3 class="section-subheading text-muted">Lorem ipsum dolor sit amet consectetur.</h3-->
                </div>
            </div>
            <div class="row text-justify">
                <div class="col-md-12">
                    <p class="large text-muted">
                      This workshop is a forum for exchanging ideas and methods for mining and learning with graphs, developing new common understandings of the problems at hand, sharing of data sets where applicable, and leveraging existing knowledge from different disciplines. The goal is to bring together researchers from academia, industry, and government, to create a forum for discussing recent advances graph analysis. In doing so we aim to better understand the overarching principles and the limitations of our current methods, and to inspire research on new algorithms and techniques for mining and learning with graphs.
                    </p>
                    <p class="large text-muted">
                      To reflect the broad scope of work on mining and learning with graphs, we encourage submissions that span the spectrum from theoretical analysis to algorithms and implementation, to applications and empirical studies. As an example, the growth of user-generated content on blogs, microblogs, discussion forums, product reviews, etc., has given rise to a host of new opportunities for graph mining in the analysis of social media. We encourage submissions on theory, methods, and applications focusing on a broad range of graph-based approaches in various domains.
                    </p>
                    <p class="large text-muted">
                      Topics of interest include, but are not limited to:
                    </p>

                    <ul class="large text-muted">
                      <li><b>Theoretical aspects:</b>
                        <ul class="large text-muted">
                          <li>Computational or statistical learning theory related to graphs</li>
                          <li>Theoretical analysis of graph algorithms or models</li>
                          <li>Sampling and evaluation issues in graph algorithms</li>
                          <li>Relationships between MLG and statistical relational learning or inductive logic programming</li>
                        </ul>
                      </li>
                        <br/>
                      <li><b>Algorithms and methods:</b>
                        <ul class="large text-muted">
                          <li>Graph mining</li>
                          <li>Kernel methods for structured data</li>
                          <li>Probabilistic and graphical models for structured data</li>
                          <li>(Multi-) Relational data mining</li>
                          <li>Methods for structured outputs</li>
                          <li>Statistical models of graph structure</li>
                          <li>Combinatorial graph methods</li>
                          <li>Spectral graph methods</li>
                          <li>Semi-supervised learning, active learning, transductive inference, and transfer learning in the context of graph</li>
                        </ul>
                      </li>
                        <br/>
                      <li><b>Applications and analysis:</b>
                      <ul class="large text-muted">
                        <li>Analysis of social media</li>
                        <li>Social network analysis</li>
                        <li>Analysis of biological networks</li>
                        <li>Large-scale analysis and modeling</li>
                      </ul>
                      </li>
                    </ul>
                    <p class="large text-muted">
                      We invite the submission of regular research papers (6-8 pages) as well as position papers (2-4 pages).
                      We recommend papers to be formatted according to the standard double-column <a href="http://www.acm.org/publications/proceedings-template#aL2" target=_blank>ACM Proceedings Style</a>.
                      All papers will be peer reviewed, single-blinded.
                      Authors whose papers are accepted to the workshop will have the opportunity to participate in a poster session, and some set may also be chosen for oral presentation.
                      The accepted papers will be published online and will not be considered archival.<br/><br/>

                      For paper submission, please proceed to the <a href="https://easychair.org/conferences/?conf=mlg2017" target=_blank>submission website</a>.<br/><br/>

                      Please send enquiries to chair@mlgworkshop.org.</br>
                      To receive updates about the current and future workshops and the Graph Mining community, please join the <a href="https://groups.google.com/d/forum/mlg-list" target=_blank>Mailing List</a>, or follow the <a href="https://twitter.com/mlgworkshop" target=_blank>Twitter Account</a>.
                    </p>
                </div>
            </div>
        </div>
    </section>

    <!-- Dates Section -->
    <section id="dates" class="bg-mid-gray">
        <div class="container">
            <div class="row">
                <div class="col-lg-12 text-center">
                    <h2 class="section-heading">Important Dates</h2>
                    <!--h3 class="section-subheading text-muted">Lorem ipsum dolor sit amet consectetur.</h3-->
                </div>
            </div>
            <div class="row">
              <div class="col-lg-4 text-left">
                &nbsp;
              </div>
            <div class="col-lg-6 text-left">
                <div class="col-md-12">
                      <p class="large text-muted">
                      <b>Paper Submission Open:</b> <strike>Apr 20, 2017</strike>
                    </p><p class="large text-muted">
                      <b>Paper Submission Deadline:</b> <strike>June 2, 2017</strike>
                    </p><p class="large text-muted">
                      <b>Author Notification:</b> <strike>June 23, 2017</strike>
                    </p><p class="large text-muted">
                      <b>Camera Ready:</b> <strike>July 7, 2017</strike>
                    </p><p class="large text-muted">
                      <b>Workshop:</b> August 14, 2017
                      </p>
                </div>
            </div>
          </div>
        </div>
    </section>

  <!-- Organization Section -->
    <section id="organization"> <!--class="bg-mid-gray"-->
        <div class="container">
            <div class="row">
                <div class="col-lg-12 text-center">
                    <h2 class="section-heading">Workshop Organizers</h2>
                    <!--h3 class="section-subheading text-muted">Lorem ipsum dolor sit amet consectetur.</h3-->
                </div>
            </div>
            <div class="row">
                <div class="col-sm-2">
                    <div class="team-member">
                        <img src="img/team/1_michele.jpg" class="img-responsive img-circle" alt="">
                        <h4>Michele Catasta</h4>
                        <p class="text-muted">Stanford University</p>
                        <ul class="list-inline social-buttons-team">
                            <li><a href="http://fooshed.net" target="_blank"><i class="fa fa-home"></i></a>
                            </li>
                            <li><a href="https://twitter.com/pirroh" target=_blank><i class="fa fa-twitter"></i></a>
                            </li>
                            <li><a href="https://www.linkedin.com/in/pirroh/" target=_blank><i class="fa fa-linkedin"></i></a>
                            </li>
                            <li><a target=_blank href="https://scholar.google.com/citations?user=ZxfOSWMAAAAJ"><i class="fa fa-graduation-cap"></i></a>
                            </li>
                        </ul>
                    </div>
                </div>
                <div class="col-sm-2">
                    <div class="team-member">
                        <img src="img/team/2_shobeir.jpg" class="img-responsive img-circle" alt="">
                        <h4>Shobeir Fakhraei</h4>
                        <p class="text-muted">University of Maryland</p>
                        <ul class="list-inline social-buttons-team">
                            <li><a href="http://www.cs.umd.edu/~shobeir/" target="_blank"><i class="fa fa-home"></i></a>
                            </li>
                            <li><a href="https://twitter.com/shobeirf" target=_blank><i class="fa fa-twitter"></i></a>
                            </li>
                            <li><a href="http://www.linkedin.com/in/shobeir" target=_blank><i class="fa fa-linkedin"></i></a>
                            </li>
                            <li><a target=_blank href="https://scholar.google.com/citations?user=6vJwj_QAAAAJ"><i class="fa fa-graduation-cap"></i></a>
                            </li>
                        </ul>
                    </div>
                </div>
                <div class="col-sm-2">
                    <div class="team-member">
                        <img src="img/team/3_danai.jpg" class="img-responsive img-circle" alt="">
                        <h4>Danai Koutra</h4>
                        <p class="text-muted">University of Michigan</p>
                        <ul class="list-inline social-buttons-team">
                          <li><a href="http://web.eecs.umich.edu/~dkoutra/" target="_blank"><i class="fa fa-home"></i></a>
                          </li>
                          <li><a href="https://twitter.com/danaikoutra" target=_blank><i class="fa fa-twitter"></i></a>
                          </li>
                          <li><a href="https://www.linkedin.com/in/danai" target=_blank><i class="fa fa-linkedin"></i></a>
                          </li>
                          <li><a target=_blank href="https://scholar.google.com/citations?user=bDrA1-8AAAAJ"><i class="fa fa-graduation-cap"></i></a>
                          </li>
                        </ul>
                    </div>
                </div>
                <div class="col-sm-2">
                    <div class="team-member">
                        <img src="img/team/4_silvio.jpg" class="img-responsive img-circle" alt="">
                        <h4>Silvio Lattanzi</h4>
                        <p class="text-muted">Google Research</p>
                        <ul class="list-inline social-buttons-team">
                          <li><a href="https://sites.google.com/site/silviolattanzi/" target="_blank"><i class="fa fa-home"></i></a>
                          </li>
                          <li><a href="https://twitter.com/SilvioL" target=_blank><i class="fa fa-twitter"></i></a>
                          </li>
                          <li><a href="https://www.linkedin.com/in/silvio-lattanzi-abb85216/" target=_blank><i class="fa fa-linkedin"></i></a>
                          </li>
                          <li><a target=_blank href="https://scholar.google.com/citations?user=vxUZ4AUAAAAJ&hl=en"><i class="fa fa-graduation-cap"></i></a>
                          </li>
                        </ul>
                    </div>
                </div>
                <div class="col-sm-2">
                    <div class="team-member">
                        <img src="img/team/5_julian.jpg" class="img-responsive img-circle" alt="">
                        <h4>Julian McAuley</h4>
                        <p class="text-muted">UC San Diego</p>
                        <ul class="list-inline social-buttons-team">
                          <li><a href="http://cseweb.ucsd.edu/~jmcauley/" target="_blank"><i class="fa fa-home"></i></a>
                          </li>
                          <li><a class="inactive" href="#organization"><i class="fa fa-twitter"></i></a>
                          </li>
                          <li><a href="https://www.linkedin.com/in/julianmcauley" target=_blank><i class="fa fa-linkedin"></i></a>
                          </li>
                          <li><a target=_blank href="https://scholar.google.com/citations?user=icbo4M0AAAAJ"><i class="fa fa-graduation-cap"></i></a>
                          </li>
                        </ul>
                    </div>
                </div>
                <div class="col-sm-2">
                    <div class="team-member">
                        <img src="img/team/6_jennifer.jpg" class="img-responsive img-circle" alt="">
                        <h4>Jennifer Neville</h4>
                        <p class="text-muted">Purdue University</p>
                        <ul class="list-inline social-buttons-team">
                          <li><a href="https://www.cs.purdue.edu/homes/neville/" target="_blank"><i class="fa fa-home"></i></a>
                          </li>
                          <li><a href="https://twitter.com/ProfJenNeville" target=_blank><i class="fa fa-twitter"></i></a>
                          </li>
                          <li><a href="https://www.linkedin.com/in/jennifer-neville-2a880b5" target=_blank><i class="fa fa-linkedin"></i></a>
                          </li>
                          <li><a target=_blank href="https://scholar.google.com/citations?user=6CTPn44AAAAJ"><i class="fa fa-graduation-cap"></i></a>
                          </li>
                        </ul>
                    </div>
                </div>
            </div>
            <div class="row" style="margin-top:60px;">
                <div class="col-lg-12 text-center">
                    <h2 class="section-heading">Program Committee</h2>
                    <!--h3 class="section-subheading text-muted">TBA</h3-->
                    <div class="col-md-1">
                       &nbsp;
                    </div>
                    <div class="col-md-5 text-left">
                      <p class="large text-muted">
                        Nesreen Ahmed (Intel Labs)<BR/>
                        Leman Akoglu (Carnegie Mellon University)<BR/>
                        Aris Anagnostopoulos (Sapienza University of Rome)<BR/>
                        Miguel Araujo (Carnegie Mellon University)<BR/>
                        Stephen Bach (Stanford University)<BR/>
                        Christian Bauckhage (Fraunhofer IAIS)<BR/>
                        Aaron Clauset (University of Colorado Boulder)<BR/>
                        Bing Tian Dai (Singapore Management University)<BR/>
                        Alessandro Epasto (Google Research)<BR/>
                        Bailey Fosdick (Colorado State University)<BR/>
                        Brian Gallagher (Lawrence Livermore National Labs)<BR/>
                        Thomas Gärtner (University of Nottingham)<BR/>
                        Assefaw Gebremedhin (Washington State University)<BR/>
                        David Gleich (Purdue University)<BR/>
                        Larry Holder (Washington State University)<BR/>
                        Kristian Kersting (TU Dortmund University)<BR/>
                        Srijan Kumar (University of Maryland)<BR/>
                      </p>
                    </div>
                    <div class="col-md-5 text-left">
                      <p class="large text-muted">
                        Evangelos Papalexakis (University of California Riverside)<BR/>
                        Ali Pinar (Sandia National Laboratories)<BR/>
                        Bryan Perozzi (Google Research)<BR/>
                        Aditya Prakash (Virginia Tech)<BR/>
                        Jay Pujara (University of California, Santa Cruz)<BR/>
                        Jan Ramon (INRIA)<BR/>
                        C. Seshadhri (University of California, Santa Cruz)<BR/>
                        Neil Shah (Carnegie Mellon University)<BR/>
                        Sucheta Soundarajan (Syracuse University)<BR/>
                        Yizhou Sun (University of California, Los Angeles)<BR/>
                        Jiliang Tang (Michigan State University)<BR/>
                        Hanghang Tong (Arizona State University)<BR/>
                        Chris Volinsky (AT&T Labs-Research)<BR/>
                        Tim Weninger (University of Notre Dame)<BR/>
                        Jevin West (University of Washington)<BR/>
                        Stefan Wrobel (Fraunhofer IAIS & Univ. of Bonn)<BR/>
                        Mark Zhang (SUNY, Binghamton)<BR/>
                        </p>
                      </div>
                      <div class="col-md-1">
                         &nbsp;
                      </div>
                </div>
            </div>
        </div>
    </section>

    <!-- History Section -->
    <section id="history" class="bg-mid-gray">
        <div class="container">
            <div class="row">
                <div class="col-lg-12 text-center">
                    <h2 class="section-heading">Previous Workshops</h2>
                    <!--h3 class="section-subheading text-muted">Lorem ipsum dolor sit amet consectetur.</h3-->
                </div>
            </div>
            <div class="row">
              <div class="col-lg-4 text-left">
                &nbsp;
              </div>
                <div class="col-lg-6 text-left">
                      <p class="large text-muted">
                        <a href="http://www.mlgworkshop.org/2016/" target=_blank  class="large text-muted">2016, San Francisco, USA (co-located with KDD)</a></br>
                        <a href="http://snap.stanford.edu/mlg2013/" target=_blank  class="large text-muted">2013, Chicago, USA (co-located with KDD)</a></br>
                        <a href="http://dtai.cs.kuleuven.be/events/mlg2012/" target=_blank  class="large text-muted">2012, Edinburgh, Scotland (co-located with ICML)</a></br>
                        <a href="http://www.cs.purdue.edu/mlg2011/" target=_blank  class="large text-muted">2011, San Diego, USA (co-located with KDD)</a></br>
                        <a href="http://www.cs.umd.edu/mlg2010/" target=_blank  class="large text-muted">2010, Washington, USA (co-located with KDD)</a></br>
                        <a href="http://dtai.cs.kuleuven.be/ilp-mlg-srl//" target=_blank  class="large text-muted">2009, Leuven, Belgium (co-located with SRL and ILP)</a></br>
                        <a href="http://research.ics.aalto.fi/events/MLG08/" target=_blank  class="large text-muted">2008, Helsinki, Finland (co-located with ICML)</a></br>
                        <a href="http://mlg07.dsi.unifi.it/" target=_blank  class="large text-muted">2007, Firenze, Italy</a></br>
                        <a href="http://www.inf.uni-konstanz.de/mlg2006/index.shtml" target=_blank  class="large text-muted">2006, Berlin, German (co-located with ECML and PKDD)</a></br>
                        <a href="#" class="large text-muted">2005, Porto, Portugal, October 7, 2005</a></br>
                        <a href="http://hms.liacs.nl/mgts2004/" target=_blank  class="large text-muted">2004, Pisa, Italy, September 24, 2004</a></br>
                        <a href="http://www.ar.sanken.osaka-u.ac.jp/MGTS-2003CFP.html" target=_blank  class="large text-muted">2003, Cavtat-Dubrovnik, Croatia</a></br>
                      </p>
                </div>
            </div>
        </div>
    </section>

    <!-- Footer -->
    <footer  class="bg-darkest-gray">
        <div class="container">
            <div class="row">
                <div class="col-md-4">
                    <span class="copyright" style="color:gray;">Copyright &copy; MLG Workshop 2017</span>
                </div>
                <div class="col-md-4">
                    <ul class="list-inline social-buttons">
                        <li><a href="https://twitter.com/mlgworkshop" target=_blank><i class="fa fa-twitter"></i></a>
                        </li>
                        <!--li><a href="#"><i class="fa fa-facebook"></i></a>
                        </li>
                        <li><a href="#"><i class="fa fa-linkedin"></i></a>
                        </li-->
                    </ul>
                </div>
                <!--div class="col-md-4">
                    <ul class="list-inline quicklinks">
                        <li><a href="#">Privacy Policy</a>
                        </li>
                        <li><a href="#">Terms of Use</a>
                        </li>
                    </ul>
                </div-->
            </div>
        </div>
    </footer>

    <!-- jQuery -->
    <script src="js/jquery.js"></script>

    <!-- Bootstrap Core JavaScript -->
    <script src="js/bootstrap.min.js"></script>

    <!-- Plugin JavaScript -->
    <script src="http://cdnjs.cloudflare.com/ajax/libs/jquery-easing/1.3/jquery.easing.min.js"></script>
    <script src="js/classie.js"></script>
    <script src="js/cbpAnimatedHeader.js"></script>

    <!-- Contact Form JavaScript -->
    <script src="js/jqBootstrapValidation.js"></script>
    <script src="js/contact_me.js"></script>

    <!-- Custom Theme JavaScript -->
    <script src="js/agency.js"></script>

</body>

</html>
