<!DOCTYPE html>
<html lang="en">

<head>

    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="MLG 2019, 15th International Workshop on Mining and Learning with Graphs, co-located with KDD 2019, London, United Kingdom">
    <meta name="author" content="Shobeir Fakhraei">

    <title>MLG 2019 - 15th International Workshop on Mining and Learning with Graphs</title>

    <!-- Bootstrap Core CSS -->
    <link href="css/bootstrap.min.css" rel="stylesheet">

    <!-- Custom CSS -->
    <link href="css/agency.css" rel="stylesheet">

    <!-- Custom Fonts -->
    <link href="font-awesome/css/font-awesome.min.css" rel="stylesheet" type="text/css">
    <link href="https://fonts.googleapis.com/css?family=Montserrat:400,700" rel="stylesheet" type="text/css">
    <link href='https://fonts.googleapis.com/css?family=Kaushan+Script' rel='stylesheet' type='text/css'>
    <link href='https://fonts.googleapis.com/css?family=Droid+Serif:400,700,400italic,700italic' rel='stylesheet' type='text/css'>
    <link href='https://fonts.googleapis.com/css?family=Roboto+Slab:400,100,300,700' rel='stylesheet' type='text/css'>

    <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
        <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
    <![endif]-->

    <style type="text/css">
    .tg  {border-collapse:collapse;border-spacing:0; width: 520px}
    .tg td{font-family:Arial, sans-serif;font-size:14px;padding:12px 12px;border-style:solid;border-width:0px;overflow:hidden;word-break:normal;border-top-width:1px;border-bottom-width:1px;}
    .tg th{font-family:Arial, sans-serif;font-size:14px;font-weight:normal;padding:12px 12px;border-style:solid;border-width:0px;overflow:hidden;word-break:normal;border-top-width:1px;border-bottom-width:1px;}
    .tg .tg-lqy6{text-align:right;vertical-align:top; width: 100px}
    .tg .tg-odj0{font-weight:bold;background-color:#ffcb2f;vertical-align:top}
    .tg .tg-yw4l{vertical-align:top}
    .tg .tg-l2oz{font-weight:bold;text-align:right;vertical-align:top}
    .tg .tg-9hbo{font-weight:bold;vertical-align:top}
    .tg .tg-xr8r{background-color:#ffffc7;text-align:right;vertical-align:top; width: 100px}
    .tg .tg-kjho{background-color:#ffffc7;vertical-align:top}
    </style>


</head>

<body id="page-top" class="index">
    <!-- Google Analytics -->
    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-75238067-1', 'auto');
      ga('require', 'linkid');
      ga('send', 'pageview');

    </script>

    <!-- Navigation -->
    <nav class="navbar navbar-default navbar-fixed-top">
        <div class="container">
            <!-- Brand and toggle get grouped for better mobile display -->
            <div class="navbar-header page-scroll">
                <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1">
                    <span class="sr-only">Toggle navigation</span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                </button>
                <a class="navbar-brand page-scroll" href="#page-top"><img src="img/mlg-logo.gif" style="margin:0px; padding:0px; height:30px"/></a>
            </div>

            <!-- Collect the nav links, forms, and other content for toggling -->
            <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
                <ul class="nav navbar-nav navbar-right">
                    <li class="hidden">
                        <a href="#page-top"></a>
                    </li>
                    <li>
                        <a class="page-scroll" href="#introduction">Intro</a>
                    </li>
                    <li>
                        <a class="page-scroll" href="#program">Schedule</a>
                    </li>
                    <li>
                        <a class="page-scroll" href="#keynote">Keynotes</a>
                    </li>
                    <li>
                        <a class="page-scroll" href="#papers">Accepted Papers</a>
                    </li>
                    <li>
                        <a class="page-scroll" href="#call">CFP</a>
                    </li>
                    <li>
                        <a class="page-scroll" href="#dates">Dates</a>
                    </li>
                    <li>
                        <a class="page-scroll" href="#organization">Organization</a>
                    </li>
                    <li>
                        <a class="page-scroll" href="#history">History</a>
                    </li>
                    <li>
                      <a href="https://twitter.com/mlgworkshop" target=_blank><i class="fa fa-twitter" style="font-size:20px;"></i></a>
                    </li>
                </ul>
            </div>
            <!-- /.navbar-collapse -->
        </div>
        <!-- /.container-fluid -->
    </nav>

    <!-- Header -->
    <header>
        <div class="container">
            <div class="intro-text">
                <div class="intro-lead-in">Held in conjunction with <a href="http://www.kdd.org/kdd2019/" target=_blank>KDD'19</a></br>
                Aug 5, 2019 - Anchorage, Alaska</div>
                <div class="intro-heading">15th International Workshop on<br/>Mining and Learning with Graphs</div>
                <a href="http://www.mlgworkshop.org/2020/" target=_blank class="page-scroll btn btn-xl">Join us at MLG2020</a>
            </div>
        </div>
    </header>

    <!-- Introduction Section -->
    <section id="introduction"> <!--class="bg-mid-gray"-->
        <div class="container">
            <div class="row">
                <div class="col-lg-8 text-center">
                    <h2 class="section-heading">Introduction</h2>
                    <!--h3 class="section-subheading text-muted">Lorem ipsum dolor sit amet consectetur.</h3-->
                </div>
            </div>
            <div class="row text-justify">

                <div class="col-md-8">
                    <p class="large text-muted">
                      There is a great deal of interest in analyzing data that is best represented as a graph. Examples include the WWW, social networks, biological networks, communication networks, transportation networks, energy grids, and many others. These graphs are typically multi-modal, multi-relational and dynamic. In the era of big data, the importance of being able to effectively mine and learn from such data is growing, as more and more structured and semi-structured data is becoming available. The workshop serves as a forum for researchers from a variety of fields working on mining and learning from graphs to share and discuss their latest findings.
                      <br/>
                      There are many challenges involved in effectively mining and learning from this kind of data, including:
                    </p>
                      <ul class="large text-muted">
                          <li>Understanding the different techniques applicable, including graph mining algorithms, network embeddings, graphical models, latent variable models, matrix factorization methods and more.</li>
                          <li>Dealing with the heterogeneity of the data.</li>
                          <li>The common need for information integration and alignment.</li>
                          <li>Handling dynamic and changing data.</li>
                          <li>Addressing each of these issues at scale.</li>
                      </ul>
                    <p class="large text-muted">
                      Traditionally, a number of subareas have contributed to this space: communities in graph mining, learning from structured data, statistical relational learning, inductive logic programming, and, moving beyond subdisciplines in computer science, social network analysis, and, more broadly network science.
                    </p>
                </div>


                <div class="col-md-4 text-right">
                     <p class="large text-muted">
                        <a href="https://twitter.com/mlgworkshop?ref_src=twsrc%5Etfw" class="twitter-follow-button" data-show-count="false">Follow @mlgworkshop</a>
                        <a class="twitter-timeline" data-lang="en" data-height="600" data-chrome="nofooter; noheader; transparent" data-link-color="#FAB81E" href="https://twitter.com/mlgworkshop?ref_src=twsrc%5Etfw"></a><script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
                      </p>
                </div>

            </div>
        </div>
    </section>

    <!-- Program Section -->
    <section id="program" class="bg-mid-gray">
        <div class="container">
            <div class="row">
                <div class="col-lg-12 text-center">
                    <h2 class="section-heading">Schedule</h2>
                    <h3 class="section-subheading text-muted"><strong>TBD</strong><br/><br/>
                    All accepted papers will be presented in the poster session.<br/> 
                    Based on scheduling constraints, some papers are selected as contributed talks or spotlight presentations.<br/> 
                    <!-- The contributed talks will be 15 min presentations including Q&amp;A, and spotlight presentations will be 90 seconds (1 slide).<br/> -->
                    </h3>
                </div>
            </div>



            <div class="row">
              <div class="col-lg-6 text-left">
                <table class="tg">
                <tr>
                    <th class="tg-odj0"></th><th class="tg-odj0">Morning Sessions</th>
                </tr>
                <tr>
                  <th class="tg-lqy6">8:45 am</th><th class="tg-yw4l">Opening Remarks &amp; Best Paper Announcement</th>
                </tr>
                <tr>
                  <td class="tg-l2oz">8:55 am<br/>
                  <img src="img/speakers/getoor.jpeg" class="img-responsive img-circle" style="height:50px; float: right;">
                  </td>
                  <td class="tg-9hbo"><a class="page-scroll" href="#keynote">Keynote 1</a><br/>
                    Lise Getoor<br/>
                    The Power of Relational Learning
                  </td>
                </tr>
                <tr>
                  <td class="tg-xr8r">9:30 am</td><td class="tg-kjho">Coffee Break</td>
                </tr>

                <tr>
                  <td class="tg-lqy6">10:00 am<br/></td>
                  <td class="tg-yw4l">Contributed Talk</br>
                  Improving Robustness to Attacks Against Vertex Classification
                  </td>
                </tr>
                <tr>
                  <td class="tg-lqy6">10:15 am<br/></td>
                  <td class="tg-yw4l">Contributed Talk</br>
                  Node Embedding via Adaptive Similarities
                  </td>
                </tr>
                <tr>
                  <td class="tg-l2oz">10:30 am<br/>
                  <img src="img/speakers/benson.jpg" class="img-responsive img-circle" style="height:50px; float: right;">
                  </td>
                  <td class="tg-9hbo"><a class="page-scroll" href="#keynote">Keynote 2</a><br/>
                    Austin Benson<br/>
                    Higher-order Link Prediction
                  </td>
                </tr>
                <tr style="background-color:#ffffff">
                  <td class="tg-lqy6">11:05 am</td>
                  <td class="tg-yw4l">
                    Poster Spotlights<br/>
                    <!-- <a target=_blank href='slides/mlg_spotlight_talks.pdf'>[slides]</a> -->
                  </td>
                </tr>
                <tr>
                  <td class="tg-lqy6">11:40 am<br/></td>
                  <td class="tg-yw4l">Sponsors Overview</td>
                </tr>

                </tr>
                  <td class="tg-xr8r">11:55 am</td>
                  <td class="tg-kjho">Lunch Break + Poster Setup<br/></td>
                </tr>

              </table>


            </div>
            <div class="col-lg-6 text-left">
              <table class="tg">
                <tr>
                  <th class="tg-odj0"></th>
                  <th class="tg-odj0">Afternoon Sessions</th>
                </tr>

                <tr>
                  <td class="tg-l2oz">1:05 pm<br/>
                  <img src="img/speakers/adamic.png" class="img-responsive img-circle" style="height:50px; float: right;">
                  </td>
                  <td class="tg-9hbo"><a class="page-scroll" href="#keynote">Keynote 3</a><br/>
                    Lada Adamic<br/>
                    Reflections of Social Networks
                  </td>
                </tr>

                <tr>
                  <td class="tg-lqy6">1:40 pm<br/></td>
                  <td class="tg-yw4l">Contributed Talk</br>
                  Discovering Robustly Connected Subgraphs with Simple Descriptions
                  </td>
                </tr>

                <tr>
                  <td class="tg-l2oz">1:55 pm<br/>
                  <img src="img/speakers/vagelis.jpg" class="img-responsive img-circle" style="height:50px; float: right;">
                  </td>
                  <td class="tg-9hbo"><a class="page-scroll" href="#keynote">Keynote 4</a><br/>
                    Vagelis Papalexakis<br/>
                    Tensor Decompositions for Multi-aspect Graph Analytics and Beyond
                  </td>
                </tr>

                </tr>
                  <td class="tg-xr8r">2:30 pm</td>
                  <td class="tg-kjho">Coffee Break (+ Poster Session)<br/></td>
                </tr>

                <tr>
                  <td class="tg-l2oz">3:00 pm<br/>
                  <img src="img/speakers/huan.jpg" class="img-responsive img-circle" style="height:50px; float: right;">
                  </td>
                  <td class="tg-9hbo"><a class="page-scroll" href="#keynote">Keynote 5</a><br/>
                    Huan Liu<br/>
                    Big Social Media Data and Challenges for KDD
                  </td>
                </tr>

                <tr>
                  <td class="tg-lqy6">3:35 pm<br/></td>
                  <td class="tg-yw4l">Contributed Talk</br>
                  Graph-Based Recommendation with Personalized Diffusion
                  </td>
                </tr>

                <tr>
                  <th class="tg-lqy6">3:50 pm</th>
                  <th class="tg-yw4l">Closing Remarks</th>
                </tr>                

                <tr style="background-color:#ffffff">
                  <td class="tg-lqy6">4:00 pm</td>
                  <td class="tg-yw4l">
                    Poster Session
                  </td>
                </tr>
                </table>
              </div>

              <div class="col-lg-3 text-left">
                &nbsp;
              </div>
          </div>


        </div>
    </section>

    <!-- Keynote Section no abstract -->

    <section id="keynote" class="bg-mid">
        <div class="container">
            <div class="row">
                <div class="col-lg-12 text-center">
                    <h2 class="section-heading">Keynote Speakers</h2>
                    <!--h3 class="section-subheading text-muted">More keynotes will be announced soon!</h3-->
                </div>
            </div>
            <div class="row">

                <div class="col-md-1">
                  &nbsp;
                </div>

                <div class="col-md-2">
                    <div class="team-member">
                        <img src="img/speakers/vagelis.jpg" class="img-responsive img-circle" alt="Vagelis Papalexakis">
                        <h4>Vagelis Papalexakis</h4>
                        <p class="text-muted">Assistant Professor<br/>UC Riverside</p>
                          <ul class="list-inline social-buttons-team">
                              <li><a target=_blank href="https://www.cs.ucr.edu/~epapalex/"><i class="fa fa-home"></i></a>
                              </li>
                              <li><a target=_blank href="https://twitter.com/vagelispapalex?lang=en"><i class="fa fa-twitter"></i></a>
                              </li>
                              <li><a target=_blank href="https://www.linkedin.com/in/vagelispapalexakis"><i class="fa fa-linkedin"></i></a>
                              </li>
                              <li><a target=_blank href="https://scholar.google.com/citations?user=2P1kinAAAAAJ&hl=en"><i class="fa fa-graduation-cap"></i></a>
                              </li>
                          </ul>
                    </div>
                </div>

                <div class="col-md-2">
                    <div class="team-member">
                        <img src="img/speakers/adamic.png" class="img-responsive img-circle" alt="Lada Adamic">
                        <h4>Lada Adamic</h4>
                        <p class="text-muted">Computational Social Scientist<br/>Facebook</p>
                          <ul class="list-inline social-buttons-team">
                              <li><a target=_blank href="http://www.ladamic.com/"><i class="fa fa-home"></i></a>
                              </li>
                              <li><a target=_blank href="https://twitter.com/ladamic?lang=en"><i class="fa fa-twitter"></i></a>
                              </li>
                              <li><a target=_blank href="https://www.linkedin.com/in/ladamic"><i class="fa fa-linkedin"></i></a>
                              </li>
                              <li><a target=_blank href="https://scholar.google.com/citations?user=0TJZPj0AAAAJ&hl=en"><i class="fa fa-graduation-cap"></i></a>
                              </li>
                          </ul>
                    </div>
                </div>

                <div class="col-md-2">
                    <div class="team-member">
                        <img src="img/speakers/benson.jpg" class="img-responsive img-circle" alt="Austin Benson">
                        <h4>Austin Benson</h4>
                        <p class="text-muted">Assistant Professor<br/>Cornell</p>
                          <ul class="list-inline social-buttons-team">
                              <li><a target=_blank href="https://www.cs.cornell.edu/~arb/"><i class="fa fa-home"></i></a>
                              </li>
                              <li><a target=_blank href="https://twitter.com/austinbenson?lang=en"><i class="fa fa-twitter"></i></a>
                              </li>
                              <li><a target=_blank href="https://www.linkedin.com/in/austin-benson-ab122822"><i class="fa fa-linkedin"></i></a>
                              </li>
                              <li><a target=_blank href="https://scholar.google.com/citations?user=BzOqNoQAAAAJ&hl=en"><i class="fa fa-graduation-cap"></i></a>
                              </li>
                          </ul>
                    </div>
                </div>

                <div class="col-md-2">
                    <div class="team-member">
                        <img src="img/speakers/huan.jpg" class="img-responsive img-circle" alt="Huan Liu">
                        <h4>Huan Liu</h4>
                        <p class="text-muted">Professor<br/>Arizona State University</p>
                          <ul class="list-inline social-buttons-team">
                              <li><a target=_blank href="http://www.public.asu.edu/~huanliu/"><i class="fa fa-home"></i></a>
                              </li>
                              <li><a target=_blank href="https://twitter.com/liuhuan?lang=en"><i class="fa fa-twitter"></i></a>
                              </li>
                              <li><a target=_blank href="https://www.linkedin.com/in/huan-liu-96ab172"><i class="fa fa-linkedin"></i></a>
                              </li>
                              <li><a target=_blank href="https://scholar.google.com/citations?user=Dzf46C8AAAAJ&hl=en"><i class="fa fa-graduation-cap"></i></a>
                              </li>
                          </ul>
                    </div>
                </div>

                <div class="col-md-2">
                    <div class="team-member">
                        <img src="img/speakers/getoor.jpeg" class="img-responsive img-circle" alt="Lise Getoor">
                        <h4>Lise Getoor</h4>
                        <p class="text-muted">Professor<br/>UC Santa Cruz</p>
                          <ul class="list-inline social-buttons-team">
                              <li><a target=_blank href="https://getoor.soe.ucsc.edu/home"><i class="fa fa-home"></i></a>
                              </li>
                              <li><a target=_blank href="https://twitter.com/lgetoor?lang=en"><i class="fa fa-twitter"></i></a>
                              </li>
                              <li><a class="inactive" href="#organization"><i class="fa fa-linkedin"></i></a>
                              </li>
                              <li><a target=_blank href="https://scholar.google.com/citations?user=Y8-xGncAAAAJ&hl=en"><i class="fa fa-graduation-cap"></i></a>
                              </li>
                          </ul>
                    </div>
                </div>

                <div class="col-md-1">
                  &nbsp;
                </div>


            </div>
        </div>
    </section>

    <!-- Accepted Papers Section -->
        <section id="papers" class="bg-mid-gray">
        <div class="container">
            <div class="row">
                <div class="col-lg-12 text-center">
                    <h2 class="section-heading">Accepted Papers</h2>
                    <h3 class="section-subheading text-muted">
                    All accepted papers will present a poster, spotlights and talks are marked with   
                    <button class="btn btn-primary btn-xs">S</button> and   
                    <button class="btn btn-primary btn-xs">T</button>
                    </h3>
                </div>
            </div>
            <div class="row">

            <div class="col-lg-1 text-center">
                &nbsp;
            </div>

            <div class="col-lg-11 text-justify">
                  <!-- Begin Paper List -->

<p class="large text-muted">
<strong>The Sparse + Low Rank trick for Matrix Factorization-Based Graph Algorithms</strong>
<button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#pid1">Abstract</button>
<button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#bib1">BibTex</button>
<a href="papers/MLG2019_paper_1.pdf" target=_blank class="btn btn-primary btn-xs" role="button">PDF</a>
<button class="btn btn-primary btn-xs">S</button>
<br/>
<i>Nathan De Lara</i><br/>
<div id="pid1" class="collapse">
<strong>Abstract:</strong>Matrix factorization is a central block in many graph algorithms for embedding, clustering and many other tasks. This block is usually the computational bottleneck of these algorithms and a naive implementation can prevent them from scaling to large datasets. However, the matrices to factorize often have a closed-form "sparse~+~low rank" structure. In this paper, we show how to adapt state-of-the-art matrix factorization techniques to this class of matrices. We demonstrate that the method is highly competitive with respect to the naive implementation and that it comes at a very small extra cost compared to the decomposition of the sparse component alone.

<hr/>
</div>
<div id="bib1" class="collapse">
@inproceedings{mlg2019_1,<br/>
title={The Sparse + Low Rank trick for Matrix Factorization-Based Graph Algorithms},<br/>
author={Nathan De Lara},<br/>
booktitle={Proceedings of the 15th International Workshop on Mining and Learning with Graphs (MLG)},<br/>
year={2019}<br/>
}
<hr/>
</div>
</p>
<p class="large text-muted">
<strong>Deep Reinforcement Learning-based Approach to Tackle Competitive Influence Maximization</strong>
<button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#pid3">Abstract</button>
<button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#bib3">BibTex</button>
<a href="papers/MLG2019_paper_3.pdf" target=_blank class="btn btn-primary btn-xs" role="button">PDF</a>
<button class="btn btn-primary btn-xs">S</button>
<br/>
<i>Tzu-Yuan Chung, Khurshed Ali and Chih-Yu Wang</i><br/>
<div id="pid3" class="collapse">
<strong>Abstract:</strong>Competitive Influence Maximization (CIM) problem studies the competition among multiple parties where each party aims to maximize their profit while competing against other parties. Recently, Reinforcement-Learning based models have been proposed to address the CIM problem. However, such models are unscalable and incapable of handling changes in the network structure. Motivated by the recent success of Deep Reinforcement Learning models and their capability to handle complex problems, we propose a novel Deep Reinforcement learning based framework (DRIM) to address the multi-round competitive influence maximization problem. DRIM framework considers the community structure of the social network for budget allocation and feature extraction with deep Q network in order to reduce the computational time of seed selection. The proposed framework employs the quota-based ϵ-greedy policy to explore the optimality of influence maximization strategies and budget allocation for each community. Experimental results show that the proposed DRIM framework performs better than the state-of-art algorithms to tackle the multi-round CIM problem.

<hr/>
</div>
<div id="bib3" class="collapse">
@inproceedings{mlg2019_3,<br/>
title={Deep Reinforcement Learning-based Approach to Tackle Competitive Influence Maximization},<br/>
author={Tzu-Yuan Chung, Khurshed Ali and Chih-Yu Wang},<br/>
booktitle={Proceedings of the 15th International Workshop on Mining and Learning with Graphs (MLG)},<br/>
year={2019}<br/>
}
<hr/>
</div>
</p>
<p class="large text-muted">
<strong>Opinion Dynamics with Backfire Effect and Biased Assimilation</strong>
<button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#pid4">Abstract</button>
<button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#bib4">BibTex</button>
<a href="papers/MLG2019_paper_4.pdf" target=_blank class="btn btn-primary btn-xs" role="button">PDF</a>
<button class="btn btn-primary btn-xs">S</button>
<br/>
<i>Xi Chen, Panayiotis Tsaparas, Jefrey Lijffijt and Tijl De Bie</i><br/>
<div id="pid4" class="collapse">
<strong>Abstract:</strong>The democratization of AI tools for content generation, combined with unrestricted access to mass media for all (e.g. through microblogging and social media), makes it increasingly hard for people to distinguish fact from fiction. This raises the question of how individual opinions evolve in such a networked environment without grounding in a known reality. The dominant approach to studying this problem uses simple models from the social sciences on how individuals change their opinions when exposed to their social neighborhood, and applies them on large social networks.

We propose a novel model that incorporates two known social phenomena: (i) Biased Assimilation: the tendency of individuals to adopt other opinions if they are similar to their own; (ii) Backfire Effect: the fact that an opposite opinion may further entrench someone in their stance, making their opinion more extreme instead of moderating it. To the best of our knowledge this is the first DeGroot-type opinion formation model that captures the Backfire Effect. A thorough theoretical and empirical analysis of the proposed model reveals intuitive conditions for polarization and consensus to exist, as well as the properties of the resulting opinions.

<hr/>
</div>
<div id="bib4" class="collapse">
@inproceedings{mlg2019_4,<br/>
title={Opinion Dynamics with Backfire Effect and Biased Assimilation},<br/>
author={Xi Chen, Panayiotis Tsaparas, Jefrey Lijffijt and Tijl De Bie},<br/>
booktitle={Proceedings of the 15th International Workshop on Mining and Learning with Graphs (MLG)},<br/>
year={2019}<br/>
}
<hr/>
</div>
</p>
<p class="large text-muted">
<strong>Analysis of Core and Truss Decompositions on Real-World Networks</strong>
<button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#pid5">Abstract</button>
<button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#bib5">BibTex</button>
<a href="papers/MLG2019_paper_5.pdf" target=_blank class="btn btn-primary btn-xs" role="button">PDF</a>
<button class="btn btn-primary btn-xs">S</button>
<br/>
<i>Penghang Liu and A. Erdem Sarıyüce</i><br/>
<div id="pid5" class="collapse">
<strong>Abstract:</strong>Finding the dense region in a graph is a crucial problem in network analysis. Core decomposition and truss decomposition address this problem from two different perspectives. The core decomposition is a vertex-driven approach that gives each vertex a core number based on the degree, while the truss decomposition is an edge- driven approach that gives each edge a truss number based on the triangles count. Some previous works explored the common patterns in real-world networks through a vertex-driven approach. Our ongoing research aims to explore the pervasive patterns and anomalies in real-world networks from both the vertex and edge perspective. We introduce an analysis of truss decomposition and its relation to core decomposition in various types of real-world networks. We first investigate the characteristics of the core and truss degeneracy of real-world networks as well as random graphs and check how the clique counts relate to those properties. Then we analyze the interplay between core and truss decomposition by checking the truss numbers (and triangle counts) of edges with respect to the core numbers (and degrees) of their end points.

<hr/>
</div>
<div id="bib5" class="collapse">
@inproceedings{mlg2019_5,<br/>
title={Analysis of Core and Truss Decompositions on Real-World Networks},<br/>
author={Penghang Liu and A. Erdem Sarıyüce},<br/>
booktitle={Proceedings of the 15th International Workshop on Mining and Learning with Graphs (MLG)},<br/>
year={2019}<br/>
}
<hr/>
</div>
</p>
<p class="large text-muted">
<strong>Image classification using topological features automatically extracted from graph representation of images</strong>
<button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#pid7">Abstract</button>
<button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#bib7">BibTex</button>
<a href="papers/MLG2019_paper_7.pdf" target=_blank class="btn btn-primary btn-xs" role="button">PDF</a>
<button class="btn btn-primary btn-xs">S</button>
<br/>
<i>Liping Yang, Diane Oyen and Brendt Wohlberg</i><br/>
<div id="pid7" class="collapse">
<strong>Abstract:</strong>The performance of machine learning methods is strongly dependent on the data representation (features) to which they are applied. For drawings in particular, we cannot rely on texture, color or shading information; there is little information present in a drawing beyond the spatial relationships and topology. A topological graph is an intuitive and powerful data structure and data representation framework that can capture the topological relations and spatial arrangement among entities present in images. In this paper, we use topological features automatically extracted from graph representations of images for image classification. Our approach is simple, intuitive, and generic. We compare our method against a traditional feature descriptor, histogram of oriented gradients (HOG) on the MNIST data set. The results demonstrate the effectiveness of our graph approach, especially when applied to small sets of training data. In addition, our method is very fast to train, and also much less sensitive to hyperparameters, requiring little hyperparameter fine tuning.

<hr/>
</div>
<div id="bib7" class="collapse">
@inproceedings{mlg2019_7,<br/>
title={Image classification using topological features automatically extracted from graph representation of images},<br/>
author={Liping Yang, Diane Oyen and Brendt Wohlberg},<br/>
booktitle={Proceedings of the 15th International Workshop on Mining and Learning with Graphs (MLG)},<br/>
year={2019}<br/>
}
<hr/>
</div>
</p>
<p class="large text-muted">
<strong>A Time-Aware Inductive Representation Learning Strategy for Heterogeneous Graphs</strong>
<button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#pid9">Abstract</button>
<button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#bib9">BibTex</button>
<a href="papers/MLG2019_paper_9.pdf" target=_blank class="btn btn-primary btn-xs" role="button">PDF</a>
<button class="btn btn-primary btn-xs">S</button>
<br/>
<i>Bo Yan, Matthew Walker and Krzysztof Janowicz</i><br/>
<div id="pid9" class="collapse">
<strong>Abstract:</strong>Graphs are versatile data structures that have permeated a large number of application fields, such as biochemistry, knowledge graphs, and social networks. As a result, different graph representation learning models have been proposed as effective approaches to represent graph components in downstream machine learning tasks, such as node classification and recommendation. However, most representation learning models in graphs do not natively work on heterogeneous graphs and consequently are not able to learn embeddings for different relations in the graph. In this paper, we extend and improve existing models by enabling an edge-based transformation procedure in order to learn embeddings for different relations in heterogeneous graphs. In addition, we show that by incorporating a sequential model to learn more expressive representations, temporal dynamics in social networks can be captured. Finally, we examine our model within the context of two very disparate heterogeneous graphs, a knowledge graph dataset and a professional social network dataset, to illustrate our point and show the effectiveness of our approach. By learning edge-based transformations, our model yields a Mean Reciprocal Rank score that is more than 4 times higher than the homogeneous counterpart for the knowledge graph dataset. By incorporating the temporal dynamics, our model improves the HITS@1 score by more than 15% compared with the baseline model for the professional social network dataset.

<hr/>
</div>
<div id="bib9" class="collapse">
@inproceedings{mlg2019_9,<br/>
title={A Time-Aware Inductive Representation Learning Strategy for Heterogeneous Graphs},<br/>
author={Bo Yan, Matthew Walker and Krzysztof Janowicz},<br/>
booktitle={Proceedings of the 15th International Workshop on Mining and Learning with Graphs (MLG)},<br/>
year={2019}<br/>
}
<hr/>
</div>
</p>
<p class="large text-muted">
<strong>When to Remember Where You Came from: Node Representation Learning in Higher-order Networks</strong>
<button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#pid10">Abstract</button>
<button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#bib10">BibTex</button>
<a href="papers/MLG2019_paper_10.pdf" target=_blank class="btn btn-primary btn-xs" role="button">PDF</a>
<button class="btn btn-primary btn-xs">S</button>
<br/>
<i>Caleb Belth, Fahad Kamran, Donna Tjandra and Danai Koutra</i><br/>
<div id="pid10" class="collapse">
<strong>Abstract:</strong>For trajectory data (e.g., flight itineraries) that tend to have beyond first-order (i.e., non-Markovian) dependencies, higher-order networks have been shown to accurately capture details lost with a standard (aggregate) network representation. 
At the same time, representation learning has shown success on a wide range of network tasks, removing the need to hand-craft features for these tasks. 
In this work, we propose a node representation learning framework called EVO or Embedding Variable Orders, which captures non-Markovian dependencies by combining work on higher-order networks with work on node embeddings. We show that EVO outperforms baselines in tasks where high-order dependencies are likely to matter, demonstrating the benefits of considering high-order dependencies in node embeddings. We also provide insights into when it does or does not help to capture these dependencies. To the best of our knowledge, this is the first work on representation learning for higher-order networks.

<hr/>
</div>
<div id="bib10" class="collapse">
@inproceedings{mlg2019_10,<br/>
title={When to Remember Where You Came from: Node Representation Learning in Higher-order Networks},<br/>
author={Caleb Belth, Fahad Kamran, Donna Tjandra and Danai Koutra},<br/>
booktitle={Proceedings of the 15th International Workshop on Mining and Learning with Graphs (MLG)},<br/>
year={2019}<br/>
}
<hr/>
</div>
</p>
<p class="large text-muted">
<strong>GroupINN: Grouping-based Interpretable Neural Network for Classification of Limited, Noisy Brain Data</strong>
<button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#pid12">Abstract</button>
<button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#bib12">BibTex</button>
<a href="papers/MLG2019_paper_12.pdf" target=_blank class="btn btn-primary btn-xs" role="button">PDF</a>
<button class="btn btn-primary btn-xs">S</button>
<br/>
<i>Yujun Yan, Jiong Zhu, Marlena Duda, Eric Solarz, Chandra Sripada and Danai Koutra</i><br/>
<div id="pid12" class="collapse">
<strong>Abstract:</strong>Mapping the human brain, or understanding how certain brain regions relate to specific aspects of cognition, has been and remains an active area of neuroscience research. Functional magnetic resonance imaging (fMRI) data—in the form of images, time series or graphs—are central in this research, but pose many challenges
in phenotype prediction tasks (e.g., noisy, small training samples). Standardly employed handcrafted models and newly proposed neural network methods pose limitations in the expressive power and interpretability, respectively, in this context.
In this work, focusing on functional graphs, a modality that partially handles some challenges of fMRI data, we propose a grouping-based interpretable neural network model, GroupINN, that effectively classifies cognitive performance from noisy fRMI-derived brain networks with 85% fewer model parameters than baseline deep models, while also identifying the most predictive brain sub-networks within several task-specific contexts. Our method incorporates the idea of node grouping into the design of the neural network. That way, unlike other methods that employ clustering as a pre-processing step to reorder nodes, GroupINN learns the node grouping and extracts graph features jointly. Experiments on task-based fMRI datasets show that our method is 2.6−69× faster than other neural network-based methods, while achieving comparable or better accuracy and providing interpretability.
<hr/>
</div>
<div id="bib12" class="collapse">
@inproceedings{mlg2019_12,<br/>
title={GroupINN: Grouping-based Interpretable Neural Network for Classification of Limited, Noisy Brain Data},<br/>
author={Yujun Yan, Jiong Zhu, Marlena Duda, Eric Solarz, Chandra Sripada and Danai Koutra},<br/>
booktitle={Proceedings of the 15th International Workshop on Mining and Learning with Graphs (MLG)},<br/>
year={2019}<br/>
}
<hr/>
</div>
</p>
<p class="large text-muted">
<strong>The Boundary Coefficient: a Vertex Measure for Visualizing and Finding Structure in Weighted Graphs</strong>
<button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#pid13">Abstract</button>
<button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#bib13">BibTex</button>
<a href="papers/MLG2019_paper_13.pdf" target=_blank class="btn btn-primary btn-xs" role="button">PDF</a>
<button class="btn btn-primary btn-xs">S</button>
<br/>
<i>Robin Vandaele, Yvan Saeys and Tijl De Bie</i><br/>
<div id="pid13" class="collapse">
<strong>Abstract:</strong>Graphs have emerged as powerful representations of data, from obvious examples such as social networks, to proximity graphs of high-dimensional metric data. Many of such real-world data sets share a common property: they have a well-hidden and much simpler graph-structured core, from which all data points emerge. Uncovering these core structures, in this paper termed backbones, often offers great insight into these data sets. However, standard methods for identifying these are computationally inefficient, sensitive to outliers, and lead to topological bias, prioritizing low-weight edges in dense regions, instead of spreading out smoothly across the topology underlying the graph. Furthermore, for high-dimensional metric data, standard methods for dimensionality reduction often fail to reveal the hidden topology. We resolve these issues by introducing the boundary coefficient (BC), a powerful vertex measure for locating core structure in data sets with an underlying graph-structured topology. Combining the BC with the newly proposed concept of f-pines, we propose a generally applicable method for revealing these structures in such data. We evaluate our method on a number of artificial and real-life data sets, demonstrating its wide range of applicability, superior effectiveness, robustness against noise, and scalability.

<hr/>
</div>
<div id="bib13" class="collapse">
@inproceedings{mlg2019_13,<br/>
title={The Boundary Coefficient: a Vertex Measure for Visualizing and Finding Structure in Weighted Graphs},<br/>
author={Robin Vandaele, Yvan Saeys and Tijl De Bie},<br/>
booktitle={Proceedings of the 15th International Workshop on Mining and Learning with Graphs (MLG)},<br/>
year={2019}<br/>
}
<hr/>
</div>
</p>
<p class="large text-muted">
<strong>Sensor Fusion and Structured Prediction for Cyberattack Event Networks</strong>
<button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#pid14">Abstract</button>
<button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#bib14">BibTex</button>
<a href="papers/MLG2019_paper_14.pdf" target=_blank class="btn btn-primary btn-xs" role="button">PDF</a>
<button class="btn btn-primary btn-xs">S</button>
<br/>
<i>Alex Memory and Graham Mueller</i><br/>
<div id="pid14" class="collapse">
<strong>Abstract:</strong>Early detection of cyberattacks – such as data breaches or ransomware – is critical to mitigate their effects. Despite advances in automated cyberattack sensors, many attacks are still detected many days or months after they occur. We propose a new approach using statistical relational learning to fuse cyberattack sensor outputs and generate attack predictions. Leveraging the graphical structures of both sensor outputs and cyberattack events themselves, we achieve higher accuracy than individual sensors by reasoning collectively over both sensors and attacks. Our predictions also are more useful to analysts because they are structured objects containing details of the predicted attacks. We conduct an extensive empirical evaluation of our approach using a database of real cyberattacks against a US corporation. We show that, relative to a sensors-only baseline, our approach increases accuracy by up to seven percent and doubles the lift of high-confidence predictions.

<hr/>
</div>
<div id="bib14" class="collapse">
@inproceedings{mlg2019_14,<br/>
title={Sensor Fusion and Structured Prediction for Cyberattack Event Networks},<br/>
author={Alex Memory and Graham Mueller},<br/>
booktitle={Proceedings of the 15th International Workshop on Mining and Learning with Graphs (MLG)},<br/>
year={2019}<br/>
}
<hr/>
</div>
</p>
<p class="large text-muted">
<strong>Unsupervised Construction of Knowledge Graphs From Text and Code</strong>
<button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#pid16">Abstract</button>
<button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#bib16">BibTex</button>
<a href="papers/MLG2019_paper_16.pdf" target=_blank class="btn btn-primary btn-xs" role="button">PDF</a>
<button class="btn btn-primary btn-xs">S</button>
<br/>
<i>Kun Cao and James Fairbanks</i><br/>
<div id="pid16" class="collapse">
<strong>Abstract:</strong>The scientific literature is a rich source of information for data mining with conceptual knowledge graphs; the open science movement has enriched this literature with complementary source code that implements scientific models.
To exploit this new resource, we construct a knowledge graph using unsupervised learning methods to identify conceptual entities. We associate source code entities to these natural language concepts using word embedding and clustering techniques. 
Practical naming conventions for methods and functions tend to reflect the concept they implement. We take advantage of this specificity by presenting a novel process for joint clustering text concepts that combines word-embeddings, nonlinear dimensionality reduction, and clustering techniques
to assist in understanding, organizing, and comparing software in the open science ecosystem. With our pipeline, we aim to assist scientists in building on existing models in their discipline when making novel models for new phenomena. By combining source code and conceptual information, our knowledge graph enhances corpus-wide understanding of scientific literature.

<hr/>
</div>
<div id="bib16" class="collapse">
@inproceedings{mlg2019_16,<br/>
title={Unsupervised Construction of Knowledge Graphs From Text and Code},<br/>
author={Kun Cao and James Fairbanks},<br/>
booktitle={Proceedings of the 15th International Workshop on Mining and Learning with Graphs (MLG)},<br/>
year={2019}<br/>
}
<hr/>
</div>
</p>
<p class="large text-muted">
<strong>Temporal Link Prediction in Dynamic Networks</strong>
<button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#pid22">Abstract</button>
<button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#bib22">BibTex</button>
<a href="papers/MLG2019_paper_22.pdf" target=_blank class="btn btn-primary btn-xs" role="button">PDF</a>
<button class="btn btn-primary btn-xs">S</button>
<br/>
<i>Hemant Kasat, Sanket Markan, Manish Gupta and Vikram Pudi</i><br/>
<div id="pid22" class="collapse">
<strong>Abstract:</strong>Link Prediction is an important task for evolutionary analysis of dynamic networks, where the goal is to predict links over time based on sequence of previous graph snapshots. Given a sequence of previous snapshots, we propose a temporal link function, SiameseLSTM, to predict probability of link formation for any pair of nodes in near future. We assume that nodes lie in a temporal latent space, gradually move as the network evolves over time and co-evolve with their neighbors in near future. The proposed model uses LSTM to project the temporal latent space embeddings of nodes to a hidden state latent space optimized for the downstream link prediction task. We use a Siamese adaption of LSTM for the hidden state embeddings to follow Structural Homophily : two nodes which are close to each other in the latent space interact with one another more frequently than two faraway nodes.
We empirically show that our model outperforms state of the art algorithms for link prediction when evaluated on real world dynamic networks. We also show how varying number of previous snapshots used to exploit historical information affects the performance of the model to predict future links.

<hr/>
</div>
<div id="bib22" class="collapse">
@inproceedings{mlg2019_22,<br/>
title={Temporal Link Prediction in Dynamic Networks},<br/>
author={Hemant Kasat, Sanket Markan, Manish Gupta and Vikram Pudi},<br/>
booktitle={Proceedings of the 15th International Workshop on Mining and Learning with Graphs (MLG)},<br/>
year={2019}<br/>
}
<hr/>
</div>
</p>
<p class="large text-muted">
<strong>Improving Robustness to Attacks Against Vertex Classification</strong>
<button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#pid23">Abstract</button>
<button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#bib23">BibTex</button>
<a href="papers/MLG2019_paper_23.pdf" target=_blank class="btn btn-primary btn-xs" role="button">PDF</a>
<button class="btn btn-primary btn-xs">T</button>
<br/>
<i>Benjamin Miller, Mustafa Çamurcu, Alexander Gomez, Kevin Chan and Tina Eliassi-Rad</i><br/>
<div id="pid23" class="collapse">
<strong>Abstract:</strong>Vertex classification—the problem of identifying the class labels of nodes in a graph—has applicability in a wide variety of domains. Examples include classifying subject areas of papers in citation networks or roles of machines in a computer network. Recent work has demonstrated that vertex classification using graph convolutional networks is susceptible to targeted poisoning attacks, in which both graph structure and node attributes can be changed in an attempt to misclassify a target node. This vulnerability decreases users’ confidence in the learning method and can prevent adoption in high-stakes contexts. This paper presents work in progress aiming to make vertex classification robust to these types of attacks.

We investigate two aspects of this problem: (1) the classification model and (2) the method for selecting training data. Our alternative classifier is a support vector machine (with a radial basis function kernel), which is applied to an augmented node feature-vector obtained by appending the node’s attributes to a Euclidean vector representing the node based on the graph structure. Our alternative methods of selecting training data are (1) to select the highest-degree nodes in each class and (2) to iteratively select the node with the most neighbors minimally connected to the training set. In the datasets on which the original attack was demonstrated, we show that changing the training set can make the network much harder to attack. To maintain a given probability of attack success, the adversary must use far more perturbations; often a factor of 2–4 over the random training baseline. Even in cases where success is relatively easy for the attacker, we show that the classification and training alternatives allow classification performance to degrade much more gradually, with weaker incorrect predictions for the attacked nodes.

<hr/>
</div>
<div id="bib23" class="collapse">
@inproceedings{mlg2019_23,<br/>
title={Improving Robustness to Attacks Against Vertex Classification},<br/>
author={Benjamin Miller, Mustafa Çamurcu, Alexander Gomez, Kevin Chan and Tina Eliassi-Rad},<br/>
booktitle={Proceedings of the 15th International Workshop on Mining and Learning with Graphs (MLG)},<br/>
year={2019}<br/>
}
<hr/>
</div>
</p>
<p class="large text-muted">
<strong>On-Device Algorithms for Public-Private Data with Absolute Privacy</strong>
<button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#pid24">Abstract</button>
<button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#bib24">BibTex</button>
<a href="papers/MLG2019_paper_24.pdf" target=_blank class="btn btn-primary btn-xs" role="button">PDF</a>
<button class="btn btn-primary btn-xs">S</button>
<br/>
<i>Alessandro Epasto, Hossein Esfandiari and Vahab Mirrokni</i><br/>
<div id="pid24" class="collapse">
<strong>Abstract:</strong>Motivated by the increasing need to preserve privacy in digital devices, we introduce the on-device public-private model of computation. 

Our motivation comes from social-network based recommender systems in which the users want to receive recommendations based on the information available on their devices, as well as the suggestions of their social contacts, without sharing such information or the social network with the central recommendation system. 

Our model allows us to solve many algorithmic problems while providing absolute (deterministic) guarantees of the privacy of on-device data and the user's social network. In fact, we ensure that the private data and private contacts are never revealed to the central system. 

Our restrictive model of computation presents several interesting algorithmic challenges because any computation based on the private information and the private social network must be performed on local devices of limited capabilities. Despite these challenges, under realistic assumptions of inter-device communication, we show several efficient algorithms for fundamental data mining and machine learning problems, ranging from k-means clustering to heavy hitters. We complement this analysis with strong impossibility results for efficient private algorithms without allowing inter-device communication. 

In our experimental evaluation, we show that our private algorithms provide results almost as accurate as those of the non-private ones while speeding up the on-device computations by orders of magnitude. 

<hr/>
</div>
<div id="bib24" class="collapse">
@inproceedings{mlg2019_24,<br/>
title={On-Device Algorithms for Public-Private Data with Absolute Privacy},<br/>
author={Alessandro Epasto, Hossein Esfandiari and Vahab Mirrokni},<br/>
booktitle={Proceedings of the 15th International Workshop on Mining and Learning with Graphs (MLG)},<br/>
year={2019}<br/>
}
<hr/>
</div>
</p>
<p class="large text-muted">
<strong>Is a Single Embedding Enough? Learning Node Representations that Capture Multiple Social Contexts</strong>
<button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#pid25">Abstract</button>
<button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#bib25">BibTex</button>
<a href="papers/MLG2019_paper_25.pdf" target=_blank class="btn btn-primary btn-xs" role="button">PDF</a>
<button class="btn btn-primary btn-xs">S</button>
<br/>
<i>Alessandro Epasto and Bryan Perozzi</i><br/>
<div id="pid25" class="collapse">
<strong>Abstract:</strong>Recent interest in graph embedding methods has focused on learning a single representation for each node in the graph. 
But can nodes really be best described by a single vector representation? 
In this work, we propose a method for learning multiple representations of the nodes in a graph (e.g., the users of a social network). 
Based on a principled decomposition of the ego-network, each representation encodes the role of the node in a different local community in which the nodes participate. 
These representations allow for improved reconstruction of the nuanced relationships that occur in the graph -- a phenomenon that we illustrate through state-of-the-art results on link prediction tasks on a variety of graphs, reducing the error by up to $90\%$. 
In addition, we show that these embeddings allow for effective visual analysis of the learned community structure.

<hr/>
</div>
<div id="bib25" class="collapse">
@inproceedings{mlg2019_25,<br/>
title={Is a Single Embedding Enough? Learning Node Representations that Capture Multiple Social Contexts},<br/>
author={Alessandro Epasto and Bryan Perozzi},<br/>
booktitle={Proceedings of the 15th International Workshop on Mining and Learning with Graphs (MLG)},<br/>
year={2019}<br/>
}
<hr/>
</div>
</p>
<p class="large text-muted">
<strong>A distributable convex approach for graph structure discovery</strong>
<button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#pid26">Abstract</button>
<button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#bib26">BibTex</button>
<a href="papers/MLG2019_paper_26.pdf" target=_blank class="btn btn-primary btn-xs" role="button">PDF</a>
<button class="btn btn-primary btn-xs">S</button>
<br/>
<i>Chao Han, Nouf Albarakati, Xi Hang Cao and Zoran Obradovic</i><br/>
<div id="pid26" class="collapse">
<strong>Abstract:</strong>Discovering the interdependent structure among variables plays a key role in knowledge discovery in many real-world applications. Given a sequence of $p$ real-valued variables, the task is to estimate the entire graph structure with $p^2$ pairwise relationships. This problem is computationally challenging since the number of unknown relationships to estimate grows quadratically with respect to the number of variables. In order to solve this problem, many methods have been proposed to cast the structure discovery as an inverse covariance estimation problem by modeling the high dimensional data using a Gaussian graphical model. They focus on how to efficiently estimate the entire precision matrix by developing more advanced optimization algorithms in a sequential manner. A number of methods are also developed to select neighborhood or perform structure learning on categorical data, which are out of this study. A tuning-insensitive approach was proposed to estimate the precision matrix of Gaussian Graphical model in a distributed manner. But it over-parametrized the problem to achieve the tuning-insensitivity. In this study, we proposed a novel framework to discover the underlying graph structure in a distributed manner with a straightforward parametrization. The idea is to decompose the structure discovery task into multiple sub-tasks, such that a column of the precision matrix is estimated in a sub-task. We also proved the distributability and the convexity of the global task. Additionally, we empirically demonstrated the effectiveness and efficiency of our proposed framework by conducting extensive experiments with comparison to a number of state-of-the-art methods on synthetic datasets. Our case study on a real-world application is also demonstrated to be reliable. The preliminary work we presented here is novel, but it is still in progress as many extensions can be developed based on the proposed distributed framework.

<hr/>
</div>
<div id="bib26" class="collapse">
@inproceedings{mlg2019_26,<br/>
title={A distributable convex approach for graph structure discovery},<br/>
author={Chao Han, Nouf Albarakati, Xi Hang Cao and Zoran Obradovic},<br/>
booktitle={Proceedings of the 15th International Workshop on Mining and Learning with Graphs (MLG)},<br/>
year={2019}<br/>
}
<hr/>
</div>
</p>
<p class="large text-muted">
<strong>Discovering Interesting Cycles in Graphs</strong>
<button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#pid27">Abstract</button>
<button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#bib27">BibTex</button>
<a href="papers/MLG2019_paper_27.pdf" target=_blank class="btn btn-primary btn-xs" role="button">PDF</a>
<button class="btn btn-primary btn-xs">S</button>
<br/>
<i>Florian Adriaens, Cigdem Aslay, Tijl De Bie, Aristides Gionis and Jefrey Lijffijt</i><br/>
<div id="pid27" class="collapse">
<strong>Abstract:</strong>Cycles in graphs often signify interesting processes. For example, cyclic trading patterns can indicate inefficiencies or economic dependencies in trade networks, cycles in food webs can identify fragile dependencies in ecosystems, and cycles in financial transaction networks can be an indication of money laundering. Identifying such interesting cycles, which can also be constrained to contain a given set of query nodes, although not extensively studied, is thus a problem of considerable importance.

In this paper, we introduce the problem of discovering interesting cycles in graphs. We first address the problem of quantifying the extent to which a given cycle is interesting for a particular analyst.
We then show that finding cycles according to this interestingness measure is related to the longest cycle and maximum mean-weight cycle problems (in the unconstrained setting) 
and to the maximum Steiner cycle and maximum mean Steiner cycle problems (in the constrained setting).

We show that the problems of finding the most interesting cycle and Steiner cycle are both NP-hard, and are NP-hard to approximate within a constant factor in the unconstrained setting, and within a factor polynomial in the input size for the constrained setting. We also show that the latter inapproximability result implies a similar result for the maximum Steiner cycle and maximum mean Steiner cycle problems. Motivated by these hardness results, we propose a number of efficient heuristic algorithms. Through extensive experiments, we verify the effectiveness of proposed methods and demonstrate their practical utility on real-world use cases.

<hr/>
</div>
<div id="bib27" class="collapse">
@inproceedings{mlg2019_27,<br/>
title={Discovering Interesting Cycles in Graphs},<br/>
author={Florian Adriaens, Cigdem Aslay, Tijl De Bie, Aristides Gionis and Jefrey Lijffijt},<br/>
booktitle={Proceedings of the 15th International Workshop on Mining and Learning with Graphs (MLG)},<br/>
year={2019}<br/>
}
<hr/>
</div>
</p>
<p class="large text-muted">
<strong>Explainable Subgraphs with Surprising Densities: A Subgroup Discovery Approach</strong>
<button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#pid28">Abstract</button>
<button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#bib28">BibTex</button>
<a href="papers/MLG2019_paper_28.pdf" target=_blank class="btn btn-primary btn-xs" role="button">PDF</a>
<button class="btn btn-primary btn-xs">S</button>
<br/>
<i>Junning Deng, Bo Kang, Jefrey Lijffijt and Tijl De Bie</i><br/>
<div id="pid28" class="collapse">
<strong>Abstract:</strong>The connectivity structure of graphs is typically related to the attributes of the nodes. In social networks for example, the probability of a friendship between any pair of people depends on a range of attributes, such as their age, residence location, workplace, and hobbies. The high-level structure of a graph can thus possibly be described well by means of patterns of the form `the subgroup of all individuals with a certain properties X are often (or rarely) friends with individuals in another subgroup defined by properties Y', in comparison to what is expected. Such rules present potentially actionable and generalizable insight into the graph.

We present a method that finds node subgroup pairs between which the edge density is interestingly high or low, using an information-theoretic definition of interestingness. Additionally, the interestingness is quantified subjectively, to contrast with prior information an analyst may have about the connectivity. This view immediately enables iterative mining of such patterns.This is the first method aimed at graph connectivity relations between different subgroups. Our method generalizes prior work on dense subgraphs induced by a subgroup description. Although this setting has been studied already, we demonstrate for this special case considerable practical advantages of our subjective interestingness measure with respect to a wide range of (objective) interestingness measures.

<hr/>
</div>
<div id="bib28" class="collapse">
@inproceedings{mlg2019_28,<br/>
title={Explainable Subgraphs with Surprising Densities: A Subgroup Discovery Approach},<br/>
author={Junning Deng, Bo Kang, Jefrey Lijffijt and Tijl De Bie},<br/>
booktitle={Proceedings of the 15th International Workshop on Mining and Learning with Graphs (MLG)},<br/>
year={2019}<br/>
}
<hr/>
</div>
</p>
<p class="large text-muted">
<strong>MixHop: Higher-Order Graph Convolutional Architecturesvia Sparsified Neighborhood Mixing</strong>
<button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#pid29">Abstract</button>
<button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#bib29">BibTex</button>
<a href="papers/MLG2019_paper_29.pdf" target=_blank class="btn btn-primary btn-xs" role="button">PDF</a>
<button class="btn btn-primary btn-xs">S</button>
<br/>
<i>Amol Kapoor, Sami Abu-El-Haija, Bryan Perozzi, Aram Galstyan, Greg Ver Steeg, Hrayr Harutyunyan, Kristina Lerman and Nazanin Alipourfard</i><br/>
<div id="pid29" class="collapse">
<strong>Abstract:</strong>Existing popular methods for semi-supervisedlearning with Graph Neural Networks (such as theGraph Convolutional Network) provably cannotlearn a general class of neighborhood mixing rela-tionships. To address this weakness, we propose anew model, MixHop, that can learn these relation-ships, including difference operators, by repeat-edly mixing feature representations of neighborsat various distances. MixHop requires no addi-tional memory or computational complexity, andoutperforms on challenging baselines. In addition,we propose sparsity regularization that allows usto visualize how the network prioritizes neighbor-hood information across different graph datasets.Our analysis of the learned architectures revealsthat neighborhood mixing varies per datasets.

<hr/>
</div>
<div id="bib29" class="collapse">
@inproceedings{mlg2019_29,<br/>
title={MixHop: Higher-Order Graph Convolutional Architecturesvia Sparsified Neighborhood Mixing},<br/>
author={Amol Kapoor, Sami Abu-El-Haija, Bryan Perozzi, Aram Galstyan, Greg Ver Steeg, Hrayr Harutyunyan, Kristina Lerman and Nazanin Alipourfard},<br/>
booktitle={Proceedings of the 15th International Workshop on Mining and Learning with Graphs (MLG)},<br/>
year={2019}<br/>
}
<hr/>
</div>
</p>
<p class="large text-muted">
<strong>Latent Network Summarization</strong>
<button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#pid31">Abstract</button>
<button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#bib31">BibTex</button>
<a href="papers/MLG2019_paper_31.pdf" target=_blank class="btn btn-primary btn-xs" role="button">PDF</a>
<button class="btn btn-primary btn-xs">S</button>
<br/>
<i>Di Jin, Ryan Rossi, Danai Koutra, Eunyee Koh, Sungchul Kim and Anup Rao</i><br/>
<div id="pid31" class="collapse">
<strong>Abstract:</strong>Node representation learning is prevalent thanks to its success in a variety of downstream tasks. However, for real-world graphs with billions of nodes, handling dense node embeddings comes with computational and storage challenges, as embeddings often require space that is orders of magnitude larger than the original graph. In this work, we introduce the problem of latent network summarization that aims to learn a compact, latent representation of the graph structure with dimensionality that is independent of the input graph size (i.e., #nodes and #edges), while retaining the ability to derive node representations on the fly. 
To solve this problem, we propose Multi-LENS, an inductive multi-level latent network summarization approach that leverages a set of relational operators and relational functions (compositions of operators) to capture the structure of egonets and higher-order subgraphs, respectively. The structure is stored in low-rank, size-independent structural feature matrices, which along with the relational functions comprise our latent network summary. Multi-LENS is general and naturally supports both homogeneous and heterogeneous graphs with or without directionality, weights, attributes or labels. Extensive experiments on large real graphs show 2 − 89% improvement in AUC for link prediction, while requiring 79−2152× less output storage space than baseline embedding methods. As application areas, we show the effectiveness of Multi-LENS summaries in detecting anomalies and events in the Enron email communication graph and Twitter co-mention graph. 
<hr/>
</div>
<div id="bib31" class="collapse">
@inproceedings{mlg2019_31,<br/>
title={Latent Network Summarization},<br/>
author={Di Jin, Ryan Rossi, Danai Koutra, Eunyee Koh, Sungchul Kim and Anup Rao},<br/>
booktitle={Proceedings of the 15th International Workshop on Mining and Learning with Graphs (MLG)},<br/>
year={2019}<br/>
}
<hr/>
</div>
</p>
<p class="large text-muted">
<strong>Graph Embeddings at Scale</strong>
<button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#pid32">Abstract</button>
<button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#bib32">BibTex</button>
<a href="papers/MLG2019_paper_32.pdf" target=_blank class="btn btn-primary btn-xs" role="button">PDF</a>
<button class="btn btn-primary btn-xs">S</button>
<br/>
<i>C. Bayan Bruss, Anish Khazane, Jonathan Rider, Richard Serpe, Saurabh Nagrecha and Keegan Hines</i><br/>
<div id="pid32" class="collapse">
<strong>Abstract:</strong>Graph embedding is a popular algorithmic approach for creating vector representations for individual vertices in networks. Training these algorithms at scale is important for creating embeddings that can be used for classification, ranking, recommendation and other common applications in industry. While industrial systems exist for training graph embeddings on large datasets, many of these distributed architectures are forced to partition copious amounts of data and model logic across many worker nodes. In this paper, we propose a distributed infrastructure that completely avoids graph partitioning, dynamically creates size constrained computational graphs across worker nodes, and uses highly efficient indexing operations for updating embeddings that allow the system to function at scale. We show that our system can scale to handle the open-source Friendster network (68 million vertices) and on an internal heterogeneous graph (50 million vertices) with a differing number of worker nodes in order to measure performance against two key quantitative metrics: link-prediction accuracy and rate of convergence. We conclude this work by analyzing how a greater number of worker nodes actually improves our system's performance on the aforementioned metrics and discuss our next steps for rigorously evaluating the embedding vectors produced by our system.

<hr/>
</div>
<div id="bib32" class="collapse">
@inproceedings{mlg2019_32,<br/>
title={Graph Embeddings at Scale},<br/>
author={C. Bayan Bruss, Anish Khazane, Jonathan Rider, Richard Serpe, Saurabh Nagrecha and Keegan Hines},<br/>
booktitle={Proceedings of the 15th International Workshop on Mining and Learning with Graphs (MLG)},<br/>
year={2019}<br/>
}
<hr/>
</div>
</p>
<p class="large text-muted">
<strong>End-to-end learning and optimization on graphs</strong>
<button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#pid35">Abstract</button>
<button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#bib35">BibTex</button>
<a href="papers/MLG2019_paper_35.pdf" target=_blank class="btn btn-primary btn-xs" role="button">PDF</a>
<button class="btn btn-primary btn-xs">S</button>
<br/>
<i>Bryan Wilder, Eric Ewing, Bistra Dilkina and Milind Tambe</i><br/>
<div id="pid35" class="collapse">
<strong>Abstract:</strong>Real-world applications often combine learning and optimization problems on graphs. For instance, our objective may be to cluster the graph in order to detect meaningful communities (or solve other common graph optimization problems such as maxcut, vertex cover, and so on). However, graphs or related attributes are often only partially observed, introducing learning problems such as link prediction which must be solved prior to optimization. We propose an approach to integrate a differentiable proxy for common graph optimization problems into training of machine learning models for tasks such as link prediction. This allows the model to focus specifically on the downstream task that its predictions will be used for. Experimental results show that our end-to-end system obtains better performance on example optimization tasks than can be obtained by combining state of the art link prediction methods with expert-designed graph optimization algorithms.

<hr/>
</div>
<div id="bib35" class="collapse">
@inproceedings{mlg2019_35,<br/>
title={End-to-end learning and optimization on graphs},<br/>
author={Bryan Wilder, Eric Ewing, Bistra Dilkina and Milind Tambe},<br/>
booktitle={Proceedings of the 15th International Workshop on Mining and Learning with Graphs (MLG)},<br/>
year={2019}<br/>
}
<hr/>
</div>
</p>
<p class="large text-muted">
<strong>Covariant Compositional Networks for Learning Graphs</strong>
<button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#pid36">Abstract</button>
<button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#bib36">BibTex</button>
<a href="papers/MLG2019_paper_36.pdf" target=_blank class="btn btn-primary btn-xs" role="button">PDF</a>
<button class="btn btn-primary btn-xs">S</button>
<br/>
<i>Truong Son Hy, Shubhendu Trivedi, Horace Pan, Brandon Anderson and Risi Kondor</i><br/>
<div id="pid36" class="collapse">
<strong>Abstract:</strong>We propose Covariant Compositional Networks (CCNs), a novel neural network architecture for learning on graphs. CCNs use tensor representations for vertex features which can then be manipulated with permutation covariant tensor operations as opposed to the standard symmetric operations used in other graph neural network models. These permutation covariant operations allow us to build more expressive graph representations while still maintaining permutation invariance.


For learning small-scale molecular graphs, we investigate the efficacy of CCNs in estimating Density Functional Theory (DFT), a widely used but expensive approach to compute the electronic structure of matter. We obtain promising results in for this task and outperform other graph learning models on the Harvard Clean Energy Project and QM9 molecular datasets.

<hr/>
</div>
<div id="bib36" class="collapse">
@inproceedings{mlg2019_36,<br/>
title={Covariant Compositional Networks for Learning Graphs},<br/>
author={Truong Son Hy, Shubhendu Trivedi, Horace Pan, Brandon Anderson and Risi Kondor},<br/>
booktitle={Proceedings of the 15th International Workshop on Mining and Learning with Graphs (MLG)},<br/>
year={2019}<br/>
}
<hr/>
</div>
</p>
<p class="large text-muted">
<strong>Heterogeneous Graphlets</strong>
<button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#pid38">Abstract</button>
<button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#bib38">BibTex</button>
<a href="papers/MLG2019_paper_38.pdf" target=_blank class="btn btn-primary btn-xs" role="button">PDF</a>
<button class="btn btn-primary btn-xs">S</button>
<br/>
<i>Ryan Rossi, Nesreen Ahmed, Aldo Carranza, David Arbour, Anup Rao, Sungchul Kim and Eunyee Koh</i><br/>
<div id="pid38" class="collapse">
<strong>Abstract:</strong>In this work, we generalize the notion of network motifs (graphlets) to heterogeneous networks by introducing the notion of a small induced typed subgraph called typed graphlet. Typed graphlets generalize graphlets to rich heterogeneous networks as they explicitly capture the higher-order typed connectivity patterns in such networks. To address this problem, we describe a general framework for counting the occurrences of such typed graphlets. The proposed algorithms leverage a number of combinatorial relationships for different typed graphlets. For each edge, we count a few typed graphlets, and with these counts along with the combinatorial relationships, we obtain the exact counts of the other typed graphlets in o(1) constant time. Notably, the worst-case time complexity of the proposed approach matches the best known untyped algorithm. In addition, the approach lends itself to an efficient lock-free and asynchronous parallelization. The experiments confirm the approach is orders of magnitude faster and more space-efficient than existing methods. Unlike existing methods that take hours on small networks, the proposed approach takes only seconds on large networks with millions of edges. This gives rise to new opportunities and applications for typed graphlets on large real-world networks.

<hr/>
</div>
<div id="bib38" class="collapse">
@inproceedings{mlg2019_38,<br/>
title={Heterogeneous Graphlets},<br/>
author={Ryan Rossi, Nesreen Ahmed, Aldo Carranza, David Arbour, Anup Rao, Sungchul Kim and Eunyee Koh},<br/>
booktitle={Proceedings of the 15th International Workshop on Mining and Learning with Graphs (MLG)},<br/>
year={2019}<br/>
}
<hr/>
</div>
</p>
<p class="large text-muted">
<strong>Node Embedding via Adaptive Similarities</strong>
<button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#pid40">Abstract</button>
<button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#bib40">BibTex</button>
<a href="papers/MLG2019_paper_40.pdf" target=_blank class="btn btn-primary btn-xs" role="button">PDF</a>
<button class="btn btn-primary btn-xs">T</button>
<br/>
<i>Dimitris Berberidis and Georgios B. Giannakis</i><br/>
<div id="pid40" class="collapse">
<strong>Abstract:</strong>Node embedding is the task of extracting informative and descriptive features over the nodes of a graph. The importance of node embedding for graph analytics as well as learning tasks, such as node classification, link prediction, and community detection, has led to a growing interest and a number of recent advances. Nonetheless, node embedding faces several major challenges. Practical embedding methods have to deal with real-world graphs that arise from different domains, with inherently diverse underlying processes as well as similarity structures and metrics. On the other hand, similar to principal component analysis in feature vector spaces, node embedding is an inherently unsupervised task. Lacking metadata for validation, practical schemes motivate standardization and limited use of tunable hyperparameters. Finally, node embedding methods must be scalable in order to cope with large-scale real-world graphs of networks with ever-increasing size. The present work puts forth an adaptive node embedding framework that adjusts the embedding process to a given underlying graph, in a fully unsupervised manner. This is achieved by leveraging the notion of a tunable node similarity matrix that assigns weights on multihop paths. The design of multihop similarities ensures that the resultant embeddings also inherit interpretable spectral properties. The proposed model is thoroughly investigated, interpreted, and numerically evaluated using stochastic block models. Moreover, an unsupervised algorithm is developed for training the model parameters effieciently. Extensive node classification, link prediction, and clustering experiments are carried out on many real-world graphs from various domains, along with comparisons with state-of-the-art scalable and unsupervised node embedding alternatives. The proposed method enjoys superior performance in many cases, while also yielding interpretable information on the underlying graph structure.

<hr/>
</div>
<div id="bib40" class="collapse">
@inproceedings{mlg2019_40,<br/>
title={Node Embedding via Adaptive Similarities},<br/>
author={Dimitris Berberidis and Georgios B. Giannakis},<br/>
booktitle={Proceedings of the 15th International Workshop on Mining and Learning with Graphs (MLG)},<br/>
year={2019}<br/>
}
<hr/>
</div>
</p>
<p class="large text-muted">
<strong>A Fast Approximate Algorithm for k-Median Problem on a Graph</strong>
<button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#pid41">Abstract</button>
<button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#bib41">BibTex</button>
<a href="papers/MLG2019_paper_41.pdf" target=_blank class="btn btn-primary btn-xs" role="button">PDF</a>
<button class="btn btn-primary btn-xs">S</button>
<br/>
<i>Keisuke Todo, Atsuyoshi Nakamura and Mineichi Kudo</i><br/>
<div id="pid41" class="collapse">
<strong>Abstract:</strong>We propose a fast approximate algorithm for k-median problem on a graph, which is a problem of finding a set S of k vertices that minimizes the length sum of the shortest paths from all the vertices to their nearest vertex in S.
Starting from an initial set S of k vertices, our algorithm iteratively updates S so as to improve the shortest-path-length sum for S. In each iteration, the algorithm calculates the shortest-path forest whose roots are vertices in S and replace S with S' that are the centers of the component tree in the forest. According to our experiments using pmed datasets, our algorithm is significantly faster than CPLEX and achieves better approximation ratio than the degree-centrality or betweenness-centrality based methods.

<hr/>
</div>
<div id="bib41" class="collapse">
@inproceedings{mlg2019_41,<br/>
title={A Fast Approximate Algorithm for k-Median Problem on a Graph},<br/>
author={Keisuke Todo, Atsuyoshi Nakamura and Mineichi Kudo},<br/>
booktitle={Proceedings of the 15th International Workshop on Mining and Learning with Graphs (MLG)},<br/>
year={2019}<br/>
}
<hr/>
</div>
</p>
<p class="large text-muted">
<strong>Graph-Based Recommendation with Personalized Diffusions</strong>
<button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#pid43">Abstract</button>
<button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#bib43">BibTex</button>
<a href="papers/MLG2019_paper_43.pdf" target=_blank class="btn btn-primary btn-xs" role="button">PDF</a>
<button class="btn btn-primary btn-xs">T</button>
<br/>
<i>Athanasios N. Nikolakopoulos, Dimitris Berberidis, George Karypis and Georgios B Giannakis</i><br/>
<div id="pid43" class="collapse">
<strong>Abstract:</strong>The present work introduces PerDif; a novel framework for learning 
personalized diffusions over item-to-item graphs for top-n recommendation. 
PerDif learns the teleportation probabilities of a 
time-inhomogeneous random walk with restarts capturing a user-specific 
underlying item exploration process. Such approach can 
lead to significant improvements in recommendation accuracy, 
while also providing useful information about the users in the 
system. Per-user fitting can be performed in parallel and very efficiently 
even in large-scale settings. A comprehensive set of experiments on real-world datasets demonstrate the scalability as well as the qualitative merits 
of the proposed framework. PerDif achieves high recommendation accuracy, 
outperforming state-of-the-art competing approaches—including several 
recently proposed methods relying on deep neural networks.

<hr/>
</div>
<div id="bib43" class="collapse">
@inproceedings{mlg2019_43,<br/>
title={Graph-Based Recommendation with Personalized Diffusions},<br/>
author={Athanasios N. Nikolakopoulos, Dimitris Berberidis, George Karypis and Georgios B Giannakis},<br/>
booktitle={Proceedings of the 15th International Workshop on Mining and Learning with Graphs (MLG)},<br/>
year={2019}<br/>
}
<hr/>
</div>
</p>
<p class="large text-muted">
<strong>Forecasting Social Interactions from Dynamic Graphs: A Case Study of Twitter, GitHub, and YouTube</strong>
<button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#pid45">Abstract</button>
<button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#bib45">BibTex</button>
<a href="papers/MLG2019_paper_45.pdf" target=_blank class="btn btn-primary btn-xs" role="button">PDF</a>
<button class="btn btn-primary btn-xs">S</button>
<br/>
<i>Prasha Shresha, Suraj Maharjan, Dustin Arendt and Svitlana Volkova</i><br/>
<div id="pid45" class="collapse">
<strong>Abstract:</strong>Most of the existing graph analytics focuses on learning from static rather than dynamic graphs using hand-crafted network features or recently emerged graph embeddings learned independently from a downstream predictive task, solving predictive rather than forecasting tasks directly. To address these limitations, we propose (1) a novel task -- forecasting over dynamic graphs, and (2) a novel deep learning, multi-task, node-aware attention model that focuses on forecasting social interactions, going beyond recently emerged approaches for learning dynamic graph embeddings. Our model relies on graph convolutions and recurrent layers to forecast social interactions in large samples of {\it real-world dynamic graphs\footnote{We use the term {\it graph} in this study, even though it is common to refer to these structures as {\it social networks}, to avoid any ambiguity with neural network terminology.}} -- Twitter, GitHub, and YouTube up to seven days in advance. Our model can successfully forecast (a) retweets and mentions of a specific news source on Twitter (focusing on deceptive and credible news sources), (b) user-repository interactions on GitHub (focusing on cryptocurrency ecosystems), (c) comments to a specific video on YouTube within the next day with mean absolute error less than 2\% and $R^2$ exceeding 0.78. We demonstrate that learning from connectivity information over time in combination with node embeddings yields better forecasting results than when we use a two-step approach with Node2Vec and DeepWalk. Moreover, by evaluating model generalizability across three social platforms with different types of interactions we provide novel insights on how the size of the training and forecasting windows, and graph topological properties influence forecasting performance.

<hr/>
</div>
<div id="bib45" class="collapse">
@inproceedings{mlg2019_45,<br/>
title={Forecasting Social Interactions from Dynamic Graphs: A Case Study of Twitter, GitHub, and YouTube},<br/>
author={Prasha Shresha, Suraj Maharjan, Dustin Arendt and Svitlana Volkova},<br/>
booktitle={Proceedings of the 15th International Workshop on Mining and Learning with Graphs (MLG)},<br/>
year={2019}<br/>
}
<hr/>
</div>
</p>
<p class="large text-muted">
<strong>A Process Graph Pattern Mining Algorithm for Discovering Structured Information Control Nets</strong>
<button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#pid48">Abstract</button>
<button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#bib48">BibTex</button>
<a href="papers/MLG2019_paper_48.pdf" target=_blank class="btn btn-primary btn-xs" role="button">PDF</a>
<button class="btn btn-primary btn-xs">S</button>
<br/>
<i>Kyoung-Sook Kim, Dinh-Lam Pham and Kwang-Hoon Kim</i><br/>
<div id="pid48" class="collapse">
<strong>Abstract:</strong>This paper develops an algorithm that is able to discover graph process patterns from process enactment event logs, implements the algorithm as a process graph mining system, and carries out a couple of operational experiments with process event log datasets. The core is the rho-Algorithm that ought to be a novel approach for rediscovering all the structured process graph patterns, such as linear (sequential), disjunctive (selective-OR), conjunctive (parallel-AND), and repetitive (iterative-LOOP) process patterns, of the information control nets from an XES-formatted process enactment event log dataset. We prove that the proposed process graph pattern mining algorithm is able to complete the process rediscovery functionalities successfully through fulfilling a series of experimental studies. Additionally, we discuss those future issues of the process graph pattern discovery and rediscovery.

<hr/>
</div>
<div id="bib48" class="collapse">
@inproceedings{mlg2019_48,<br/>
title={A Process Graph Pattern Mining Algorithm for Discovering Structured Information Control Nets},<br/>
author={Kyoung-Sook Kim, Dinh-Lam Pham and Kwang-Hoon Kim},<br/>
booktitle={Proceedings of the 15th International Workshop on Mining and Learning with Graphs (MLG)},<br/>
year={2019}<br/>
}
<hr/>
</div>
</p>
<p class="large text-muted">
<strong>Discovering Robustly Connected Subgraphs with Simple Descriptions</strong>
<button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#pid49">Abstract</button>
<button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#bib49">BibTex</button>
<a href="papers/MLG2019_paper_49.pdf" target=_blank class="btn btn-primary btn-xs" role="button">PDF</a>
<button class="btn btn-primary btn-xs">T</button>
<br/>
<i>Janis Kalofolias, Mario Boley and Jilles Vreeken</i><br/>
<div id="pid49" class="collapse">
<strong>Abstract:</strong>We study the problem of discovering robustly connected subgraphs that have simple descriptions. That is, our aim is to discover sets of nodes for which the induced subgraph is not only difficult to shatter into disconnected components, but, for which the nodes can also be selected from the entire graph with just a simple conjunctive query on the vertex attributes. As many subgraphs do not have a simple description, first mining robust subgraphs, and then post-hoc discovering their description leads to suboptimal results. Instead, we hence propose to optimise over describable subgraphs only. To do so efficiently, we propose a non-redundant iterative deepening approach, which we equip with a linear-time tight optimistic estimator that allows us to prune large parts of the search space. Through extensive empirical evaluation we show that our method can consider large real-world graphs, and discovers not only easily interpretable but also meaningful subgraphs.

<hr/>
</div>
<div id="bib49" class="collapse">
@inproceedings{mlg2019_49,<br/>
title={Discovering Robustly Connected Subgraphs with Simple Descriptions},<br/>
author={Janis Kalofolias, Mario Boley and Jilles Vreeken},<br/>
booktitle={Proceedings of the 15th International Workshop on Mining and Learning with Graphs (MLG)},<br/>
year={2019}<br/>
}
<hr/>
</div>
</p>
<p class="large text-muted">
<strong>Is PageRank All You Need for Scalable Graph Neural Networks?</strong>
<button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#pid50">Abstract</button>
<button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#bib50">BibTex</button>
<a href="papers/MLG2019_paper_50.pdf" target=_blank class="btn btn-primary btn-xs" role="button">PDF</a>
<button class="btn btn-primary btn-xs">S</button>
<br/>
<i>Aleksandar Bojchevski, Johannes Klicpera, Bryan Perozzi, Martin Blais, Amol Kapoor, Michal Lukasik and Stephan Günnemann</i><br/>
<div id="pid50" class="collapse">
<strong>Abstract:</strong>Graph neural networks (GNNs) have emerged as a powerful approach for solving many network mining tasks. However, efficiently utilizing them on web-scale data remains a challenge despite related advances in research. Most recently proposed scalable GNNs rely on an expensive recursive message-passing procedure to propagate information through the graph. We circumvent this limitation by leveraging connections between GNNs and personalized PageRank and we develop a model that incorporates multi-hop neighborhood information in a single (non-recursive) step. Our work-in-progress approach PPRGo is significantly faster than multi-hop models while maintaining state-of-the-art prediction performance. We demonstrate the strengths and scalability of our approach on graphs orders of magnitude larger than typically considered in the literature.

<hr/>
</div>
<div id="bib50" class="collapse">
@inproceedings{mlg2019_50,<br/>
title={Is PageRank All You Need for Scalable Graph Neural Networks?},<br/>
author={Aleksandar Bojchevski, Johannes Klicpera, Bryan Perozzi, Martin Blais, Amol Kapoor, Michal Lukasik and Stephan Günnemann},<br/>
booktitle={Proceedings of the 15th International Workshop on Mining and Learning with Graphs (MLG)},<br/>
year={2019}<br/>
}
<hr/>
</div>
</p>


                  <!-- End Paper List -->
            </div>
          </div>
        </div>
    </section>


    <!-- Call for Papers Section -->
    <section id="call"> <!--class="bg-mid-gray"-->
        <div class="container">
            <div class="row">
                <div class="col-lg-12 text-center">
                    <h2 class="section-heading">Call for Papers</h2>
                    <!--h3 class="section-subheading text-muted">Lorem ipsum dolor sit amet consectetur.</h3-->
                </div>
            </div>
            <div class="row text-justify">
                <div class="col-md-12">
                    <p class="large text-muted">
                      This workshop is a forum for exchanging ideas and methods for mining and learning with graphs, developing new common understandings of the problems at hand, sharing of data sets where applicable, and leveraging existing knowledge from different disciplines. The goal is to bring together researchers from academia, industry, and government, to create a forum for discussing recent advances graph analysis. In doing so, we aim to better understand the overarching principles and the limitations of our current methods and to inspire research on new algorithms and techniques for mining and learning with graphs.
                    </p>
                    <p class="large text-muted">
                      To reflect the broad scope of work on mining and learning with graphs, we encourage submissions that span the spectrum from theoretical analysis to algorithms and implementation, to applications and empirical studies. As an example, the growth of user-generated content on blogs, microblogs, discussion forums, product reviews, etc., has given rise to a host of new opportunities for graph mining in the analysis of social media. We encourage submissions on theory, methods, and applications focusing on a broad range of graph-based approaches in various domains.
                    </p>
                    <p class="large text-muted">
                      Topics of interest include, but are not limited to:
                    </p>

                    <ul class="large text-muted">
                      <li><b>Theoretical aspects:</b>
                        <ul class="large text-muted">
                          <li>Computational or statistical learning theory related to graphs</li>
                          <li>Theoretical analysis of graph algorithms or models</li>
                          <li>Sampling and evaluation issues in graph algorithms</li>
                          <li>Analysis of dynamic graphs</li>
                        </ul>
                      </li>
                      <li><b>Algorithms and methods:</b>
                        <ul class="large text-muted">
                          <li>Graph mining</li>
                          <li>Probabilistic and graphical models for structured data</li>
                          <li>Heterogeneous/multi-model graph analysis</li>
                          <li>Network embedding models</li>
                          <li>Statistical models of graph structure</li>
                          <li>Combinatorial graph methods</li>
                          <li>Semi-supervised learning, active learning, transductive inference, and transfer learning in the context of graph</li>
                        </ul>
                      </li>
                      <li><b>Applications and analysis:</b>
                      <ul class="large text-muted">
                        <li>Analysis of social media</li>
                        <li>Analysis of biological networks</li>
                        <li>Knowledge graph construction</li>
                        <li>Large-scale analysis and modeling</li>
                      </ul>
                      </li>
                    </ul>

                   <p class="large text-muted">
                    We welcome many kinds of papers, such as, but not limited to:
                  </p>

                    <ul class="large text-muted">
                      <li>Novel research papers
                      </li><li>Demo papers
                      </li><li>Work-in-progress papers
                      </li><li>Visionary papers (white papers)
                      </li><li>Appraisal papers of existing methods and tools (e.g., lessons learned)
                      </li><li>Relevant work that has been previously published
                      </li><li>Work that will be presented at the main conference
                      </li>
                    </ul>

                    <p class="large text-muted">
                    Authors should <strong>clearly indicate</strong> in their abstracts the kinds of submissions that the papers belong to, to help reviewers better understand their contributions. <br/>
                    All papers will be peer reviewed, single-blinded. 
                    Submissions must be in PDF, <strong>no more than 8 pages long</strong> — shorter papers are welcome — and formatted according to the standard double-column <a href="http://www.acm.org/publications/proceedings-template#aL2" target=_blank>ACM Proceedings Style</a>. <br/>
                    The accepted papers will be published on the workshop’s website and will not be considered archival for resubmission purposes. <br/>
                    Authors whose papers are accepted to the workshop will have the opportunity to participate in a spotlight and poster session, and some set will also be chosen for oral presentation.
                    <!-- , <u><strong>and considered for $1,000 best paper award sponsored by Google and Kyndi</strong></u>. -->

                    </p>

                    <p class="large text-muted">
                      <strong>For paper submission, please proceed to the <a href="https://easychair.org/conferences/?conf=mlg2019" target=_blank>submission website</a>.</strong>
                    </p>

                    <p class="large text-muted">
                      <strong>Please send enquiries to chair@mlgworkshop.org.</strong>
                    </p>

                    <p class="large text-muted">                    
                      To receive updates about the current and future workshops and the Graph Mining community, please join the <a href="https://groups.google.com/d/forum/mlg-list" target=_blank>Mailing List</a>, or follow the <a href="https://twitter.com/mlgworkshop" target=_blank>Twitter Account</a>.
                    </p>
                </div>
            </div>
        </div>
    </section>

    <!-- Dates Section -->
    <section id="dates" class="bg-mid-gray">
        <div class="container">
            <div class="row">
                <div class="col-lg-12 text-center">
                    <h2 class="section-heading">Important Dates</h2>
                   <!--  <h3 class="section-subheading text-muted"><strong>TBD</strong></h3> -->
                </div>
            </div>
            <div class="row">
              <div class="col-lg-4 text-left">
                &nbsp;
              </div>
            <div class="col-lg-6 text-left">
                <div class="col-md-12">
                      <!-- <p class="large text-muted"> -->
                      <!-- <b>Paper Submission Open:</b> <strike>April 1, 2019</strike> -->
                    <!-- </p><p class="large text-muted">
                      <b>Paper Abstract Deadline:</b> May 5, 2019 -->
                    </p><p class="large text-muted">
                      <b>Paper Submission Deadline:</b> May 12, 2019
                    </p><p class="large text-muted">
                      <b>Author Notification:</b> June 7, 2019
                    </p><p class="large text-muted">
                      <b>Camera Ready:</b> June 22, 2019
                    </p><p class="large text-muted">
                      <b>Workshop:</b> August 5, 2019
                      </p>
                </div>
            </div>
          </div>
        </div>
    </section>

  <!-- Organization Section -->
    <section id="organization"> <!--class="bg-mid-gray"-->
        <div class="container">
            <div class="row">
                <div class="col-lg-12 text-center">
                    <h2 class="section-heading">Workshop Organizers</h2>
                    <!--h3 class="section-subheading text-muted">Lorem ipsum dolor sit amet consectetur.</h3-->
                </div>
            </div>
            <div class="row">


                <div class="col-md-1">
                  &nbsp;                  
                </div>   

                <div class="col-sm-2">
                    <div class="team-member">
                        <img src="img/team/2_shobeir.jpg" class="img-responsive img-circle" alt="Shobeir Fakhraei">
                        <h4>Shobeir Fakhraei</h4>
                        <p class="text-muted">Research Scientist<br/>U. of Southern California (ISI)</p>
                        <ul class="list-inline social-buttons-team">
                            <li><a href="http://www.cs.umd.edu/~shobeir/" target="_blank"><i class="fa fa-home"></i></a>
                            </li>
                            <li><a href="https://twitter.com/shobeirf" target=_blank><i class="fa fa-twitter"></i></a>
                            </li>
                            <li><a href="http://www.linkedin.com/in/shobeir" target=_blank><i class="fa fa-linkedin"></i></a>
                            </li>
                            <li><a target=_blank href="https://scholar.google.com/citations?user=6vJwj_QAAAAJ"><i class="fa fa-graduation-cap"></i></a>
                            </li>
                        </ul>
                    </div>
                </div>
                <div class="col-sm-2">
                    <div class="team-member">
                        <img src="img/team/aude.jpg" class="img-responsive img-circle" alt="Aude Hofleitner">
                        <h4>Aude Hofleitner</h4>
                        <p class="text-muted">Research Scientist Manager<br/>Facebook</p>
                        <ul class="list-inline social-buttons-team">
                            <li><a href="https://research.fb.com/people/hofleitner-aude/" target="_blank"><i class="fa fa-home"></i></a>
                            </li>
                            <li><a href="https://twitter.com/hofleitner?lang=en" target=_blank><i class="fa fa-twitter"></i></a>
                            </li>
                            <li><a href="https://www.linkedin.com/in/audehofleitner" target=_blank><i class="fa fa-linkedin"></i></a>
                            </li>
                            <li><a target=_blank href="https://scholar.google.com/citations?user=w-xdg4sAAAAJ&hl=en"><i class="fa fa-graduation-cap"></i></a>
                            </li>
                        </ul>
                    </div>
                </div>
                <div class="col-sm-2">
                    <div class="team-member">
                        <img src="img/team/3_danai.jpg" class="img-responsive img-circle" alt="Danai Koutra">
                        <h4>Danai Koutra<br><br></h4>
                        <p class="text-muted">Assistant Professor<br/>University of Michigan Ann Arbor</p>
                        <ul class="list-inline social-buttons-team">
                          <li><a href="http://web.eecs.umich.edu/~dkoutra/" target="_blank"><i class="fa fa-home"></i></a>
                          </li>
                          <li><a href="https://twitter.com/danaikoutra" target=_blank><i class="fa fa-twitter"></i></a>
                          </li>
                          <li><a href="https://www.linkedin.com/in/danai" target=_blank><i class="fa fa-linkedin"></i></a>
                          </li>
                          <li><a target=_blank href="https://scholar.google.com/citations?user=bDrA1-8AAAAJ"><i class="fa fa-graduation-cap"></i></a>
                          </li>
                        </ul>
                    </div>
                </div>
                <div class="col-sm-2">
                    <div class="team-member">
                        <img src="img/team/5_julian.jpg" class="img-responsive img-circle" alt="Julian McAuley">
                        <h4>Julian McAuley<br><br></h4>
                        <p class="text-muted">Assistant Professor<br/>University of California San Diego</p>
                        <ul class="list-inline social-buttons-team">
                          <li><a href="http://cseweb.ucsd.edu/~jmcauley/" target="_blank"><i class="fa fa-home"></i></a>
                          </li>
                          <li><a class="inactive" href="#organization"><i class="fa fa-twitter"></i></a>
                          </li>
                          <li><a class="inactive" href="#organization"><i class="fa fa-linkedin"></i></a>
                          </li>
                          <li><a target=_blank href="https://scholar.google.com/citations?user=icbo4M0AAAAJ"><i class="fa fa-graduation-cap"></i></a>
                          </li>
                        </ul>
                    </div>
                </div>                
                <div class="col-sm-2">
                    <div class="team-member">
                        <img src="img/team/bryan.jpg" class="img-responsive img-circle" alt="Bryan Perozzi">
                        <h4>Bryan Perozzi<br><br></h4>
                        <p class="text-muted">Research Scientist<br/>Google Research<br/>&nbsp;</p>
                        <ul class="list-inline social-buttons-team">
                          <li><a href="http://www.perozzi.net/" target="_blank"><i class="fa fa-home"></i></a>
                          </li>
                          <li><a href="https://twitter.com/phanein" target=_blank><i class="fa fa-twitter"></i></a>
                          </li>
                          <li><a href="https://www.linkedin.com/in/bryanperozzi/" target=_blank><i class="fa fa-linkedin"></i></a>
                          </li>
                          <li><a target=_blank href="https://scholar.google.com/citations?user=rZgbMs4AAAAJ&hl=en&oi=ao"><i class="fa fa-graduation-cap"></i></a>
                          </li>
                        </ul>
                    </div>
                </div>
                <div class="col-sm-2">
                    <div class="team-member">
                        <img src="img/team/tim.jpg" class="img-responsive img-circle" alt="Tim Weninger">
                        <h4>Tim Weninger<br><br></h4>
                        <p class="text-muted">Assistant Professor<br/>University of Notre Dame</p>
                        <ul class="list-inline social-buttons-team">
                          <li><a target=_blank href="https://www3.nd.edu/~tweninge/"><i class="fa fa-home"></i></a>
                          </li>
                          <li><a target=_blank href="https://twitter.com/tim_weninger"><i class="fa fa-twitter"></i></a>
                          </li>
                          <li><a target=_blank href="https://www.linkedin.com/in/tim-weninger-b462277b/"><i class="fa fa-linkedin"></i></a>
                          </li>
                          <li><a target=_blank href="https://scholar.google.com/citations?user=V1js0MUAAAAJ&hl=en"><i class="fa fa-graduation-cap"></i></a>
                          </li>
                        </ul>
                    </div>

                <div class="col-md-1">
                  &nbsp;                  
                </div>   


                </div>
            </div>
            <div class="row" style="margin-top:60px;">
                <div class="col-lg-12 text-center">
                    <h2 class="section-heading">Program Committee</h2>
                    <!-- <h3 class="section-subheading text-muted">TBD</h3> -->
                    <div class="col-md-1">
                       &nbsp;
                    </div>
                    <div class="col-md-5 text-left">
                      <p class="large text-muted">
Zhongfei Zhang (Binghamton University)<br />
Jan Ramon (INRIA)<br />
Neil Shah (Snap Research)<br />
Stefan Wrobel (Fraunhofer IAIS and Univ. of Bonn)<br />
Yizhou Sun (University of California, Los Angeles)<br />
Xin-Zeng Wu (Information Sciences Institute)<br />
Kristian Kersting (TU Darmstadt)<br />
Ali Pinar (Sandia National Laboratories)<br />
Christian Bauckhage (Fraunhofer)<br />
Xiang Ren (University of Southern California)<br />
Leto Peel (Universite catholique de Louvain)<br />
Ana Paula Appel (IBM Research Brazil)<br />
Stefano Leucci (Max Planck Institute für Informatik)<br />
Bailey Fosdick (Colorado State University)<br />
Larry Holder (Washington State University)<br />
                      </p>
                    </div>
                    <div class="col-md-5 text-left">
                      <p class="large text-muted">
Alessandro Epasto (Google Research)<br />
Leman Akoglu (Carnegie Mellon University)<br />
Jundong Li (Arizona State University)<br />
Aris Anagnostopoulos (Sapienza University of Rome)<br />
Acar Tamersoy (Symantec Research Labs)<br />
Sucheta Soundarajan (Syracuse University)<br />
Emilio Ferrara (University of Southern California)<br />
Hocine Cherifi (University of Burgundy)<br />
Yinghui Wu (Washington State University)<br />
Ivan Brugere (Salesforce Research)<br />
William Hamilton (McGill University)<br />
Stratis Ioannidis (Northeastern University)<br />
David Gleich (Purdue University)<br />
Hanghang Tong (Arizona State University)<br />
                      </p>
                      </div>
                      <div class="col-md-1">
                         &nbsp;
                      </div>
                </div>
            </div>
        </div>
    </section>

    <!-- History Section -->
    <section id="history" class="bg-mid-gray">
        <div class="container">
            <div class="row">
                <div class="col-lg-12 text-center">
                    <h2 class="section-heading">Previous Workshops</h2>
                    <!--h3 class="section-subheading text-muted">Lorem ipsum dolor sit amet consectetur.</h3-->
                </div>
            </div>
            <div class="row">
                <div class="col-lg-4 text-left">
                  &nbsp;
                </div>

                <div class="col-lg-6 text-left">
                      <p class="large text-muted">
                      	<a href="http://www.mlgworkshop.org/2018/" target=_blank  class="large text-muted">2018, London, United Kingdom (co-located with KDD)</a></br>
                        <a href="http://www.mlgworkshop.org/2017/" target=_blank  class="large text-muted">2017, Halifax, Nova Scotia, Canada (co-located with KDD)</a></br>
                        <a href="http://www.mlgworkshop.org/2016/" target=_blank  class="large text-muted">2016, San Francisco, USA (co-located with KDD)</a></br>
                        <a href="http://snap.stanford.edu/mlg2013/" target=_blank  class="large text-muted">2013, Chicago, USA (co-located with KDD)</a></br>
                        <a href="http://dtai.cs.kuleuven.be/events/mlg2012/" target=_blank  class="large text-muted">2012, Edinburgh, Scotland (co-located with ICML)</a></br>
                        <a href="http://www.cs.purdue.edu/mlg2011/" target=_blank  class="large text-muted">2011, San Diego, USA (co-located with KDD)</a></br>
                        <a href="http://www.cs.umd.edu/mlg2010/" target=_blank  class="large text-muted">2010, Washington, USA (co-located with KDD)</a></br>
                        <a href="http://dtai.cs.kuleuven.be/ilp-mlg-srl//" target=_blank  class="large text-muted">2009, Leuven, Belgium (co-located with SRL and ILP)</a></br>
                        <a href="http://research.ics.aalto.fi/events/MLG08/" target=_blank  class="large text-muted">2008, Helsinki, Finland (co-located with ICML)</a></br>
                        <a href="http://mlg07.dsi.unifi.it/" target=_blank  class="large text-muted">2007, Firenze, Italy</a></br>
                        <a href="http://www.inf.uni-konstanz.de/mlg2006/index.shtml" target=_blank  class="large text-muted">2006, Berlin, German (co-located with ECML and PKDD)</a></br>
                        <a href="#" class="large text-muted">2005, Porto, Portugal, October 7, 2005</a></br>
                        <a href="http://hms.liacs.nl/mgts2004/" target=_blank  class="large text-muted">2004, Pisa, Italy, September 24, 2004</a></br>
                        <a href="http://www.ar.sanken.osaka-u.ac.jp/MGTS-2003CFP.html" target=_blank  class="large text-muted">2003, Cavtat-Dubrovnik, Croatia</a></br>
                      </p>
                </div>
            </div>
        </div>
    </section>

    <!-- Sponsors Section -->
    <section id="Sponsors" class="bg-mid">
        <div class="container">
            <div class="row">
                <div class="col-lg-12 text-center">
                    <h2 class="section-heading">Sponsors</h2>
                    <!--h3 class="section-subheading text-muted">Lorem ipsum dolor sit amet consectetur.</h3-->
                </div>
            </div>
            <div class="row">
                <div class="col-lg-12 text-left">
                  &nbsp;<br/><br/>
                </div>
            </div>                
            <div class="row">
                <!-- <div class="col-lg-2 text-left"> -->
                  <!-- &nbsp; -->
                <!-- </div> -->
                <!-- <div class="col-lg-2 text-left"> -->
                  <!-- &nbsp; -->
                <!-- </div> -->

                <!-- <div class="col-lg-4 text-left"> -->

                  <div class="col-lg-12 text-center">
                    <img src="img/sponsors/facebook_logo.png" alt="Facebook" width='250px'>

                    <img src="img/sponsors/linkedin_logo.png" alt="LinkedIn" width='250px'>
&nbsp;&nbsp;
                    <img src="img/sponsors/neo4j_logo.png" alt="Neo4j" width='250px'>
                  </div>
                <!-- </div> -->

<!--                 <div class="col-lg-2 text-left">
                    &nbsp;
                </div> -->
            </div>
        </div>
    </section>

    <!-- Footer -->
    <footer  class="bg-darkest-gray">
        <div class="container">
            <div class="row">
                <div class="col-md-4">
                    <span class="copyright" style="color:gray;">Copyright &copy; MLG Workshop 2019</span>
                </div>
                <div class="col-md-4">
                    <ul class="list-inline social-buttons">
                        <li><a href="https://twitter.com/mlgworkshop" target=_blank><i class="fa fa-twitter"></i></a>
                        </li>
                        <!--li><a href="#"><i class="fa fa-facebook"></i></a>
                        </li>
                        <li><a href="#"><i class="fa fa-linkedin"></i></a>
                        </li-->
                    </ul>
                </div>
                <!--div class="col-md-4">
                    <ul class="list-inline quicklinks">
                        <li><a href="#">Privacy Policy</a>
                        </li>
                        <li><a href="#">Terms of Use</a>
                        </li>
                    </ul>
                </div-->
            </div>
        </div>
    </footer>

    <!-- jQuery -->
    <script src="js/jquery.js"></script>

    <!-- Bootstrap Core JavaScript -->
    <script src="js/bootstrap.min.js"></script>

    <!-- Plugin JavaScript -->
    <script src="http://cdnjs.cloudflare.com/ajax/libs/jquery-easing/1.3/jquery.easing.min.js"></script>
    <script src="js/classie.js"></script>
    <script src="js/cbpAnimatedHeader.js"></script>

    <!-- Contact Form JavaScript -->
    <script src="js/jqBootstrapValidation.js"></script>
    <script src="js/contact_me.js"></script>

    <!-- Custom Theme JavaScript -->
    <script src="js/agency.js"></script>

</body>

</html>
