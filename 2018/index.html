<!DOCTYPE html>
<html lang="en">

<head>

    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="MLG 2018, 14th International Workshop on Mining and Learning with Graphs, co-located with KDD 2018, London, United Kingdom">
    <meta name="author" content="Shobeir Fakhraei">

    <title>MLG 2018 - 14th International Workshop on Mining and Learning with Graphs</title>

    <!-- Bootstrap Core CSS -->
    <link href="css/bootstrap.min.css" rel="stylesheet">

    <!-- Custom CSS -->
    <link href="css/agency.css" rel="stylesheet">

    <!-- Custom Fonts -->
    <link href="font-awesome/css/font-awesome.min.css" rel="stylesheet" type="text/css">
    <link href="https://fonts.googleapis.com/css?family=Montserrat:400,700" rel="stylesheet" type="text/css">
    <link href='https://fonts.googleapis.com/css?family=Kaushan+Script' rel='stylesheet' type='text/css'>
    <link href='https://fonts.googleapis.com/css?family=Droid+Serif:400,700,400italic,700italic' rel='stylesheet' type='text/css'>
    <link href='https://fonts.googleapis.com/css?family=Roboto+Slab:400,100,300,700' rel='stylesheet' type='text/css'>

    <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
        <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
    <![endif]-->

    <style type="text/css">
    .tg  {border-collapse:collapse;border-spacing:0; width: 520px}
    .tg td{font-family:Arial, sans-serif;font-size:14px;padding:12px 12px;border-style:solid;border-width:0px;overflow:hidden;word-break:normal;border-top-width:1px;border-bottom-width:1px;}
    .tg th{font-family:Arial, sans-serif;font-size:14px;font-weight:normal;padding:12px 12px;border-style:solid;border-width:0px;overflow:hidden;word-break:normal;border-top-width:1px;border-bottom-width:1px;}
    .tg .tg-lqy6{text-align:right;vertical-align:top; width: 100px}
    .tg .tg-odj0{font-weight:bold;background-color:#ffcb2f;vertical-align:top}
    .tg .tg-yw4l{vertical-align:top}
    .tg .tg-l2oz{font-weight:bold;text-align:right;vertical-align:top}
    .tg .tg-9hbo{font-weight:bold;vertical-align:top}
    .tg .tg-xr8r{background-color:#ffffc7;text-align:right;vertical-align:top; width: 100px}
    .tg .tg-kjho{background-color:#ffffc7;vertical-align:top}
    </style>


</head>

<body id="page-top" class="index">
    <!-- Google Analytics -->
    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-75238067-1', 'auto');
      ga('require', 'linkid');
      ga('send', 'pageview');

    </script>

    <!-- Navigation -->
    <nav class="navbar navbar-default navbar-fixed-top">
        <div class="container">
            <!-- Brand and toggle get grouped for better mobile display -->
            <div class="navbar-header page-scroll">
                <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1">
                    <span class="sr-only">Toggle navigation</span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                </button>
                <a class="navbar-brand page-scroll" href="#page-top"><img src="img/mlg-logo.gif" style="margin:0px; padding:0px; height:30px"/></a>
            </div>

            <!-- Collect the nav links, forms, and other content for toggling -->
            <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
                <ul class="nav navbar-nav navbar-right">
                    <li class="hidden">
                        <a href="#page-top"></a>
                    </li>
                    <li>
                        <a class="page-scroll" href="#introduction">Intro</a>
                    </li>
                    <li>
                        <a class="page-scroll" href="#program">Schedule</a>
                    </li>
                    <li>
                        <a class="page-scroll" href="#keynote">Keynotes</a>
                    </li>
                    <li>
                        <a class="page-scroll" href="#papers">Accepted Papers</a>
                    </li>
                    <li>
                        <a class="page-scroll" href="#call">CFP</a>
                    </li>
                    <li>
                        <a class="page-scroll" href="#dates">Dates</a>
                    </li>
                    <li>
                        <a class="page-scroll" href="#organization">Organization</a>
                    </li>
                    <li>
                        <a class="page-scroll" href="#history">History</a>
                    </li>
                    <li>
                      <a href="https://twitter.com/mlgworkshop" target=_blank><i class="fa fa-twitter" style="font-size:20px;"></i></a>
                    </li>
                </ul>
            </div>
            <!-- /.navbar-collapse -->
        </div>
        <!-- /.container-fluid -->
    </nav>

    <!-- Header -->
    <header>
        <div class="container">
            <div class="intro-text">
                <div class="intro-lead-in">Held in conjunction with <a href="http://www.kdd.org/kdd2018/" target=_blank>KDD'18</a></br>
                Aug 20, 2018 - London, United Kingdom</div>
                <div class="intro-heading">14th International Workshop on<br/>Mining and Learning with Graphs</div>
                <a href="http://www.mlgworkshop.org/2020/" target=_blank class="page-scroll btn btn-xl">Join us at MLG2020</a>
            </div>
        </div>
    </header>

    <!-- Introduction Section -->
    <section id="introduction"> <!--class="bg-mid-gray"-->
        <div class="container">
            <div class="row">
                <div class="col-lg-8 text-center">
                    <h2 class="section-heading">Introduction</h2>
                    <!--h3 class="section-subheading text-muted">Lorem ipsum dolor sit amet consectetur.</h3-->
                </div>
            </div>
            <div class="row text-justify">

                <div class="col-md-8">
                    <p class="large text-muted">
                      There is a great deal of interest in analyzing data that is best represented as a graph. Examples include the WWW, social networks, biological networks, communication networks, transportation networks, energy grids, and many others. These graphs are typically multi-modal, multi-relational and dynamic. In the era of big data, the importance of being able to effectively mine and learn from such data is growing, as more and more structured and semi-structured data is becoming available. The workshop serves as a forum for researchers from a variety of fields working on mining and learning from graphs to share and discuss their latest findings.
                      <br/>
                      There are many challenges involved in effectively mining and learning from this kind of data, including:
                    </p>
                      <ul class="large text-muted">
                          <li>Understanding the different techniques applicable, including graph mining algorithms, network embeddings, graphical models, latent variable models, matrix factorization methods and more.</li>
                          <li>Dealing with the heterogeneity of the data.</li>
                          <li>The common need for information integration and alignment.</li>
                          <li>Handling dynamic and changing data.</li>
                          <li>Addressing each of these issues at scale.</li>
                      </ul>
                    <p class="large text-muted">
                      Traditionally, a number of subareas have contributed to this space: communities in graph mining, learning from structured data, statistical relational learning, inductive logic programming, and, moving beyond subdisciplines in computer science, social network analysis, and, more broadly network science.
                    </p>
                </div>


                <div class="col-md-4 text-right">
                     <p class="large text-muted">
                        <a href="https://twitter.com/mlgworkshop?ref_src=twsrc%5Etfw" class="twitter-follow-button" data-show-count="false">Follow @mlgworkshop</a>
                        <a class="twitter-timeline" data-lang="en" data-height="600" data-chrome="nofooter; noheader; transparent" data-link-color="#FAB81E" href="https://twitter.com/mlgworkshop?ref_src=twsrc%5Etfw"></a><script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
                      </p>
                </div>

            </div>
        </div>
    </section>

    <!-- Program Section -->
    <section id="program" class="bg-mid-gray">
        <div class="container">
            <div class="row">
                <div class="col-lg-12 text-center">
                    <h2 class="section-heading">Schedule</h2>
                    <h3 class="section-subheading text-muted"><strong>ExCeL London, London, UK | ICC Capital Suite Room 8</strong><br/><br/>
                    All accepted papers will be presented in the poster session.<br/> 
                    Based on scheduling constraints, some papers are selected as contributed talks or spotlight presentations.<br/> 
                    The contributed talks will be 15 min presentations including Q&amp;A, and spotlight presentations will be 90 seconds (1 slide).<br/>
                    </h3>
                </div>
            </div>

            <div class="row">
              <div class="col-lg-6 text-left">
                <table class="tg">
                  <tr>
                    <th class="tg-odj0"></th>
                    <th class="tg-odj0">Morning Sessions</th>
                  </tr>
                <tr>
                  <th class="tg-lqy6">8:45 am</th>
                  <th class="tg-yw4l">Opening Remarks &amp; Best Paper Announcement</th>
                </tr>
                <tr>
                  <td class="tg-l2oz">8:55 am<br/>
                  <img src="img/speakers/luna.jpg" class="img-responsive img-circle" style="height:50px; float: right;">

                  </td>
                  <td class="tg-9hbo"><a class="page-scroll" href="#keynote">Keynote:</a><br/>
                    Luna Dong<br/>
                    Harvesting Knowledge from Semi-structured Web Data
                  </td>

                </tr>

                <tr>
                  <td class="tg-xr8r">9:30 am</td>
                  <td class="tg-kjho">Coffee Break</td>
                </tr>

                <tr>
                  <td class="tg-l2oz">10:00 am<br/>
                  <img src="img/speakers/kristina.jpg" class="img-responsive img-circle" style="height:50px; float: right;">
                  </td>
                  <td class="tg-9hbo"><a class="page-scroll" href="#keynote">Keynote:</a><br/>
                    Kristina Lerman<br/>
                    Global Consequences of Local Bias in Networks</td>

                <tr style="background-color:#ffffff">
                  <td class="tg-lqy6">10:35 am</td>
                  <td class="tg-yw4l">
                    Poster Spotlights <br/>
                    <a target=_blank href='slides/mlg_spotlight_talks.pdf'>[slides]</a>
                  </td>
                </tr>

                <tr>
                  <td class="tg-l2oz">11:20 am<br/>
                  <img src="img/speakers/sujith.jpg" class="img-responsive img-circle" style="height:50px; float: right;">
                  </td>
                  <td class="tg-9hbo"><a class="page-scroll" href="#keynote">Keynote:</a><br/>
                    Sujith Ravi<br/>
                    Neural Graph Learning at Scale</td>
                </tr>

                </tr>
                  <td class="tg-xr8r">12:00 pm</td>
                  <td class="tg-kjho">Lunch Break + Poster Setup<br/></td>
                </tr>

              </table>


            </div>
            <div class="col-lg-6 text-left">
              <table class="tg">
                <tr>
                  <th class="tg-odj0"></th>
                  <th class="tg-odj0">Afternoon Sessions</th>
                </tr>

                <tr>
                  <td class="tg-l2oz">1:00 pm<br/>
                  <img src="img/speakers/christos.jpg" class="img-responsive img-circle" style="height:50px; float: right;">
                  </td>
                  <td class="tg-9hbo"><a class="page-scroll" href="#keynote">Keynote:</a><br/>
                    Christos Faloutsos<br/>
                    Mining Large Graphs</td>
                </tr>

                <tr>
                  <td class="tg-lqy6">1:40 pm</td>
                  <td class="tg-yw4l">Contributed Talk:</br>
                  Adaptive Diffusions for Scalable Learning over Graphs<br/>
                </tr>

                <tr>
                  <td class="tg-l2oz">1:55 pm<br/>
                  <img src="img/speakers/tanya.jpg" class="img-responsive img-circle" style="height:50px; float: right;">
                  </td>
                  <td class="tg-9hbo"><a class="page-scroll" href="#keynote">Keynote:</a><br/>
                    Tanya Berger-Wolf<br/>
                    Networks in Behavioral Ecology: Why Zebras Don't Have Facebook?</td>
                </tr>

                <tr>
                  <td class="tg-xr8r">2:30 pm</td>
                  <td class="tg-kjho">Coffee Break (+ Poster Session)</td>
                </tr>

                <tr>
                  <td class="tg-l2oz">3:00 pm<br/>
                  <img src="img/speakers/taha.jpg" class="img-responsive img-circle" style="height:50px; float: right;">
                  </td>
                  <td class="tg-9hbo"><a class="page-scroll" href="#keynote">Keynote:</a><br/>
                  Taha Yasseri<br/>
                  Social Conflict, Learning Through Motif Analysis</td>
                </tr>
                <tr>
                  <td class="tg-lqy6">3:35 pm</td>
                  <td class="tg-yw4l">
                    Contributed Talk:<br/>
                    From acquaintance to best friend forever: robust and fine-grained inference of social-tie strengths
                    </td>
                </tr>
                <tr >
                  <th class="tg-lqy6">3:50 pm</th>
                  <th class="tg-yw4l">Closing Remarks</th>
                </tr>                
                <tr style="background-color:#ffffff">
                  <td class="tg-lqy6">4:00 pm</td>
                  <td class="tg-yw4l">
                    Poster Session
                  </td>
                </tr>
                </table>
              </div>

              <div class="col-lg-3 text-left">
                &nbsp;
              </div>
          </div>

        </div>
    </section>

    <!-- Keynote Section no abstract -->
    <section id="keynote" class="bg-mid">
        <div class="container">
            <div class="row">
                <div class="col-lg-12 text-center">
                    <h2 class="section-heading">Keynote Speakers</h2>
                    <!--h3 class="section-subheading text-muted">More keynotes will be announced soon!</h3-->
                </div>
            </div>
            <div class="row">

                <!--div class="col-sm-1">
                  &nbsp;
                </div-->

                <div class="col-md-2">
                    <div class="team-member">
                        <img src="img/speakers/tanya.jpg" class="img-responsive img-circle" alt="Tanya Berger-Wolf">
                        <h4>Tanya Berger-Wolf</h4>
                        <p class="text-muted">Professor<br/>U. of Illinois Chicago</p>
                          <ul class="list-inline social-buttons-team">
                              <li><a target=_blank href="https://www.cs.uic.edu/~tanyabw/"><i class="fa fa-home"></i></a>
                              </li>
                              <li><a  class="inactive" href="#keynote"><i class="fa fa-twitter"></i></a>
                              </li>
                              <li><a target=_blank href="https://www.linkedin.com/in/tanyabw/"><i class="fa fa-linkedin"></i></a>
                              </li>
                              <li><a target=_blank href="https://scholar.google.com/citations?user=Hq28JM0AAAAJ&hl=en"><i class="fa fa-graduation-cap"></i></a>
                              </li>
                          </ul>
                    </div>
                </div>

                <div class="col-md-2">
                    <div class="team-member">
                        <img src="img/speakers/luna.jpg" class="img-responsive img-circle" alt="Luna Dong">
                        <h4>Luna Dong</h4><br/>
                        <p class="text-muted">Principal Scientist<br/>Amazon</p>
                          <ul class="list-inline social-buttons-team">
                              <li><a target=_blank href="http://lunadong.com/"><i class="fa fa-home"></i></a>
                              </li>
                              <li><a  class="inactive" href="#keynote"><i class="fa fa-twitter"></i></a>
                              </li>
                              <li><a target=_blank href="https://www.linkedin.com/in/xin-luna-dong-6820953b/"><i class="fa fa-linkedin"></i></a>
                              </li>
                              <li><a target=_blank href="https://scholar.google.com/citations?user=uGsKvHoAAAAJ&hl=en"><i class="fa fa-graduation-cap"></i></a>
                              </li>
                          </ul>
                    </div>
                </div>

                <div class="col-md-2">
                    <div class="team-member">
                        <img src="img/speakers/christos.jpg" class="img-responsive img-circle" alt="Christos Faloutsos">
                        <h4>Christos Faloutsos</h4>
                        <p class="text-muted">Professor<br/>Carnegie Mellon U.</p>
                          <ul class="list-inline social-buttons-team">
                              <li><a target=_blank href="http://www.cs.cmu.edu/~christos/"><i class="fa fa-home"></i></a>
                              </li>
                              <li><a  class="inactive" href="#keynote"><i class="fa fa-twitter"></i></a>
                              </li>
                              <li><a target=_blank href="https://www.linkedin.com/in/christos-faloutsos-43a7aa2/"><i class="fa fa-linkedin"></i></a>
                              </li>
                              <li><a target=_blank href="https://scholar.google.com/citations?user=nd8lQQIAAAAJ&hl=en"><i class="fa fa-graduation-cap"></i></a>
                              </li>
                          </ul>
                    </div>
                </div>

                <div class="col-md-2">
                    <div class="team-member">
                        <img src="img/speakers/kristina.jpg" class="img-responsive img-circle" alt="Kristina Lerman">
                        <h4>Kristina Lerman</h4><br/>
                        <p class="text-muted">Associate Professor<br/>U. of Southern California</p>
                        <ul class="list-inline social-buttons-team">
                          <li><a target=_blank href="https://www.isi.edu/integration/people/lerman/index.html"><i class="fa fa-home"></i></a>
                          </li>
                          <li><a target=_blank href="https://twitter.com/kristinalerman?lang=en"><i class="fa fa-twitter"></i></a>
                          </li>
                          <li><a target=_blank href="https://www.linkedin.com/in/kristinalerman/"><i class="fa fa-linkedin"></i></a>
                          </li>
                          <li><a target=_blank href="https://scholar.google.com/citations?user=PlAG11IAAAAJ"><i class="fa fa-graduation-cap"></i></a>
                          </li>
                        </ul>
                    </div>
                </div>

                <div class="col-md-2">
                    <div class="team-member">
                        <img src="img/speakers/sujith.jpg" class="img-responsive img-circle" alt="Sujith Ravi">
                        <h4>Sujith Ravi</h4><br/>
                        <p class="text-muted">Research Scientist<br/>Google Research</p>
                        <ul class="list-inline social-buttons-team">
                          <li><a target=_blank href="http://www.sravi.org/"><i class="fa fa-home"></i></a>
                          </li>
                          <li><a target=_blank href="https://twitter.com/ravisujith"><i class="fa fa-twitter"></i></a>
                          </li>
                          <li><a target=_blank href="https://www.linkedin.com/in/sujithravi/"><i class="fa fa-linkedin"></i></a>
                          </li>
                          <li><a target=_blank href="https://scholar.google.com/citations?user=sM-dHicAAAAJ&hl=en"><i class="fa fa-graduation-cap"></i></a>
                          </li>
                        </ul>
                    </div>
                </div>

                <div class="col-md-2">
                    <div class="team-member">
                        <img src="img/speakers/taha.jpg" class="img-responsive img-circle" alt="Taha Yasseri">
                        <h4>Taha Yasseri</h4><br/>
                        <p class="text-muted">Assistant Professor<br/>University of Oxford</p>
                        <ul class="list-inline social-buttons-team">
                          <li><a target=_blank href="https://www.oii.ox.ac.uk/people/taha-yasseri/"><i class="fa fa-home"></i></a>
                          </li>
                          <li><a target=_blank href="https://twitter.com/TahaYasseri"><i class="fa fa-twitter"></i></a>
                          </li>
                          <li><a target=_blank href="https://www.linkedin.com/in/taha-yasseri-30a46455/"><i class="fa fa-linkedin"></i></a>
                          </li>
                          <li><a target=_blank href="https://scholar.google.com/citations?user=AiLoMKwAAAAJ&hl=en"><i class="fa fa-graduation-cap"></i></a>
                          </li>
                        </ul>
                    </div>
                </div>

                <!--div class="col-sm-1">
                  &nbsp;
                </div-->


            </div>
        </div>
    </section>

    <!-- Accepted Papers Section -->
    <section id="papers" class="bg-mid-gray">
        <div class="container">
            <div class="row">
                <div class="col-lg-12 text-center">
                    <h2 class="section-heading">Accepted Papers</h2>
                    <h3 class="section-subheading text-muted">
                    All accepted papers will present a poster, spotlights and talks are marked with   
                    <button class="btn btn-primary btn-xs">S</button> and   
                    <button class="btn btn-primary btn-xs">T</button>
                    </h3>
                </div>
            </div>
            <div class="row">

            <div class="col-lg-1 text-center">
                &nbsp;
            </div>

            <div class="col-lg-11 text-justify">
                  <!-- Begin Paper List -->

                  <p class="large text-muted">
                    <strong>Growing Better Graphs With Latent-Variable Probabilistic Graph Grammars</strong> 
                    <button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#pid9">Abstract</button> 
                    <button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#bib9">BibTex</button> 
                    <a href="papers/MLG2018_paper_9.pdf" target=_blank class="btn btn-primary btn-xs" role="button">PDF</a> 
                    <button class="btn btn-primary btn-xs">S</button>
                    <br/>
                    <i>Xinyi Wang, Salvador Aguinaga, Tim Weninger and David Chiang</i><br/>

                    <div id="pid9" class="collapse">
                    <strong>Abstract:</strong> Recent work in graph models has found that probabilistic hyperedge replacement grammars (HRGs) can be extracted from graphs and used to generate new random graphs with graph properties and substructures close to the original. In this paper, we show how to add latent variables to the model, trained using Expectation-Maximization, to generate still better graphs,  that is, ones that generalize better to the test data. We evaluate the new method by separating training and test graphs, building the model on the former and measuring the likelihood of the latter, as a more stringent test of how well the model can generalize to new graphs. On this metric, we find that our latent-variable HRGs consistently outperform several existing graph models and provide interesting insights into the building blocks of real world networks.
                    <br/><br/><strong>Keywords:</strong> Graph Generation, Graph Grammars, Graph Generator Evaluation, Unsupervised Learning
                    <hr/>
                    </div>

                    <div id="bib9" class="collapse">
                    @inproceedings{mlg2018_9,<br/>
                    title={Growing Better Graphs With Latent-Variable Probabilistic Graph Grammars},<br/>
                    author={Xinyi Wang, Salvador Aguinaga, Tim Weninger and David Chiang},<br/>
                    booktitle={Proceedings of the 14th International Workshop on Mining and Learning with Graphs (MLG)},<br/>
                    year={2018}<br/>
                    }
                    <hr/>
                    </div>

                    </p>

                    <p class="large text-muted">
                    <strong>Adaptive Diffusions for Scalable Learning over Graphs</strong> 
                    <button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#pid21">Abstract</button> 
                    <button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#bib21">BibTex</button> 
                    <a href="papers/MLG2018_paper_21.pdf" target=_blank class="btn btn-primary btn-xs" role="button">PDF</a> 
                    <button class="btn btn-primary btn-xs">T</button>
                    <br/>
                    <i>Dimitris Berberidis, Athanasios N. Nikolakopoulos and Georgios B. Giannakis</i><br/>

                    <div id="pid21" class="collapse">
                    <strong>Abstract:</strong> Diffusion-based classifiers such as those relying on the Personalized
                    PageRank and the Heat kernel, enjoy remarkable classification accuracy at modest computational requirements. Their performance
                    however is affected by the extent to which the chosen diffusion
                    captures a typically unknown label propagation mechanism, that
                    can be specific to the underlying graph, and potentially different for
                    each class. The present work introduces a disciplined, data-efficient
                    approach to learning class-specific diffusion functions adapted to the
                    underlying network topology. The novel learning approach leverages the notion of "landing probabilities" of class-specific random
                    walks, which can be computed efficiently, thereby ensuring scalability to large graphs. This is supported by rigorous analysis of
                    the properties of the model as well as the proposed algorithms.
                    Classification tests on real networks demonstrate that adapting the
                    diffusion function to the given graph and observed labels, significantly improves the performance over fixed diffusions; reaching --
                    and many times surpassing -- the classification accuracy of computationally heavier state-of-the-art competing methods, that rely on
                    node embeddings and deep neural networks.
                    <br/><br/><strong>Keywords:</strong> Semi-supervised Classification, Random Walks, Diffusions
                    <hr/>
                    </div>

                    <div id="bib21" class="collapse">
                    @inproceedings{mlg2018_21,<br/>
                    title={Adaptive Diffusions for Scalable Learning over Graphs},<br/>
                    author={Dimitris Berberidis, Athanasios N. Nikolakopoulos and Georgios B. Giannakis},<br/>
                    booktitle={Proceedings of the 14th International Workshop on Mining and Learning with Graphs (MLG)},<br/>
                    year={2018}<br/>
                    }
                    <hr/>
                    </div>

                    </p>

                    <p class="large text-muted">
                    <strong>From acquaintance to best friend forever: robust and fine-grained inference of social-tie strengths</strong> 
                    <button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#pid28">Abstract</button> 
                    <button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#bib28">BibTex</button> 
                    <a href="papers/MLG2018_paper_28.pdf" target=_blank class="btn btn-primary btn-xs" role="button">PDF</a> 
                    <button class="btn btn-primary btn-xs">T</button>
                    <br/>
                    <i>Florian Adriaens, Tijl De Bie, Aristides Gionis, Jefrey Lijffijt and Polina Rozenshtein</i><br/>

                    <div id="pid28" class="collapse">
                    <strong>Abstract:</strong> Social networks often provide only a binary perspective on social ties: two individuals are either connected or not.
                    While sometimes external information can be used to infer the strength of social ties, access to such information may be restricted or impractical.

                    Sintos and Tsaparas (KDD 2014) first suggested to infer the strength of social ties from the topology of the network alone, by leveraging the Strong Triadic Closure (STC) property, postulated to hold in social networks.
                    The STC property states that if person A has strong social ties with persons B and C, B and C must be connected to each other as well (whether with a weak or strong tie).
                    Sintos and Tsaparas exploited this property to formulate the inference of the strength of social ties as an NP-hard optimization problem, and proposed two approximation algorithms.

                    We refine and improve this line of work,by developing a sequence of linear relaxations of the problem, which can be solved exactly in polynomial time.
                    Usefully, these relaxations infer more fine-grained levels of tie strength (beyond strong and weak),which also allows to avoid making arbitrary strong/weak strength assignments when the network topology provides inconclusive evidence.
                    One of the relaxations simultaneously infers the presence of a limited number of STC violations.
                    An extensive theoretical analysis leads to two efficient algorithmic approaches.
                    Finally, our experimental results elucidate the strengths of the proposed approach, and sheds new light on the validity of the STC property in practice.
                    <br/><br/><strong>Keywords:</strong> Strong Triadic Closure, Strength of social ties, Linear Programming, Convex Relaxations
                    <hr/>
                    </div>

                    <div id="bib28" class="collapse">
                    @inproceedings{mlg2018_28,<br/>
                    title={From acquaintance to best friend forever: robust and fine-grained inference of social-tie strengths},<br/>
                    author={Florian Adriaens, Tijl De Bie, Aristides Gionis, Jefrey Lijffijt and Polina Rozenshtein},<br/>
                    booktitle={Proceedings of the 14th International Workshop on Mining and Learning with Graphs (MLG)},<br/>
                    year={2018}<br/>
                    }
                    <hr/>
                    </div>

                    </p>

                    <p class="large text-muted">
                    <strong>Watch Your Step: Learning Graph Embeddings Through Attention</strong> 
                    <button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#pid50">Abstract</button> 
                    <button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#bib50">BibTex</button> 
                    <a href="papers/MLG2018_paper_50.pdf" target=_blank class="btn btn-primary btn-xs" role="button">PDF</a>
                    <button class="btn btn-primary btn-xs">S</button> 
                    <br/>
                    <i>Sami Abu-El-Haija, Bryan Perozzi, Rami Al-Rfou and Alex Alemi</i><br/>

                    <div id="pid50" class="collapse">
                    <strong>Abstract:</strong>  Graph embedding methods represent nodes in a continuous vector space, 
                    preserving information from the graph (e.g. by sampling random walks). 
                    There are many hyper-parameters to these methods (such as random walk length) which have to be manually tuned for every graph. 
                    In this paper, we replace random walk hyper-parameters with trainable parameters that we automatically learn via backpropagation. In particular, we learn a novel attention model on the power series of the transition matrix, which guides the random walk to optimize an upstream objective. 
                    Unlike previous approaches to attention models, the method that we propose 
                    utilizes attention parameters exclusively on the data (e.g. on the random walk), and not used by the model for inference. 
                    We experiment on link prediction tasks, as we aim to produce embeddings that best-preserve the graph structure, generalizing to unseen information. We improve state-of-the-art on a comprehensive suite of real world datasets including social, collaboration, and biological networks. Adding attention to random walks can reduce the error by 20% to 45% on datasets we attempted. 
                    Further, our learned attention parameters are different for every graph, and our automatically-found values agree with the optimal choice of hyper-parameter if we manually tune existing methods.
                    <br/><br/><strong>Keywords:</strong> Graph, Embedding, Attention, Context Distribution, Deep Learning
                    <hr/>
                    </div>

                    <div id="bib50" class="collapse">
                    @inproceedings{mlg2018_50,<br/>
                    title={Watch Your Step: Learning Graph Embeddings Through Attention},<br/>
                    author={Sami Abu-El-Haija, Bryan Perozzi, Rami Al-Rfou and Alex Alemi},<br/>
                    booktitle={Proceedings of the 14th International Workshop on Mining and Learning with Graphs (MLG)},<br/>
                    year={2018}<br/>
                    }
                    <hr/>
                    </div>

                    </p>

                    <p class="large text-muted">
                    <strong>t-PINE: Tensor-based Predictable and Interpretable Node Embeddings</strong> 
                    <button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#pid1">Abstract</button> 
                    <button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#bib1">BibTex</button> 
                    <a href="papers/MLG2018_paper_1.pdf" target=_blank class="btn btn-primary btn-xs" role="button">PDF</a>
                    <button class="btn btn-primary btn-xs">S</button> 
                    <br/>
                    <i>Saba Al-Sayouri, Ekta Gujral, Danai Koutra, Evangelos Papalexakis and Sarah Lam</i><br/>

                    <div id="pid1" class="collapse">
                    <strong>Abstract:</strong> Graph representations have increasingly grown in popularity dur- ing the last years. Existing representation learning approaches ex- plicitly encode network structure. Despite their good performance in downstream processes (e.g., node classi cation, link prediction), there is still room for improvement in di erent aspects, like e cacy, visualization, and interpretability. In this paper, we propose, t-PINE, a method that addresses these limitations. Contrary to baseline methods, which generally learn explicit graph representations by solely using an adjacency matrix, t-PINE avails a multi-view infor- mation graph—the adjacency matrix represents the  rst view, and a nearest neighbor adjacency, computed over the node features, is the second view—in order to learn explicit and implicit node repre- sentations, using the Canonical Polyadic (a.k.a. CP) decomposition. We argue that the implicit and the explicit mapping from a higher- dimensional to a lower-dimensional vector space is the key to learn more useful, highly predictable, and gracefully interpretable rep- resentations. Having good interpretable representations provides a good guidance to understand how each view contributes to the representation learning process. In addition, it helps us to exclude unrelated dimensions. Extensive experiments show that t-PINE drastically outperforms baseline methods by up to 158.6% with respect to Micro-F1, in several multi-label classi cation problems, while it has high visualization and interpretability utility.
                    <br/><br/><strong>Keywords:</strong> information networks, graph embeddings, tensor decomposition
                    <hr/>
                    </div>

                    <div id="bib1" class="collapse">
                    @inproceedings{mlg2018_1,<br/>
                    title={t-PINE: Tensor-based Predictable and Interpretable Node Embeddings},<br/>
                    author={Saba Al-Sayouri, Ekta Gujral, Danai Koutra, Evangelos Papalexakis and Sarah Lam},<br/>
                    booktitle={Proceedings of the 14th International Workshop on Mining and Learning with Graphs (MLG)},<br/>
                    year={2018}<br/>
                    }
                    <hr/>
                    </div>

                    </p>

                    <p class="large text-muted">
                    <strong>Fully Heterogeneous Collective Regression</strong> 
                    <button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#pid33">Abstract</button> 
                    <button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#bib33">BibTex</button> 
                    <a href="papers/MLG2018_paper_33.pdf" target=_blank class="btn btn-primary btn-xs" role="button">PDF</a>
                    <button class="btn btn-primary btn-xs">S</button> 
                    <br/>
                    <i>David Liedtka and Luke McDowell</i><br/>

                    <div id="pid33" class="collapse">
                    <strong>Abstract:</strong> Prior work has demonstrated that multiple methods for link-based classification (LBC) can substantially improve accuracy when the nodes of interest are interconnected.  To date, however, very little work has considered how methods for LBC could be applied in domains that require continuous, rather than categorical, predictions.  In addition, prior work with LBC has learned only one predictive model to use for all nodes of a given type, but some domains exhibit significant node diversity that is not well-suited to this approach.  In response, we introduce fully heterogeneous collective regression (FHCR), a new method that learns node-specific models from data and uses these models to jointly predict continuous outputs.  We apply FHCR to a voting prediction task, and create novel correlation-based link generation methods that outperform alternative methods. In addition, we introduce multiple new methods for inferring continuous outputs that can incorporate link-based information, and show that regression-specific methods based on Bayesian inference outperform the naive approach of inserting regression into existing LBC methods. Overall, we demonstrate the viability of the new FHCR paradigm by producing results that are comparable or better than those of previous link-unaware methods, yet are at least two orders of magnitude faster.
                    <br/><br/><strong>Keywords:</strong> collective inference, collective regression, link-based data, online predictions
                    <hr/>
                    </div>

                    <div id="bib33" class="collapse">
                    @inproceedings{mlg2018_33,<br/>
                    title={Fully Heterogeneous Collective Regression},<br/>
                    author={David Liedtka and Luke McDowell},<br/>
                    booktitle={Proceedings of the 14th International Workshop on Mining and Learning with Graphs (MLG)},<br/>
                    year={2018}<br/>
                    }
                    <hr/>
                    </div>

                    </p>

                    <p class="large text-muted">
                    <strong>Reducing Network Incompleteness Through Online Learning: A Feasibility Study</strong> 
                    <button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#pid40">Abstract</button> 
                    <button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#bib40">BibTex</button> 
                    <a href="papers/MLG2018_paper_40.pdf" target=_blank class="btn btn-primary btn-xs" role="button">PDF</a>
                    <button class="btn btn-primary btn-xs">S</button> 
                    <br/>
                    <i>Timothy Larock, Timothy Sakharov, Sahely Bhadra and Tina Eliassi-Rad</i><br/>

                    <div id="pid40" class="collapse">
                    <strong>Abstract:</strong> Real-world phenomena are often partially observed. This partial observability leads to incomplete data. Acquiring more data is often expensive, hard, or impossible. We present a feasibility study on the limits of online learning to reduce incompleteness in network data. In particular, we investigate the following problem: given a network and limited resources to collect more data (i.e., a budget), can an optimal strategy be learned for reducing the network's incompleteness? Reducing the incompleteness of a network can be interpreted in different ways and represented by various objective functions. For example, it could mean: observe as many previously unobserved nodes as possible, or observe as many new nodes with a certain property, or observe as many new nodes and triangles, etc. Here, we focus on the first interpretation -- i.e., we use the given budget to increase the number of nodes in the incomplete graph; but our proposed method can handle various objective functions. Using one unit of the budget means querying an oracle that has access to the fully observed network and getting back full information about a single node's neighbors (at the time of query). We refer to this process as probing a node. Examples of probing nodes include using an API to get information about an account, placing monitors on routers to get information about Internet traffic flow, etc. We make no assumptions about the underlying model generating the network data or how the incomplete network was observed. Our findings on synthetic and real-world networks showcase when learning is feasible, when it is not, and when one should just use a heuristic (i.e., when learning is unnecessary or redundant).
                    <br/><br/><strong>Keywords:</strong> Partially observed networks, Online learning, Feasibility study
                    <hr/>
                    </div>

                    <div id="bib40" class="collapse">
                    @inproceedings{mlg2018_40,<br/>
                    title={Reducing Network Incompleteness Through Online Learning: A Feasibility Study},<br/>
                    author={Timothy Larock, Timothy Sakharov, Sahely Bhadra and Tina Eliassi-Rad},<br/>
                    booktitle={Proceedings of the 14th International Workshop on Mining and Learning with Graphs (MLG)},<br/>
                    year={2018}<br/>
                    }
                    <hr/>
                    </div>

                    </p>

                    <p class="large text-muted">
                    <strong>What the HAK? Estimating Ranking Deviations in Incomplete Graphs</strong> 
                    <button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#pid2">Abstract</button> 
                    <button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#bib2">BibTex</button> 
                    <a href="papers/MLG2018_paper_2.pdf" target=_blank class="btn btn-primary btn-xs" role="button">PDF</a>
                    <button class="btn btn-primary btn-xs">S</button> 
                    <br/>
                    <i>Helge Holzmann, Avishek Anand and Megha Khosla</i><br/>

                    <div id="pid2" class="collapse">
                    <strong>Abstract:</strong> Most real-world graphs collected from the Web like Web graphs and social network graphs are incomplete. This leads to inaccurate estimates of graph properties based on link analysis such as PageRank. In this paper we focus on studying such deviations in ordering/ranking imposed by PageRank over incomplete graphs. We first show that deviations in rankings induced by PageRank are indeed possible. We measure how much a ranking, induced by PageRank, on an input graph could deviate from the original unseen graph. More importantly, we are interested in conceiving a measure that approximates the rank correlation among them without any knowledge of the original graph. To this extent we formulate the HAK measure that is based on computing the impact redistribution of PageRank according to the local graph structure. Finally, we perform extensive experiments on both real-world Web and social network graphs with more than 100M vertices and 10B edges as well as synthetic graphs to showcase the utility of HAK. 
                    <br/><br/><strong>Keywords:</strong> Graph Analysis, Incomplete Subgraphs, PageRank
                    <hr/>
                    </div>

                    <div id="bib2" class="collapse">
                    @inproceedings{mlg2018_2,<br/>
                    title={What the HAK? Estimating Ranking Deviations in Incomplete Graphs},<br/>
                    author={Helge Holzmann, Avishek Anand and Megha Khosla},<br/>
                    booktitle={Proceedings of the 14th International Workshop on Mining and Learning with Graphs (MLG)},<br/>
                    year={2018}<br/>
                    }
                    <hr/>
                    </div>

                    </p>

                    <p class="large text-muted">
                    <strong>Hierarchical Graph Clustering based on Node Pair Sampling</strong> 
                    <button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#pid4">Abstract</button> 
                    <button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#bib4">BibTex</button> 
                    <a href="papers/MLG2018_paper_4.pdf" target=_blank class="btn btn-primary btn-xs" role="button">PDF</a>
                    <button class="btn btn-primary btn-xs">S</button> 
                    <br/>
                    <i>Thomas Bonald, Bertrand Charpentier, Alexis Galland and Alexandre Hollocou</i><br/>

                    <div id="pid4" class="collapse">
                    <strong>Abstract:</strong> We present a novel hierarchical graph clustering algorithm  inspired by modularity-based clustering techniques. The algorithm is agglomerative and based on a simple distance between clusters induced by the probability of sampling node pairs. We prove that this distance is reducible, which enables the use of the nearest-neighbor chain to speed up the agglomeration. The output of the algorithm is a regular  dendrogram, which reveals the multi-scale structure of the graph. The results are illustrated  on both synthetic and real datasets.
                    <br/><br/><strong>Keywords:</strong> hierarchical clustering, dendrogram, modularity, resolution, multi-scale
                    <hr/>
                    </div>

                    <div id="bib4" class="collapse">
                    @inproceedings{mlg2018_4,<br/>
                    title={Hierarchical Graph Clustering based on Node Pair Sampling},<br/>
                    author={Thomas Bonald, Bertrand Charpentier, Alexis Galland and Alexandre Hollocou},<br/>
                    booktitle={Proceedings of the 14th International Workshop on Mining and Learning with Graphs (MLG)},<br/>
                    year={2018}<br/>
                    }
                    <hr/>
                    </div>

                    </p>

                    <p class="large text-muted">
                    <strong>Generalized Embedding Models for Knowledge Graph Mining</strong> 
                    <button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#pid5">Abstract</button> 
                    <button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#bib5">BibTex</button> 
                    <a href="papers/MLG2018_paper_5.pdf" target=_blank class="btn btn-primary btn-xs" role="button">PDF</a>
                    <button class="btn btn-primary btn-xs">S</button> 
                    <br/>
                    <i>Qiao Liu, Rui Wan, Xiaohui Yang, Yifu Zeng and Haibin Zhang</i><br/>

                    <div id="pid5" class="collapse">
                    <strong>Abstract:</strong> Many types of relations in physical, biological, social and information systems can be modeled as homogeneous or heterogeneous concept graphs. Hence, learning from and with graph embeddings has drawn a great deal of research interest recently, but developing an embedding learning method that is flexible enough to accommodate variations in physical networks is still a challenging problem. In this paper, we conjecture that the one-shot supervised learning mechanism is a bottleneck in improving the performance of the graph embedding learning, and propose to extend this by introducing a multi-shot “unsupervised” learning framework where a 2-layer MLP network for every shot .The framework can be extended to accommodate a variety of homogeneous and heterogeneous networks. Empirical results on several real-world data set show that the proposed model consistently and significantly outperforms existing state-of-the-art approaches on knowledge base completion and graph based multi-label classification tasks.
                    <br/><br/><strong>Keywords:</strong> representation learning, graph embedding learning, reasoning link prediction, multi-label classification, knowledge graphs
                    <hr/>
                    </div>

                    <div id="bib5" class="collapse">
                    @inproceedings{mlg2018_5,<br/>
                    title={Generalized Embedding Models for Knowledge Graph Mining},<br/>
                    author={Qiao Liu, Rui Wan, Xiaohui Yang, Yifu Zeng and Haibin Zhang},<br/>
                    booktitle={Proceedings of the 14th International Workshop on Mining and Learning with Graphs (MLG)},<br/>
                    year={2018}<br/>
                    }
                    <hr/>
                    </div>

                    </p>

                    <p class="large text-muted">
                    <strong>Network Signatures from Image Representation of Adjacency Matrices: Deep/Transfer Learning for Subgraph Classification</strong> 
                    <button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#pid10">Abstract</button> 
                    <button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#bib10">BibTex</button> 
                    <a href="papers/MLG2018_paper_10.pdf" target=_blank class="btn btn-primary btn-xs" role="button">PDF</a>
                    <button class="btn btn-primary btn-xs">S</button> 
                    <br/>
                    <i>Kshiteesh Hegde, Malik Magdon-Ismail, Ram Ramanathan and Bishal Thapa</i><br/>

                    <div id="pid10" class="collapse">
                    <strong>Abstract:</strong> This paper is a hybrid between novel research and a demo. We show the power of image representation of subgraphs for classification of network fragments with the targets being their parent networks. The graph image representation is based on 2D image embeddings of adjacency matrices. We use this image representation in two modes. First, as the input to a machine learning algorithm. Second, as the input to a pure transfer learner. Our conclusions from several datasets are that

                    i. deep learning using our structured image features performs the best compared to benchmark graph kernel and classical features based methods; and,

                    ii. pure transfer learning works effectively with minimum interference from the user and is robust against small data.

                    <br/><br/><strong>Keywords:</strong> Deep Learning, Network Signatures, Graph Classification, Image Embeddings of Graphs, Transfer Learning
                    <hr/>
                    </div>

                    <div id="bib10" class="collapse">
                    @inproceedings{mlg2018_10,<br/>
                    title={Network Signatures from Image Representation of Adjacency Matrices: Deep/Transfer Learning for Subgraph Classification},<br/>
                    author={Kshiteesh Hegde, Malik Magdon-Ismail, Ram Ramanathan and Bishal Thapa},<br/>
                    booktitle={Proceedings of the 14th International Workshop on Mining and Learning with Graphs (MLG)},<br/>
                    year={2018}<br/>
                    }
                    <hr/>
                    </div>

                    </p>

                    <p class="large text-muted">
                    <strong>Testing Alignment of Node Attributes with Network Structure Through Label Propagation </strong> 
                    <button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#pid13">Abstract</button> 
                    <button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#bib13">BibTex</button> 
                    <a href="papers/MLG2018_paper_13.pdf" target=_blank class="btn btn-primary btn-xs" role="button">PDF</a>
                    <button class="btn btn-primary btn-xs">S</button> 
                    <br/>
                    <i>Natalie Stanley, Marc Niethammer and Peter J. Mucha</i><br/>

                    <div id="pid13" class="collapse">
                    <strong>Abstract:</strong> Attributed network data is becoming increasingly common across fields, as we are often equipped with information about nodes in addition to their pairwise connectivity patterns. This extra information can manifest as a classification, or as a multidimensional vector of features. Recently developed methods that seek to extend community detection approaches to attributed networks have explored how to most effectively combine connectivity and attribute information to identify quality communities. These methods often rely on some assumption of the dependency relationships between attributes and connectivity. In this work, we seek to develop a statistical test to assess whether node attributes align with network connectivity. The objective is to quantitatively evaluate whether nodes with similar connectivity patterns also have similar attributes. To address this problem, we use a node sampling and label propagation approach. We apply our method to several synthetic examples that explore how network structure and attribute characteristics affect the empirical p-value computed by our method. Finally, we apply the test to a network generated from a single cell mass cytometry (CyTOF) dataset and show that our test can identify markers associated with distinct sub populations of single cells. 
                    <br/><br/><strong>Keywords:</strong> community detection, attributed networks, label propagation, computational biology, clustering
                    <hr/>
                    </div>

                    <div id="bib13" class="collapse">
                    @inproceedings{mlg2018_13,<br/>
                    title={Testing Alignment of Node Attributes with Network Structure Through Label Propagation },<br/>
                    author={Natalie Stanley, Marc Niethammer and Peter J. Mucha},<br/>
                    booktitle={Proceedings of the 14th International Workshop on Mining and Learning with Graphs (MLG)},<br/>
                    year={2018}<br/>
                    }
                    <hr/>
                    </div>

                    </p>

                    <p class="large text-muted">
                    <strong>The Power Mean Laplacian for Multilayer Graph Clustering</strong> 
                    <button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#pid18">Abstract</button> 
                    <button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#bib18">BibTex</button> 
                    <a href="https://arxiv.org/pdf/1803.00491.pdf" target=_blank class="btn btn-primary btn-xs" role="button">PDF</a>
                    <button class="btn btn-primary btn-xs">S</button> 
                    <br/>
                    <i>Pedro Mercado, Antoine Gautier, Francesco Tudisco and Matthias Hein</i><br/>

                    <div id="pid18" class="collapse">
                    <strong>Abstract:</strong> Multilayer graphs encode different kind of interactions between the same set of entities. When one wants to cluster such a multilayer graph, the natural question arises how one should merge the information from different layers. We introduce in this paper a one-parameter family of matrix power means for merging the Laplacians from different layers and analyze it in expectation in the stochastic block model. We show that this family allows to recover ground truth clusters under different settings and verify this in real world data. While computing the matrix power mean can be very expensive for large graphs, we introduce a numerical scheme to efficiently compute its eigenvectors for the case of large sparse graphs.
                    <br/><br/><strong>Keywords:</strong> Multilayer Graphs, Spectral Clustering, Numerical Linear Algebra
                    <hr/>
                    </div>

                    <div id="bib18" class="collapse">
                    @inproceedings{mlg2018_18,<br/>
                    title={The Power Mean Laplacian for Multilayer Graph Clustering},<br/>
                    author={Pedro Mercado, Antoine Gautier, Francesco Tudisco and Matthias Hein},<br/>
                    booktitle={Proceedings of the 14th International Workshop on Mining and Learning with Graphs (MLG)},<br/>
                    year={2018}<br/>
                    }
                    <hr/>
                    </div>

                    </p>

                    <p class="large text-muted">
                    <strong>Spread Sampling for Graphs: Theory and Application</strong> 
                    <button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#pid22">Abstract</button> 
                    <button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#bib22">BibTex</button> 
                    <a href="papers/MLG2018_paper_22.pdf" target=_blank class="btn btn-primary btn-xs" role="button">PDF</a>
                    <button class="btn btn-primary btn-xs">S</button> 
                    <br/>
                    <i>Yu Wang, Bortik Bandyopadhyay, Aniket Chakrabarti, David Sivakoff and Srinivasan Parthasarathy</i><br/>

                    <div id="pid22" class="collapse">
                    <strong>Abstract:</strong> This paper proposes a novel scalable node sampling algorithm for large graphs that can achieve better \textit{spread} 
                    or diversity across communities intrinsic to the graph without requiring any costly pre-processing steps.
                    The proposed method leverages a simple iterative sampling technique controlled by two parameters: \textit{infection rate}, 
                    that controls the dynamics of the procedure and \textit{removal threshold} that affects the end-of-procedure sampling size. 
                    We present theoretical analyses of the sampling probability for this method on the celebrated Erd\H os--R\'enyi graph model, 
                    and of the community diversity on the Stochastic Block Model. 
                    Efficiently finding small samples with high diversity from large graphs has a number of practical applications such as online survey and community detection. 
                    Our method achieves very high community diversity with extremely low sampling budget on both synthetic and real-world graphs, with either balanced or imbalanced communities.
                    We leverage the proposed sampling technique on community detection and show it outperforms the baselins of the same type.

                    <br/><br/><strong>Keywords:</strong> Sampling, Graph Mining, Community Detection
                    <hr/>
                    </div>

                    <div id="bib22" class="collapse">
                    @inproceedings{mlg2018_22,<br/>
                    title={Spread Sampling for Graphs: Theory and Application},<br/>
                    author={Yu Wang, Bortik Bandyopadhyay, Aniket Chakrabarti, David Sivakoff and Srinivasan Parthasarathy},<br/>
                    booktitle={Proceedings of the 14th International Workshop on Mining and Learning with Graphs (MLG)},<br/>
                    year={2018}<br/>
                    }
                    <hr/>
                    </div>

                    </p>

                    <p class="large text-muted">
                    <strong>Temporal Walk Based Centrality Metric for Graph Streams</strong> 
                    <button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#pid27">Abstract</button> 
                    <button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#bib27">BibTex</button> 
                    <a href="papers/MLG2018_paper_27.pdf" target=_blank class="btn btn-primary btn-xs" role="button">PDF</a>
                    <button class="btn btn-primary btn-xs">S</button> 
                    <br/>
                    <i>Ferenc Beres, Andras A. Benczur and Robert Palovics</i><br/>

                    <div id="pid27" class="collapse">
                    <strong>Abstract:</strong> Centrality measures account for the importance of the nodes of a network.
                    In the seminal study of Boldi and Vigna (2014), the comparative evaluation of centrality measures was termed a difficult, arduous task.
                    In networks with fast dynamics, such as the Twitter mention or retweet graphs, predicting emerging centrality is even more challenging.
                    Our main result is a new, temporal walk based dynamic centrality measure that models temporal information propagation by considering the order of edge creation.
                    This measure outperforms graph snapshot based static and other recently proposed dynamic centrality measures in assigning the highest time-aware centrality to the actually relevant nodes of the network.
                    One of our main contributions is creating a quantitative experiment to assess temporal centrality metrics.
                    <br/><br/><strong>Keywords:</strong> Temporal graphs, Twitter, Centrality, Data Stream
                    <hr/>
                    </div>

                    <div id="bib27" class="collapse">
                    @inproceedings{mlg2018_27,<br/>
                    title={Temporal Walk Based Centrality Metric for Graph Streams},<br/>
                    author={Ferenc Beres, Andras A. Benczur and Robert Palovics},<br/>
                    booktitle={Proceedings of the 14th International Workshop on Mining and Learning with Graphs (MLG)},<br/>
                    year={2018}<br/>
                    }
                    <hr/>
                    </div>

                    </p>

                    <p class="large text-muted">
                    <strong>A Method for Learning Representations of Signed Networks</strong> 
                    <button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#pid31">Abstract</button> 
                    <button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#bib31">BibTex</button> 
                    <a href="papers/MLG2018_paper_31.pdf" target=_blank class="btn btn-primary btn-xs" role="button">PDF</a>
                    <button class="btn btn-primary btn-xs">S</button> 
                    <br/>
                    <i>Inzamam Rahaman and Patrick Hosein</i><br/>

                    <div id="pid31" class="collapse">
                    <strong>Abstract:</strong> There has been an increasing interest in learning low dimensional
                    representations of graphs that can be exploited in machine learning
                    and data mining. The geometric relationships between the
                    representations learned for nodes should reflect relationships between
                    nodes in the graph. Most work has concentrated on unsigned
                    graphs, which only model positive relationships. However, such
                    techniques can be inadequate for signed graphs, which model both
                    positive and negative relationships. In this work in progress paper,
                    we present a method - StEM (Signed neTwork Embedding Model) -
                    for learning representations of signed networks that can achieve
                    good performance on the tasks of visualization, node classification,
                    and signed link prediction.
                    <br/><br/><strong>Keywords:</strong> Signed Networks, Representation Learning, Graph Embedding
                    <hr/>
                    </div>

                    <div id="bib31" class="collapse">
                    @inproceedings{mlg2018_31,<br/>
                    title={A Method for Learning Representations of Signed Networks},<br/>
                    author={Inzamam Rahaman and Patrick Hosein},<br/>
                    booktitle={Proceedings of the 14th International Workshop on Mining and Learning with Graphs (MLG)},<br/>
                    year={2018}<br/>
                    }
                    <hr/>
                    </div>

                    </p>

                    <p class="large text-muted">
                    <strong>Logistic-Tropical Decompositions and Nested Subgraphs</strong> 
                    <button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#pid35">Abstract</button> 
                    <button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#bib35">BibTex</button> 
                    <a href="papers/MLG2018_paper_35.pdf" target=_blank class="btn btn-primary btn-xs" role="button">PDF</a>
                    <button class="btn btn-primary btn-xs">S</button> 
                    <br/>
                    <i>Sanjar Karaev, Saskia Metzler and Pauli Miettinen</i><br/>

                    <div id="pid35" class="collapse">
                    <strong>Abstract:</strong> Communities in graphs are usually modelled as (quasi-) cliques, but this is not the only -- or even necessarily the best -- model. Other models, such as stars, hyperbolic shapes, or core-periphery communities have been proposed as well. These can be generalized to nested subgraphs, i.e. graphs whose adjacency matrix is nested. In this paper, we study the problem of summarizing a graph as a union of nested subgraphs. We approach the problem by applying a recent characterization of nested graphs using rounding rank. We extend this characterization to sets of overlapping nested matrices using tropical algebra. This allows us to model the problem as a thresholded subtropical matrix factorization, and design an algorithm for a maximum-likelihood version of the problem. Our experiments show that our algorithm is very scalable and can find good summarizations using structures that cannot be concisely expressed in terms of normal matrix factorizations.
                    <br/><br/><strong>Keywords:</strong> tropical algebra, community detection, nested matrix, rounding rank
                    <hr/>
                    </div>

                    <div id="bib35" class="collapse">
                    @inproceedings{mlg2018_35,<br/>
                    title={Logistic-Tropical Decompositions and Nested Subgraphs},<br/>
                    author={Sanjar Karaev, Saskia Metzler and Pauli Miettinen},<br/>
                    booktitle={Proceedings of the 14th International Workshop on Mining and Learning with Graphs (MLG)},<br/>
                    year={2018}<br/>
                    }
                    <hr/>
                    </div>

                    </p>

                    <p class="large text-muted">
                    <strong>Graph CNN + LSTM Framework For Dynamic Macroscopic Traffic Congestion Prediction</strong> 
                    <button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#pid41">Abstract</button> 
                    <button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#bib41">BibTex</button> 
                    <a href="papers/MLG2018_paper_41.pdf" target=_blank class="btn btn-primary btn-xs" role="button">PDF</a>
                    <button class="btn btn-primary btn-xs">S</button> 
                    <br/>
                    <i>Sudatta Mohanty and Alexey Pozdnukhov</i><br/>

                    <div id="pid41" class="collapse">
                    <strong>Abstract:</strong> Accurate real-time predictions for traffic congestion in a region and knowledge of its causes may allow implementation of effective dynamic control strategies. However, the complex nature of congestion propagation and network-wide spatio-temporal correlations make prediction challenging. To facilitate this process, we define a novel dynamic state variable corresponding to a zone with homogeneous and slowly evolving traffic, called Macroscopic Congestion Level (MCL). We hypothesize that future MCL is a function of the current and past network states for the region-wide network, defined by Origin-Destination (O-D) demand, link counts, link travel times and observed MCL values. We leverage the fact that transportation systems often generate graph-like data either because physical movement is constrained to a road network or due to the coordination of travel choices made by various individuals. We construct a knowledge graph and implement a Graph-CNN + LSTM model to make real-time predictions. The model accuracy is tested against several baselines: (i) 1-NN model, (ii) LSTM-only model and (iii) Graph-CNN + LSTM model with no road network related priors; on simulated data of home-work and work-home trips on a simplified freeway network representing nine counties in the SF Bay Area. Our results indicate improvement in performance which may be attributed to better feature learning by Graph-CNN. Finally, we develop a Neural Attention based framework to produce a spatio-temporal saliency heatmap of input variables. Tests on a toy network with hypothetical demand demonstrate the effectiveness of the proposed framework for identifying the specific cause of congestion.

                    This paper has been jointly submitted to 14th International Workshop On Mining And Learning With Graphs as well as 3rd Mining Urban Data Workshop, both organized in conjunction with ACM SIGKDD 2018.
                    <br/><br/><strong>Keywords:</strong> Macroscopic Fundamental Diagram, Macroscopic Congestion Level, Graph CNN + LSTM, Neural Attention
                    <hr/>
                    </div>

                    <div id="bib41" class="collapse">
                    @inproceedings{mlg2018_41,<br/>
                    title={Graph CNN + LSTM Framework For Dynamic Macroscopic Traffic Congestion Prediction},<br/>
                    author={Sudatta Mohanty and Alexey Pozdnukhov},<br/>
                    booktitle={Proceedings of the 14th International Workshop on Mining and Learning with Graphs (MLG)},<br/>
                    year={2018}<br/>
                    }
                    <hr/>
                    </div>

                    </p>

                    <p class="large text-muted">
                    <strong>Temporal Graph Generation Based on a Distribution of Temporal Motifs</strong> 
                    <button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#pid42">Abstract</button> 
                    <button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#bib42">BibTex</button> 
                    <a href="papers/MLG2018_paper_42.pdf" target=_blank class="btn btn-primary btn-xs" role="button">PDF</a>
                    <button class="btn btn-primary btn-xs">S</button> 
                    <br/>
                    <i>Sumit Purohit, Lawrence B Holder and George Chin</i><br/>

                    <div id="pid42" class="collapse">
                    <strong>Abstract:</strong> Generating a synthetic graph that is similar to a given real-world graph is a critical requirement for privacy preservation and benchmarking purposes. Various generative models attempt to generate static graphs similar to real-world graphs. However, generation of temporal graphs is still an open research area. We present a temporal-motif based approach to generate synthetic temporal graph datasets and show results from three real-world use cases. We show that our approach can generate high fidelity synthetic graph. We also show that this approach can also generate multi-type heterogeneous graph. We also present a parameterized version of our approach which can generate linear, sub-linear, and super-linear preferential attachment graph.
                    <br/><br/><strong>Keywords:</strong> Temporal Graph, Graph Generative Model, Motifs Distribution
                    <hr/>
                    </div>

                    <div id="bib42" class="collapse">
                    @inproceedings{mlg2018_42,<br/>
                    title={Temporal Graph Generation Based on a Distribution of Temporal Motifs},<br/>
                    author={Sumit Purohit, Lawrence B Holder and George Chin},<br/>
                    booktitle={Proceedings of the 14th International Workshop on Mining and Learning with Graphs (MLG)},<br/>
                    year={2018}<br/>
                    }
                    <hr/>
                    </div>

                    </p>

                    <p class="large text-muted">
                    <strong>Relevance Measurements in Online Signed Social Networks</strong> 
                    <button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#pid48">Abstract</button> 
                    <button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#bib48">BibTex</button> 
                    <a href="papers/MLG2018_paper_48.pdf" target=_blank class="btn btn-primary btn-xs" role="button">PDF</a>
                    <button class="btn btn-primary btn-xs">S</button> 
                    <br/>
                    <i>Tyler Derr, Chenxing Wang, Suhang Wang and Jiliang Tang</i><br/>

                    <div id="pid48" class="collapse">
                    <strong>Abstract:</strong> Measuring relevance for two nodes is fundamental to social network analysis, which has been proven to benefit many network analysis tasks and applications such as link prediction, node classification, community detection, search and recommendations. The majority of existing relevance measurements focused on unsigned social networks (or networks with only positive links). However, social media provides mechanisms that allow online users to specify negative links in addition to positive ones. For example, Slashdot users can create foe links; users in Epinions can establish distrust relations; while users in Facebook and Twitter can block or unfriend others.  Thereby, social networks with both positive and negative links (or signed social networks) become ubiquitous in social media and have attracted increasing attention in recent years. On the one hand, it is evident from recent studies that negative links have added value in a number of analytical tasks. On the other hand, the availability of negative links challenges existing relevance measurements designed for unsigned networks. Hence, we need dedicated relevance measurements for signed social networks.  In this paper, we present an initial and comprehensive investigation on signed relevance measurements and design numerous relevance measurements for signed social networks from both local and global perspectives. Empirical experiments on four real-world signed social networks demonstrate the importance of negative links in building signed relevance measurements and their effects on social network analysis tasks. 
                    <br/><br/><strong>Keywords:</strong> Signed networks, Relevance measurement, Balance theory
                    <hr/>
                    </div>

                    <div id="bib48" class="collapse">
                    @inproceedings{mlg2018_48,<br/>
                    title={Relevance Measurements in Online Signed Social Networks},<br/>
                    author={Tyler Derr, Chenxing Wang, Suhang Wang and Jiliang Tang},<br/>
                    booktitle={Proceedings of the 14th International Workshop on Mining and Learning with Graphs (MLG)},<br/>
                    year={2018}<br/>
                    }
                    <hr/>
                    </div>

                    </p>

                    <p class="large text-muted">
                    <strong>A Marketing Game: a rigorous model for strategic resource allocation</strong> 
                    <button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#pid53">Abstract</button> 
                    <button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#bib53">BibTex</button> 
                    <a href="papers/MLG2018_paper_53.pdf" target=_blank class="btn btn-primary btn-xs" role="button">PDF</a>
                    <button class="btn btn-primary btn-xs">S</button> 
                    <br/>
                    <i>Matthew Reyes</i><br/>

                    <div id="pid53" class="collapse">
                    <strong>Abstract:</strong> We have recently introduced a model of consumer choice that parametrizes actions taken by a marketer to influence decisions made within a social network. The foundation of our model is the theory of random utility due to McFadden and others, and the extension to contingent decision-making pioneered by Blume, on top of which we introduced a marketer for each of the alternatives from which consumers make their respective choice decisions, and the concept of a marketing response indicating the marketing strength that results from a particular dollar investment. 
                    In this paper we follow up on our previous work and consider a number of questions relevant to marketing on topologies on interest.
                    <br/><br/><strong>Keywords:</strong> interaction games, product adoption, marketing, choice response, Glauber dynamics, Gibbs distributions
                    <hr/>
                    </div>

                    <div id="bib53" class="collapse">
                    @inproceedings{mlg2018_53,<br/>
                    title={A Marketing Game: a rigorous model for strategic resource allocation},<br/>
                    author={Matthew Reyes},<br/>
                    booktitle={Proceedings of the 14th International Workshop on Mining and Learning with Graphs (MLG)},<br/>
                    year={2018}<br/>
                    }
                    <hr/>
                    </div>

                    </p>

                    <p class="large text-muted">
                    <strong>GeniePath: Graph Neural Networks with Adaptive Receptive Paths</strong> 
                    <button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#pid59">Abstract</button> 
                    <button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#bib59">BibTex</button> 
                    <a href="papers/MLG2018_paper_59.pdf" target=_blank class="btn btn-primary btn-xs" role="button">PDF</a>
                    <button class="btn btn-primary btn-xs">S</button> 
                    <br/>
                    <i>Ziqi Liu and Jun Zhou</i><br/>

                    <div id="pid59" class="collapse">
                    <strong>Abstract:</strong> We present, GeniePath, a scalable approach for learning adaptive receptive fields of neural networks defined on permutation invariant graph data. In GeniePath, we propose an adaptive path layer consists of two functions designed for breadth and depth exploration respectively, where the former learns the importance of different sized neighborhoods, while the latter extracts and filters signals aggregated from neighbors of different hops away. Our method works both in transductive and inductive settings, and extensive experiments com- pared with state-of-the-art methods show that our approaches are useful especially on large graph.
                    <br/><br/><strong>Keywords:</strong> graph neural networks, graph representation learning, receptive field learning
                    <hr/>
                    </div>

                    <div id="bib59" class="collapse">
                    @inproceedings{mlg2018_59,<br/>
                    title={GeniePath: Graph Neural Networks with Adaptive Receptive Paths},<br/>
                    author={Ziqi Liu and Jun Zhou},<br/>
                    booktitle={Proceedings of the 14th International Workshop on Mining and Learning with Graphs (MLG)},<br/>
                    year={2018}<br/>
                    }
                    <hr/>
                    </div>

                    </p>

                    <p class="large text-muted">
                    <strong>When is a Network a Network? Multi-Order Graphical Model Selection in Pathways and Temporal Networks</strong> 
                    <button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#pid55">Abstract</button> 
                    <button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#bib55">BibTex</button> 
                    <a href="papers/MLG2018_paper_55.pdf" target=_blank class="btn btn-primary btn-xs" role="button">PDF</a> 
                    <br/>
                    <i>Ingo Scholtes</i><br/>

                    <div id="pid55" class="collapse">
                    <strong>Abstract:</strong> We introduce a framework for the modeling of sequential data capturing pathways of varying lengths observed in a network. Such data are important, e.g., when studying click streams in the Web, travel patterns in transportation systems, information cascades in social networks, biological pathways, or time-stamped social interactions. While it is common to apply graph analytics and network analysis to such data, recent works have shown that temporal correlations can invalidate the results of such methods. This raises a fundamental question: When is a network abstraction of sequential data justified? Addressing this open question, we propose a framework that combines Markov chains of multiple, higher orders into a multi-layer graphical model that captures temporal correlations in pathways at multiple length scales simultaneously. We develop a model selection technique to infer the optimal number of layers of such a model and show that it outperforms baseline Markov order detection techniques. An application to eight data sets on pathways and temporal networks shows that it allows to infer graphical models that capture both topological and temporal characteristics of such data. Our work highlights fallacies of graph mining and network analysis techniques and provides a principled answer to the open question when they are justified. Generalizing network representations to multi-order graphical models, it opens perspectives for new data mining and machine learning algorithms for graphs.

                    This submission is a shortened version of a research paper published at KDD'17.
                    <br/><br/><strong>Keywords:</strong> higher-order network analysis, representation learning, model selection, dynamic social networks, pathway data, time series analysis, node ranking
                    <hr/>
                    </div>

                    <div id="bib55" class="collapse">
                    @inproceedings{mlg2018_55,<br/>
                    title={When is a Network a Network? Multi-Order Graphical Model Selection in Pathways and Temporal Networks},<br/>
                    author={Ingo Scholtes},<br/>
                    booktitle={Proceedings of the 14th International Workshop on Mining and Learning with Graphs (MLG)},<br/>
                    year={2018}<br/>
                    }
                    <hr/>
                    </div>

                    </p>

                    <p class="large text-muted">
                    <strong>Towards Shortest Paths Via Adiabatic Quantum Computing</strong> 
                    <button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#pid7">Abstract</button> 
                    <button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#bib7">BibTex</button> 
                    <a href="papers/MLG2018_paper_7.pdf" target=_blank class="btn btn-primary btn-xs" role="button">PDF</a> 
                    <br/>
                    <i>Christian Bauckhage, Rafet Sifa, Jannis Schücker, Cesar Ojeda, Eduado Brito and Kostadin Cvejoski</i><br/>

                    <div id="pid7" class="collapse">
                    <strong>Abstract:</strong> Since first working quantum computers are now available, accelerated developments of this technology may be expected. This will likely impact graph- or network analysis because quantum computers promise fast solutions for many problems in these areas. In this paper, we explore the use of adiabatic quantum computing in finding shortest paths. We devise an Ising energy minimization formulation for this task and discuss how to set up a system of quantum bits to find minimum energy states of the model. In simulation experiments, we numerically solve the corresponding Schroedinger equations and observe our approach to work well. This evidences that shortest path computation can at least be assisted by quantum computers.
                    <br/><br/><strong>Keywords:</strong> graph analysis, shortest paths, Ising models, adiabatic quantum computing
                    <hr/>
                    </div>

                    <div id="bib7" class="collapse">
                    @inproceedings{mlg2018_7,<br/>
                    title={Towards Shortest Paths Via Adiabatic Quantum Computing},<br/>
                    author={Christian Bauckhage, Rafet Sifa, Jannis Schücker, Cesar Ojeda, Eduado Brito and Kostadin Cvejoski},<br/>
                    booktitle={Proceedings of the 14th International Workshop on Mining and Learning with Graphs (MLG)},<br/>
                    year={2018}<br/>
                    }
                    <hr/>
                    </div>

                    </p>

                    <p class="large text-muted">
                    <strong>Semi-Supervised Learning on Graphs Based on Local Label Distributions</strong> 
                    <button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#pid8">Abstract</button> 
                    <button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#bib8">BibTex</button> 
                    <a href="papers/MLG2018_paper_8.pdf" target=_blank class="btn btn-primary btn-xs" role="button">PDF</a> 
                    <br/>
                    <i>Evgeniy Faerman, Felix Borutta, Julian Busch and Matthias Schubert</i><br/>

                    <div id="pid8" class="collapse">
                    <strong>Abstract:</strong> Most approaches that tackle the problem of node classification consider nodes to be similar, if they have shared neighbors or are close to each other in the graph. Recent methods for attributed graphs additionally take attributes of neighboring nodes into account. We argue that the class labels of the neighbors bear important information and considering them helps to improve classification quality. Two nodes which are similar based on class labels in their neighborhood do not need to be close-by in the graph and may even belong to different connected components. In this work, we propose a novel approach for the semi-supervised node classification. Precisely, we propose a new node embedding which is based on the class labels in the local neighborhood of a node. We show that this is a different setting from attribute-based embeddings and thus, we propose a new method to learn label-based node embeddings which can mirror a variety of relations between the class labels of neighboring nodes. Our experimental evaluation demonstrates that our new methods can significantly improve the prediction quality on real world data sets.
                    <br/><br/><strong>Keywords:</strong> Feature learning, Graph representations, Node embeddings, Node classification
                    <hr/>
                    </div>

                    <div id="bib8" class="collapse">
                    @inproceedings{mlg2018_8,<br/>
                    title={Semi-Supervised Learning on Graphs Based on Local Label Distributions},<br/>
                    author={Evgeniy Faerman, Felix Borutta, Julian Busch and Matthias Schubert},<br/>
                    booktitle={Proceedings of the 14th International Workshop on Mining and Learning with Graphs (MLG)},<br/>
                    year={2018}<br/>
                    }
                    <hr/>
                    </div>

                    </p>

                    <p class="large text-muted">
                    <strong>Adaptive Personalized Knowledge Graph Summarization</strong> 
                    <button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#pid11">Abstract</button> 
                    <button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#bib11">BibTex</button> 
                    <a href="papers/MLG2018_paper_11.pdf" target=_blank class="btn btn-primary btn-xs" role="button">PDF</a> 
                    <br/>
                    <i>Lukas Faber, Tara Safavi, Davide Mottin, Emmanuel Müller and Danai Koutra</i><br/>

                    <div id="pid11" class="collapse">
                    <strong>Abstract:</strong> Knowledge graphs, which are rich networks of entities and concepts connected via multiple types of relationships, have gained traction as powerful structures for natural language understanding and question answering. Although recent research efforts have started to address efficient querying and storage of knowledge graphs, such methods are neither \emph{user-driven} nor \emph{flexible to changes in the data}, both of which are important in the real world. We thus introduce and motivate \textbf{adaptive knowledge graph summarization} to create personalized local knowledge graphs that contain only the information most relevant to an individual user's interests. Such concise summaries may be stored on mobile devices, allowing for fast interactive querying, and constantly updated to serve changing user needs and data evolution. In this position paper, we make a case for adaptive knowledge graph summarization, outlining promising approaches toward efficient, personalized knowledge graph management.
                    <br/><br/><strong>Keywords:</strong> graph summarization, knowledge graphs, personalization
                    <hr/>
                    </div>

                    <div id="bib11" class="collapse">
                    @inproceedings{mlg2018_11,<br/>
                    title={Adaptive Personalized Knowledge Graph Summarization},<br/>
                    author={Lukas Faber, Tara Safavi, Davide Mottin, Emmanuel Müller and Danai Koutra},<br/>
                    booktitle={Proceedings of the 14th International Workshop on Mining and Learning with Graphs (MLG)},<br/>
                    year={2018}<br/>
                    }
                    <hr/>
                    </div>

                    </p>

                    <p class="large text-muted">
                    <strong>GraphRAD: A Graph-based Risky Account Detection System</strong> 
                    <button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#pid12">Abstract</button> 
                    <button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#bib12">BibTex</button> 
                    <a href="papers/MLG2018_paper_12.pdf" target=_blank class="btn btn-primary btn-xs" role="button">PDF</a> 
                    <br/>
                    <i>Jun Ma, Danqing Zhang, Yun Wang, Yan Zhang and Alexey Pozdnoukhov</i><br/>

                    <div id="pid12" class="collapse">
                    <strong>Abstract:</strong> Given the linked account graph with tens of millions of vertices, and a list of confirmed risky accounts, how can we quickly find a short list of potential risky accounts for further human expert investigation? Most mainstream graph-based fraud detection algorithms focusing on detecting dense blocks of fake follows, or fake reviews from the social media graph, however, do not align well with the answer of the question.
                    Here we hypothesize that fraud accounts share dense connections within a "fraud community", but have less so with accounts outside of community. We propose GraphRAD, a risky account detection system based on local graph clustering algorithms. Our experiments show that from a real-world account graph of 60 million vertices and 500 million edges, GraphRAD was able to catch 67 previously unidentified fraud accounts by proposing 28 small-scale local communities, which is significantly more effective than the baseline model.
                    The paper is submitted as work-in-progress.
                    <br/><br/><strong>Keywords:</strong> fraud detection, payment fraud, local graph clustering, community detection, semi-supervised learning, graph regularization
                    <hr/>
                    </div>

                    <div id="bib12" class="collapse">
                    @inproceedings{mlg2018_12,<br/>
                    title={GraphRAD: A Graph-based Risky Account Detection System},<br/>
                    author={Jun Ma, Danqing Zhang, Yun Wang, Yan Zhang and Alexey Pozdnoukhov},<br/>
                    booktitle={Proceedings of the 14th International Workshop on Mining and Learning with Graphs (MLG)},<br/>
                    year={2018}<br/>
                    }
                    <hr/>
                    </div>

                    </p>

                    <p class="large text-muted">
                    <strong>Jointly learning relevant subgraph patterns and nonlinear models of their indicators</strong> 
                    <button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#pid17">Abstract</button> 
                    <button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#bib17">BibTex</button> 
                    <a href="papers/MLG2018_paper_17.pdf" target=_blank class="btn btn-primary btn-xs" role="button">PDF</a> 
                    <br/>
                    <i>Ryo Shirakawa, Yusei Yokoyama, Fumiya Okazaki and Ichigaku Takigawa</i><br/>

                    <div id="pid17" class="collapse">
                    <strong>Abstract:</strong> Classification and regression in which the inputs are graphs of arbitrary size and shape have been paid attention in various fields such as computational chemistry and bioinformatics. Subgraph indicators are often used as the most fundamental features, but the number of possible subgraph patterns are intractably large due to the combinatorial explosion. We propose a novel efficient algorithm to jointly learn relevant subgraph patterns and nonlinear models of their indicators. Previous methods for such joint learning of subgraph features and models are based on search for single best subgraph features with specific pruning and boosting procedures of adding their indicators one by one, which result in linear models of subgraph indicators. In contrast, the proposed approach is based on directly learning regression trees for graph inputs using a newly derived bound of the total sum of squares for data partitions by a given subgraph feature, and thus can learn nonlinear models through standard gradient boosting. An illustrative example we call the Graph-XOR problem to consider nonlinearity, numerical experiments with real datasets, and scalability comparisons to naïve approaches using explicit pattern enumeration are also presented. 
                    <br/><br/><strong>Keywords:</strong> Graph classification and regression, subgraph pattern mining, nonlinear supervised learning
                    <hr/>
                    </div>

                    <div id="bib17" class="collapse">
                    @inproceedings{mlg2018_17,<br/>
                    title={Jointly learning relevant subgraph patterns and nonlinear models of their indicators},<br/>
                    author={Ryo Shirakawa, Yusei Yokoyama, Fumiya Okazaki and Ichigaku Takigawa},<br/>
                    booktitle={Proceedings of the 14th International Workshop on Mining and Learning with Graphs (MLG)},<br/>
                    year={2018}<br/>
                    }
                    <hr/>
                    </div>

                    </p>

                    <p class="large text-muted">
                    <strong>A Graph Model with Indirect Co-location Links</strong> 
                    <button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#pid19">Abstract</button> 
                    <button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#bib19">BibTex</button> 
                    <a href="papers/MLG2018_paper_19.pdf" target=_blank class="btn btn-primary btn-xs" role="button">PDF</a> 
                    <br/>
                    <i>Md Shahzamal, Raja Jurdak, Bernard Mans and Frank de Hoog</i><br/>

                    <div id="pid19" class="collapse">
                    <strong>Abstract:</strong> Graph models are widely used to analyse diffusion processes embedded in social contacts and to develop applications. A range of graph models are available to replicate the underlying social structures and dynamics realistically. However, most of the current graph models can only consider concurrent interactions among individuals in the co-located interaction networks. However, they do not account for indirect interactions that can transmit spreading items to individuals who visit the same locations at different times but within a certain time limit. The diffusion phenomena occurring through direct and indirect interactions is called same place different time (SPDT) diffusion. This paper introduces a model to synthesize co-located interaction graphs capturing both direct interactions, where individuals meet at a location, and indirect interactions, where individuals visit the same location at different times within a set timeframe. We analyze 60 million location updates made by 2 million users from a social networking application to characterize the graph properties, including the space-time correlations and its time evolving characteristics, such as bursty or ongoing behaviors. The generated synthetic graph reproduces diffusion dynamics of a realistic contact graph, and reduces the prediction error by up to 82 when compare to other contact graph models demonstrating its potential for forecasting epidemic spread.
                    <br/><br/><strong>Keywords:</strong> Network embedding models, Graph mining, Statistical models of graph structure, Large-scale analysis and modeling, Social networks, Spatio-temporal data
                    <hr/>
                    </div>

                    <div id="bib19" class="collapse">
                    @inproceedings{mlg2018_19,<br/>
                    title={A Graph Model with Indirect Co-location Links},<br/>
                    author={Md Shahzamal, Raja Jurdak, Bernard Mans and Frank de Hoog},<br/>
                    booktitle={Proceedings of the 14th International Workshop on Mining and Learning with Graphs (MLG)},<br/>
                    year={2018}<br/>
                    }
                    <hr/>
                    </div>

                    </p>

                    <p class="large text-muted">
                    <strong>Probabilistic Random Walks for Churn Prediction using Representation Learning</strong> 
                    <button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#pid24">Abstract</button> 
                    <button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#bib24">BibTex</button> 
                    <a href="papers/MLG2018_paper_24.pdf" target=_blank class="btn btn-primary btn-xs" role="button">PDF</a> 
                    <br/>
                    <i>Sandra Mitrovic and Jochen De Weerdt</i><br/>

                    <div id="pid24" class="collapse">
                    <strong>Abstract:</strong> Unleashing the full potential of data is oftentimes a cumbersome task, especially when dealing with network data. It is therefore possible that while focusing on one part of the solution, other valuable pieces of information remain under-treated leading to under-performing results. In this work, we zoom into the nature of an augmentation of call graphs devised for addressing churn prediction in telco. By shifting the focus from a homogeneous to a heterogeneous perspective, by defining different probabilistic meta paths, and by applying representation learning on graphs using these defined meta paths, we demonstrate the benefits of this approach, not only by means of improvements of predictive results, but also with promising insights regarding the interplay of meta path type and predictive outcome. As such, this is still a work in progress but the current results have also been submitted to (and are currently under review at) another conference.

                    <br/><br/><strong>Keywords:</strong> Probabilistic Random Walks, Node Embedding, RFM-Augmented Networks, Churn Prediction
                    <hr/>
                    </div>

                    <div id="bib24" class="collapse">
                    @inproceedings{mlg2018_24,<br/>
                    title={Probabilistic Random Walks for Churn Prediction using Representation Learning},<br/>
                    author={Sandra Mitrovic and Jochen De Weerdt},<br/>
                    booktitle={Proceedings of the 14th International Workshop on Mining and Learning with Graphs (MLG)},<br/>
                    year={2018}<br/>
                    }
                    <hr/>
                    </div>

                    </p>

                    <p class="large text-muted">
                    <strong>Mining Subjectively Interesting Attributed Subgraphs</strong> 
                    <button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#pid26">Abstract</button> 
                    <button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#bib26">BibTex</button> 
                    <a href="papers/MLG2018_paper_26.pdf" target=_blank class="btn btn-primary btn-xs" role="button">PDF</a> 
                    <br/>
                    <i>Anes Bendimerad, Ahmad Mel, Jefrey Lijffijt, Marc Plantevit, Céline Robardet and Tijl De Bie</i><br/>

                    <div id="pid26" class="collapse">
                    <strong>Abstract:</strong> Community detection in graphs, data clustering, and local pattern mining are three mature fields of data mining and machine learning.
                    In recent years, attributed subgraph mining is emerging as a new powerful data mining task in the intersection of these areas. Given a graph and a set of attributes for each vertex, attributed subgraph mining aims to find cohesive subgraphs for which (a subset of) the attribute values has exceptional values in some sense. 
                    While research on this task can borrow from the three abovementioned fields, the principled integration of graph and attribute data poses two challenges: the definition of a pattern language that is intuitive and lends itself to efficient search strategies, and the formalization of the interestingness of such patterns. 
                    We propose an integrated solution to both of these challenges. The proposed pattern language improves upon prior work in being both highly flexible and intuitive.
                    We show how an effective and principled algorithm can enumerate patterns of this language. The proposed approach for quantifying interestingness of patterns of this language is rooted in information theory, and is able to account for prior knowledge on the data. 
                    Prior work typically quantifies interestingness for the cohesion of the subgraph and for the exceptionality of its attributes separately, to combine these in a parameterized trade-off. Instead, in our proposal this trade-off is implicitly handled in a principled, parameter-free manner. 
                    Extensive empirical results confirm the proposed pattern syntax is intuitive, and the interestingness measure aligns well with actual subjective interestingness.
                    <br/><br/><strong>Keywords:</strong> Graphs, Networks, Subjective Interestingness, Subgraph Mining
                    <hr/>
                    </div>

                    <div id="bib26" class="collapse">
                    @inproceedings{mlg2018_26,<br/>
                    title={Mining Subjectively Interesting Attributed Subgraphs},<br/>
                    author={Anes Bendimerad, Ahmad Mel, Jefrey Lijffijt, Marc Plantevit, Céline Robardet and Tijl De Bie},<br/>
                    booktitle={Proceedings of the 14th International Workshop on Mining and Learning with Graphs (MLG)},<br/>
                    year={2018}<br/>
                    }
                    <hr/>
                    </div>

                    </p>

                    <p class="large text-muted">
                    <strong>From clusters to queries: exploiting uncertainty in the modularity landscape of complex networks</strong> 
                    <button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#pid36">Abstract</button> 
                    <button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#bib36">BibTex</button> 
                    <a href="papers/MLG2018_paper_36.pdf" target=_blank class="btn btn-primary btn-xs" role="button">PDF</a> 
                    <br/>
                    <i>James Gilbert and Jamie Twycross</i><br/>

                    <div id="pid36" class="collapse">
                    <strong>Abstract:</strong> Uncovering latent community structure in complex networks is a field that has received an enormous amount of attention.
                    Unfortunately, whilst potentially very powerful, unsupervised methods for uncovering labels based on topology alone has been shown to suffer from several difficulties.
                    For example, the search space for many module extraction approaches, such as the modularity maximisation algorithm, appears to be extremely glassy, with many high valued solutions that lack any real similarity to one another.
                    However, in this paper we argue that this is not a flaw with the modularity maximisation algorithm but, rather, information that can be used to aid the context specific classification of functional relationships between vertices.
                    Formally, we present an approach for generating a high value modularity consensus space for a network, based on the ensemble space of locally optimal modular partitions.
                    We then use this approach to uncover latent relationships, given small query sets.
                    The methods developed in this paper are applied to biological and social datasets with ground-truth label data, using a small number of examples used as seed sets to uncover relationships.
                    When tested on both real and synthetic datasets our method is shown to achieve high levels of classification accuracy in a context specific manner, with results comparable to random walk with restart methods.
                    <br/><br/><strong>Keywords:</strong> Complex networks, Community detection, Graph clustering, Semi-supervised Learning, Analysis of biological networks
                    <hr/>
                    </div>

                    <div id="bib36" class="collapse">
                    @inproceedings{mlg2018_36,<br/>
                    title={From clusters to queries: exploiting uncertainty in the modularity landscape of complex networks},<br/>
                    author={James Gilbert and Jamie Twycross},<br/>
                    booktitle={Proceedings of the 14th International Workshop on Mining and Learning with Graphs (MLG)},<br/>
                    year={2018}<br/>
                    }
                    <hr/>
                    </div>

                    </p>

                    <p class="large text-muted">
                    <strong>Clustering Affiliation Inference from Graph Samples</strong> 
                    <button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#pid37">Abstract</button> 
                    <button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#bib37">BibTex</button> 
                    <a href="papers/MLG2018_paper_37.pdf" target=_blank class="btn btn-primary btn-xs" role="button">PDF</a> 
                    <br/>
                    <i>Jianpeng Zhang, Kaijie Zhu, Yulong Pei, George Fletcher and Mykola Pechenizkiy</i><br/>

                    <div id="pid37" class="collapse">
                    <strong>Abstract:</strong> Graph sampling is a widely-used approach to address the scalability issue when analyzing large-scale graphs. Several promising cluster-preserving sampling algorithms have been proposed. However, once the clustering structure on a sampled graph is obtained, we may still need a method to infer the clustering affiliations of all other nodes in the original graph from the clustered nodes in the sampled subgraph. In this paper, we present a new two-stage clustering inference (\textit{TCI}) method to infer clustering affiliations of all nodes in the original graph. \textit{TCI} is composed of two stages: 1) initialization of clustering affiliations for unsampled nodes based on computed neighborhood affiliation information; 2) label propagation for the whole graph. Our experimental results demonstrate that the proposed \textit{TCI} method in conjunction with any considered cluster-preserving sampling strategy is capable of inferring the clustering affiliation of the population commendably, and it performs better than the competing methods.
                    <br/><br/><strong>Keywords:</strong> Graph Sampling, Clustering Structure, Population Inference, Representative Sample
                    <hr/>
                    </div>

                    <div id="bib37" class="collapse">
                    @inproceedings{mlg2018_37,<br/>
                    title={Clustering Affiliation Inference from Graph Samples},<br/>
                    author={Jianpeng Zhang, Kaijie Zhu, Yulong Pei, George Fletcher and Mykola Pechenizkiy},<br/>
                    booktitle={Proceedings of the 14th International Workshop on Mining and Learning with Graphs (MLG)},<br/>
                    year={2018}<br/>
                    }
                    <hr/>
                    </div>

                    </p>

                    <p class="large text-muted">
                    <strong>What are they up to? Distilling the Twitter Stream of Subpopulations</strong> 
                    <button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#pid45">Abstract</button> 
                    <button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#bib45">BibTex</button> 
                    <a href="papers/MLG2018_paper_45.pdf" target=_blank class="btn btn-primary btn-xs" role="button">PDF</a> 
                    <br/>
                    <i>Ido Dangur, Ron Bekkerman and Einat Minkov</i><br/>

                    <div id="pid45" class="collapse">
                    <strong>Abstract:</strong> Social network researchers have been tackling community detection / community search for over a decade. Detecting communities -- small groups of people who know each other and interact with each other -- have numerous applications, starting from marketing and computational advertisement, all the way to the homeland security domain. By now, the problem can be considered mostly solved, in either its unsupervised form (community detection) or semi-supervised form (community search). In our quest to answer general -- and very exciting -- questions \emph{What are people up to? What do they care about? What are they discussing?}, we move beyond detecting communities to circumscribing subpopulations -- large groups of people who share some common characteristics, for example activists, students, engineers, New Yorkers, football fans etc. We want to know what are $<\dots>$ talking about on Twitter, where $<\dots>$ is any subpopulation. Initially, the subpopulation is characterized by a few representative members, who are treated as seeds in the iterative Personalized PageRank (PPR) framework that enlarges the subpopulation at each iteration. We immediately hit the scalability limitation, which we overcome by proposing the Splash PPR algorithm, inspired by Splash Belief Propagation. We implement Splash PPR on Apache Spark and show its efficiency and effectiveness on extracting the Twitter stream of a subpopulation of machine learning practitioners, by which we pave the road to distilling valuable signal out of the sea of Twitter noise.
                    <br/><br/><strong>Keywords:</strong> Twitter, Subpopulations, Personalized PageRank, Big Data
                    <hr/>
                    </div>

                    <div id="bib45" class="collapse">
                    @inproceedings{mlg2018_45,<br/>
                    title={What are they up to? Distilling the Twitter Stream of Subpopulations},<br/>
                    author={Ido Dangur, Ron Bekkerman and Einat Minkov},<br/>
                    booktitle={Proceedings of the 14th International Workshop on Mining and Learning with Graphs (MLG)},<br/>
                    year={2018}<br/>
                    }
                    <hr/>
                    </div>

                    </p>

                    <p class="large text-muted">
                    <strong>N-GCN: Multi-scale Graph Convolution for Semi-supervised Node Classification</strong> 
                    <button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#pid49">Abstract</button> 
                    <button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#bib49">BibTex</button> 
                    <a href="papers/MLG2018_paper_49.pdf" target=_blank class="btn btn-primary btn-xs" role="button">PDF</a> 
                    <br/>
                    <i>Sami Abu-El-Haija, Amol Kapoor, Bryan Perozzi and Joonseok Lee</i><br/>

                    <div id="pid49" class="collapse">
                    <strong>Abstract:</strong> Graph Convolutional Networks (GCNs) have shown significant improvements in semi-supervised learning on graph-structured data. Concurrently, unsupervised learning of graph embeddings has benefited from the information contained in random walks. In this paper, we propose a model: Network of GCNs (N-GCN), which marries these two lines of work. At its core, N-GCN trains multiple instances of GCNs over node pairs discovered at different distances in random walks, and learns a combination of the instance outputs which optimizes the classification objective. Our experiments show that our proposed N-GCN model improves state-of-the-art baselines on all of the challenging node classification tasks we consider: Cora, Citeseer, Pubmed, and PPI. In addition, our proposed method has other desirable properties, including generalization to recently proposed semi-supervised learning methods such as GraphSAGE, allowing us to propose N-SAGE, and resilience to adversarial input perturbations.
                    <br/><br/><strong>Keywords:</strong> Graph, Convolution, Spectral, Semi-Supervised Learning, Deep Learning
                    <hr/>
                    </div>

                    <div id="bib49" class="collapse">
                    @inproceedings{mlg2018_49,<br/>
                    title={N-GCN: Multi-scale Graph Convolution for Semi-supervised Node Classification},<br/>
                    author={Sami Abu-El-Haija, Amol Kapoor, Bryan Perozzi and Joonseok Lee},<br/>
                    booktitle={Proceedings of the 14th International Workshop on Mining and Learning with Graphs (MLG)},<br/>
                    year={2018}<br/>
                    }
                    <hr/>
                    </div>

                    </p>

                    <p class="large text-muted">
                    <strong>Error-Bounded Graph Construction for Semi-supervised Manifold Learning</strong> 
                    <button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#pid51">Abstract</button> 
                    <button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#bib51">BibTex</button> 
                    <a href="papers/MLG2018_paper_51.pdf" target=_blank class="btn btn-primary btn-xs" role="button">PDF</a> 
                    <br/>
                    <i>Christopher Symons</i><br/>

                    <div id="pid51" class="collapse">
                    <strong>Abstract:</strong> Graphs are commonly used in semi-supervised learning to represent a manifold on which the data reside in a high-dimensional ambient space. The graph can then be utilized in different ways, typically via the Laplacian of the graph, in order to leverage associations among the unlabeled data to improve learning. One common way to leverage the graph Laplacian is as a regularization term, where models that would disagree with the graph are penalized. More often the spectrum of the graph Laplacian is used to find a lower dimensional embedding in which neighboring relations encoded via the graph are preserved. Most manifold-based methods of semi-supervised learning depend upon geometric structure in the ambient feature space in order to construct a graph whose edges encode similarity that should be useful in selecting a model. A critical assumption is that some standard measure of similarity applied to the ambient space can be used to construct a graph that is error-free or of low error, meaning that examples (i.e., vertices) from distinct classes are not connected. However, this assumption often precludes the use of such methods in noisy or complex feature spaces, even though such spaces often arise in problems that can most benefit from structure that might be uncovered within the unlabeled data. This paper presents a method of graph construction for manifold-based semi-supervised learning that respects the manifold assumptions underlying these methods and bounds the error on the graph itself, which then permits bounds on the overall generalization error of the learning algorithms without relying on assumptions that do not hold in many modern problem domains.
                    <br/><br/><strong>Keywords:</strong> graph Laplacian, manifolds, semi-supervised learning, theoretical error bounds
                    <hr/>
                    </div>

                    <div id="bib51" class="collapse">
                    @inproceedings{mlg2018_51,<br/>
                    title={Error-Bounded Graph Construction for Semi-supervised Manifold Learning},<br/>
                    author={Christopher Symons},<br/>
                    booktitle={Proceedings of the 14th International Workshop on Mining and Learning with Graphs (MLG)},<br/>
                    year={2018}<br/>
                    }
                    <hr/>
                    </div>

                    </p>

                    <p class="large text-muted">
                    <strong>ROACH: Online Apprentice Critic Focused Crawling via CSS Cues and Reinforcement</strong> 
                    <button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#pid54">Abstract</button> 
                    <button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#bib54">BibTex</button> 
                    <a href="papers/MLG2018_paper_54.pdf" target=_blank class="btn btn-primary btn-xs" role="button">PDF</a> 
                    <br/>
                    <i>Asitang Mishra, Chris Mattmann, Paul Ramirez and Wayne Burke</i><br/>

                    <div id="pid54" class="collapse">
                    <strong>Abstract:</strong> The Internet today is replete with forum sites that - in the context of the deep/dark web - are used to sell illicit goods, and to deal in illegal activities including human trafficking (HT). Working on the DARPA MEMEX project, our team collaborated with law en- forcement to perform bulk analysis and crawl these sites and in doing so found a number of challenges. Forum sites contained pages with many links and little content and the ads - the rich source of content - were hidden behind link-dense hubs. To identify impor- tant links that led to ads, crawlers had to take advantage of CSS visual cues. As forum sites changed often, training a model offline would not be sufficient. We address these issues by creating ROACH, or Reinforcement-based, Online, Apprentice-Critic based focused crawling approacH. ROACH provides an online, adaptive crawling mechanism that employs static subject matter expert knowledge, with online learning based on a simplified version of reinforce- ment learning with back propagation. We use the widely popular apprentice-critic framework for performing this capability. ROACH is independent of any crawler implementation. The approach is scalable and accurate and overall provides better link relevancy scores than two baseline approaches including Apache Nutch. We evaluate ROACH on a dataset collected in the human trafficking domain from the DARPA MEMEX effort.
                    <br/><br/><strong>Keywords:</strong> Web Crawling, Graph-based Reinforcement Learning, Focused Crawling, Information Retrieval, Machine Learning
                    <hr/>
                    </div>

                    <div id="bib54" class="collapse">
                    @inproceedings{mlg2018_54,<br/>
                    title={ROACH: Online Apprentice Critic Focused Crawling via CSS Cues and Reinforcement},<br/>
                    author={Asitang Mishra, Chris Mattmann, Paul Ramirez and Wayne Burke},<br/>
                    booktitle={Proceedings of the 14th International Workshop on Mining and Learning with Graphs (MLG)},<br/>
                    year={2018}<br/>
                    }
                    <hr/>
                    </div>

                    </p>

                    <p class="large text-muted">
                    <strong>Social Relation Inference via Label Propagation</strong> 
                    <button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#pid58">Abstract</button> 
                    <button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#bib58">BibTex</button> 
                    <a href="papers/MLG2018_paper_58.pdf" target=_blank class="btn btn-primary btn-xs" role="button">PDF</a> 
                    <br/>
                    <i>Yingtao Tian, Haochen Chen, Bryan Perozzi, Muhao Chen, Xiaofei Sun and Steven Skiena</i><br/>

                    <div id="pid58" class="collapse">
                    <strong>Abstract:</strong> Collaboration networks are a ubiquitous way to characterize the
                    interactions between people. In this paper, we consider the problem
                    of inferring social relations in collaboration networks, such as the
                    fields that researchers collaborate in, or the categories of projects
                    that Github users work on together.

                    Social relation inference can be formalized as a multi-label classification
                    problem on graph edges, but many popular algorithms for
                    semi-supervised learning on graphs only operate on the nodes of a
                    graph. To bridge this gap, we propose a principled method which
                    leverages the natural homophily present in collaboration networks.
                    First, observing that the fields of collaboration for two people are
                    usually at the intersection of their interests, we transform an edge
                    labeling into node labels. Second, we use a label propagation algorithm
                    to propagate node labels in the entire graph. Once the label
                    distribution for all nodes has been obtained, we can easily infer the
                    label distribution for all edges. Experiments on three large-scale
                    collaboration networks demonstrate that our method outperforms
                    the state-of-the-art methods for social relation inference by a large
                    margin, in addition to running several orders of magnitude faster.
                    <br/><br/><strong>Keywords:</strong> label propagation, social relation inference, network representation learning, network embedding
                    <hr/>
                    </div>

                    <div id="bib58" class="collapse">
                    @inproceedings{mlg2018_58,<br/>
                    title={Social Relation Inference via Label Propagation},<br/>
                    author={Yingtao Tian, Haochen Chen, Bryan Perozzi, Muhao Chen, Xiaofei Sun and Steven Skiena},<br/>
                    booktitle={Proceedings of the 14th International Workshop on Mining and Learning with Graphs (MLG)},<br/>
                    year={2018}<br/>
                    }
                    <hr/>
                    </div>

                    </p>

                    <p class="large text-muted">
                    <strong>Fusion Graph Convolutional Networks</strong> 
                    <button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#pid63">Abstract</button> 
                    <button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#bib63">BibTex</button> 
                    <a href="papers/MLG2018_paper_63.pdf" target=_blank class="btn btn-primary btn-xs" role="button">PDF</a> 
                    <br/>
                    <i>Priyesh Vijayan, Yash Chandak, Mitesh M. Khapra and Balaraman Ravindran</i><br/>

                    <div id="pid63" class="collapse">
                    <strong>Abstract:</strong> State of the art methods for semi-supervised node classification in graphs uses differentiable functions to aggregate neighborhood information from multiple hops. Differentiable functions such as Graph Convolutional Networks (GCN) aggregate neighborhood information recursively over multiple hops and are learned end to end. These higher order propagation models primarily vary in their neighborhood aggregation functions as well as in their instantiation of weighted combinations of the node and its neighbors' information at each hop. However, these variants are limited in their ability to combine information from different hops efficiently. In this paper, we analyze this particular limitation with existing models that restrict them from performing well across datasets from different domains. Further, we provide a fusion component which is mathematically motivated to improve the existing models to learn the importance of information from different hops. This proposed mechanism is shown to improve over existing methods across 8 popular datasets from different domains. Specifically, our model improves the original Graph Convolutional Network (GCN) by a significant margin providing highly competitive state of the art results.
                    <br/><br/><strong>Keywords:</strong> Node classification, Semi-supervised learning, Social Networks, Collective classification, Data mining
                    <hr/>
                    </div>

                    <div id="bib63" class="collapse">
                    @inproceedings{mlg2018_63,<br/>
                    title={Fusion Graph Convolutional Networks},<br/>
                    author={Priyesh Vijayan, Yash Chandak, Mitesh M. Khapra and Balaraman Ravindran},<br/>
                    booktitle={Proceedings of the 14th International Workshop on Mining and Learning with Graphs (MLG)},<br/>
                    year={2018}<br/>
                    }
                    <hr/>
                    </div>

                    </p>

                    <p class="large text-muted">
                    <strong>Graphlets versus node2vec and struc2vec in the task of network alignment</strong> 
                    <button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#pid38">Abstract</button> 
                    <button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#bib38">BibTex</button> 
                    <a href="papers/MLG2018_paper_38.pdf" target=_blank class="btn btn-primary btn-xs" role="button">PDF</a> 
                    <br/>
                    <i>Shawn Gu and Tijana Milenkovic</i><br/>

                    <div id="pid38" class="collapse">
                    <strong>Abstract:</strong> Network embedding aims to represent each node in a network
                    as a low-dimensional feature vector that summarizes the given
                    node’s (extended) network neighborhood. The nodes’ feature vectors
                    can then be used in various downstream machine learning
                    tasks. Recently, many embedding methods that automatically learn
                    the features of nodes have emerged, such as node2vec and struc2vec,
                    which have been used in tasks such as node classification, link prediction,
                    and node clustering, mainly in the social network domain.
                    There are also other embedding methods that explicitly look at
                    the connections between nodes, i.e., the nodes’ network neighborhoods,
                    such as graphlets. Graphlets have been used in many tasks
                    such as network comparison, link prediction, and network clustering,
                    mainly in the computational biology domain. Even though
                    the two types of embedding methods (node2vec/struct2vec versus
                    graphlets) have a similar goal – to represent nodes as features
                    vectors, no comparisons have been made between them, possibly
                    because they have originated in the different domains. Therefore,
                    in this study, we compare graphlets to node2vec and struc2vec,
                    and we do so in the task of network alignment. In evaluations on
                    synthetic and real-world biological networks, we find that graphlets
                    are both more accurate and faster than node2vec and struc2vec.
                    This work falls under the following submission types: “Novel research
                    paper” and “Appraisal paper of existing methods and tools”.
                    <br/><br/><strong>Keywords:</strong> social networks, biological networks, network embedding, graphlets, network alignment
                    <hr/>
                    </div>

                    <div id="bib38" class="collapse">
                    @inproceedings{mlg2018_38,<br/>
                    title={Graphlets versus node2vec and struc2vec in the task of network alignment},<br/>
                    author={Shawn Gu and Tijana Milenkovic},<br/>
                    booktitle={Proceedings of the 14th International Workshop on Mining and Learning with Graphs (MLG)},<br/>
                    year={2018}<br/>
                    }
                    <hr/>
                    </div>

                    </p>

                    <p class="large text-muted">
                    <strong>SANE: Scalable Attribute-aware Network Embedding</strong> 
                    <button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#pid6">Abstract</button> 
                    <button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#bib6">BibTex</button> 
                    <a href="papers/MLG2018_paper_6.pdf" target=_blank class="btn btn-primary btn-xs" role="button">PDF</a> 
                    <br/>
                    <i>Weiyi Liu, Zhining Liu, Toyotaro Suzumura and Guangmin Hu</i><br/>

                    <div id="pid6" class="collapse">
                    <strong>Abstract:</strong> Network in the real world generally contains topological features and attribute features.
                    How to integrate features in the topological and attribute space simultaneously has gradually become one of the research focuses in network embedding.
                    In this position paper, we propose SANE: scalable attribute-aware network embedding. 
                    The present preliminary results show that, by enforcing the alignment of a local linear relationship between each node and its K-nearest neighbors in topology and attribute space, SANE is more informative comparing with a single representation from topology or attributes alone.
                    <br/><br/><strong>Keywords:</strong> feature learning, attributed graph, node embeddings, scalability
                    <hr/>
                    </div>

                    <div id="bib6" class="collapse">
                    @inproceedings{mlg2018_6,<br/>
                    title={SANE: Scalable Attribute-aware Network Embedding},<br/>
                    author={Weiyi Liu, Zhining Liu, Toyotaro Suzumura and Guangmin Hu},<br/>
                    booktitle={Proceedings of the 14th International Workshop on Mining and Learning with Graphs (MLG)},<br/>
                    year={2018}<br/>
                    }
                    <hr/>
                    </div>

                    </p>

                    <p class="large text-muted">
                    <strong>Temporal graph-based clustering for historical record linkage</strong> 
                    <button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#pid14">Abstract</button> 
                    <button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#bib14">BibTex</button> 
                    <a href="papers/MLG2018_paper_14.pdf" target=_blank class="btn btn-primary btn-xs" role="button">PDF</a> 
                    <br/>
                    <i>Charini Nanayakkara, Peter Christen and Thilina Ranbaduge</i><br/>

                    <div id="pid14" class="collapse">
                    <strong>Abstract:</strong> Research in the social sciences is increasingly based on large and complex data collections, where individual data sets from different domains are linked and integrated to allow advanced analytics. A popular type of data used in such a context are historical censuses, as well as birth, death, and marriage certificates. Individually, such data sets however limit the types of studies that can be conducted. Specifically, it is impossible to track individuals, families, or households over time. Once such data sets are linked and family trees spanning several decades are available, it is possible to, for example, investigate how education, health, mobility, employment and social status influence each other and the life of people over two or even more generations. A major challenge is however the accurate linkage of historical data sets which is due to data quality and commonly also the lack of ground truth data being available. Unsupervised techniques need to be employed, which can be based on similarity graphs generated by comparing individual records. In this paper we present initial results from clustering birth records from Scotland where we aim to identify all births of the same mother and group siblings into clusters. We extend existing clustering techniques for record linkage by incorporating temporal constraints that must hold between births of the same mother, and explore novel temporal clustering ideas. Experimental results show improvements over non-temporary approaches, however further work is needed to obtain links of high quality.
                    <br/><br/><strong>Keywords:</strong> Entity resolution, Birth records, Scottish, Star clustering
                    <hr/>
                    </div>

                    <div id="bib14" class="collapse">
                    @inproceedings{mlg2018_14,<br/>
                    title={Temporal graph-based clustering for historical record linkage},<br/>
                    author={Charini Nanayakkara, Peter Christen and Thilina Ranbaduge},<br/>
                    booktitle={Proceedings of the 14th International Workshop on Mining and Learning with Graphs (MLG)},<br/>
                    year={2018}<br/>
                    }
                    <hr/>
                    </div>

                    </p>

                    <p class="large text-muted">
                    <strong>HGsuspector: Scalable Collective Fraud Detection in Heterogeneous Graphs</strong> 
                    <button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#pid16">Abstract</button> 
                    <button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#bib16">BibTex</button> 
                    <a href="papers/MLG2018_paper_16.pdf" target=_blank class="btn btn-primary btn-xs" role="button">PDF</a> 
                    <br/>
                    <i>Xiang Li, Wen Zhang, Jiuzhou Xi and Hao Zhu</i><br/>

                    <div id="pid16" class="collapse">
                    <strong>Abstract:</strong> Heterogeneous graphs have drawn more and more attention in both research and engineering, such as Amazon's who-buys-what graph, Facebook's who-likes-page graph, opinion graphs and etc. Present work of fraud detection on heterogeneous graphs is either on bipartite graphs or heterogeneous graphs with a handful of node and edge types. For a common heterogeneous graph, it is not easy to detect suspicious subgraphs directly, while fraud detection of bipartite graphs with metric is accurate and fast. What if handle heterogeneous graphs by utilizing the advantages of bipartite graphs?

                    Here we propose HGsuspector, a novel, simple and scalable algorithm for detecting collective fraud in directed heterogeneous graphs. At first, we decompose directed heterogeneous graphs into a set of bipartite graphs, then for each bipartite graphs we define a metric on each connected bipartite graph and calculate scores on it. Finally, we obtain corresponding suspicious subgraphs with anomaly detection algorithms.

                    We demonstrate the effectiveness and competitive performance of HGsuspector in experiments on real-world datasets, which indicates that HGsuspector could detect the suspicious subgraphs both accurately and fast on large graphs with billion nodes and edges, and it outperforms other state-of-the-art algorithms.
                    <br/><br/><strong>Keywords:</strong> Bipartite Graph, Heterogeneous Graph, Connected Bipartite Subgraph, Edge Density Function
                    <hr/>
                    </div>

                    <div id="bib16" class="collapse">
                    @inproceedings{mlg2018_16,<br/>
                    title={HGsuspector: Scalable Collective Fraud Detection in Heterogeneous Graphs},<br/>
                    author={Xiang Li, Wen Zhang, Jiuzhou Xi and Hao Zhu},<br/>
                    booktitle={Proceedings of the 14th International Workshop on Mining and Learning with Graphs (MLG)},<br/>
                    year={2018}<br/>
                    }
                    <hr/>
                    </div>

                    </p>

                    <p class="large text-muted">
                    <strong>A New Algorithmic Model for Graph Analysis of Streaming Data</strong> 
                    <button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#pid23">Abstract</button> 
                    <button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#bib23">BibTex</button> 
                    <a href="papers/MLG2018_paper_23.pdf" target=_blank class="btn btn-primary btn-xs" role="button">PDF</a> 
                    <br/>
                    <i>Chunxing Yin, Jason Riedy, and David A. Bader</i><br/>

                    <div id="pid23" class="collapse">
                    <strong>Abstract:</strong> The constant and massive influx of new data into analysis systems needs to be addressed without assuming we can pause the onslaught.  Here we consider one aspect: non-stop graph analysis of streaming data.  We formalize a new and practical algorithm model that includes both single-run analysis as well as efficiently updating analysis results only around changed data.  In our model, a massive graph undergoes changes from an input stream of edge insertions and removals.  These changes occur concurrently with analysis.  Algorithms do not pause or stop the input stream.  Assuming basic data access safety, we consider an algorithm valid for our model if the output is correct for a graph consisting of the initial graph and some implicit subset of concurrent changes.

                    Our technical contributions include 1) the first formal model for graph analysis with concurrent changes, 2) properties of the model including how our model is the strongest possible without point-in-time graph views, 3) demonstrations of our model on connected components and PageRank, and 4) an extension to updating computed results incrementally.

                    <br/><br/><strong>Keywords:</strong> graph analysis, streaming data, high-performance data analysis
                    <hr/>
                    </div>

                    <div id="bib23" class="collapse">
                    @inproceedings{mlg2018_23,<br/>
                    title={A New Algorithmic Model for Graph Analysis of Streaming Data},<br/>
                    author={Chunxing Yin, Jason Riedy, and David A. Bader},<br/>
                    booktitle={Proceedings of the 14th International Workshop on Mining and Learning with Graphs (MLG)},<br/>
                    year={2018}<br/>
                    }
                    <hr/>
                    </div>

                    </p>

                    <p class="large text-muted">
                    <strong>Temporal Analysis of Reddit Networks via Role Embeddings</strong> 
                    <button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#pid43">Abstract</button> 
                    <button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#bib43">BibTex</button> 
                    <a href="papers/MLG2018_paper_43.pdf" target=_blank class="btn btn-primary btn-xs" role="button">PDF</a> 
                    <br/>
                    <i>Siobhán Grayson and Derek Greene</i><br/>

                    <div id="pid43" class="collapse">
                    <strong>Abstract:</strong> Inspired by diachronic word analysis from the field of natural language processing, we propose an approach for uncovering temporal insights regarding user roles from social networks using graph embedding methods. Specifically, we apply the role embedding algorithm, struc2vec, to a collection of social networks exhibiting either "loyal" or "vagrant" characteristics, derived from the popular online social news aggregation website Reddit. For each subreddit, we extract nine months of data and create network role embeddings on consecutive time windows. We are then able to compare and contrast how user roles change over time by aligning the resulting temporal embeddings spaces. In particular, this is a 'work-in-progress paper' where we analyze temporal role embeddings, from both an individual and community-level perspective, for both loyal and vagrant user communities present on Reddit.
                    <br/><br/><strong>Keywords:</strong> temporal role analysis, graph embeddings, social network analysis
                    <hr/>
                    </div>

                    <div id="bib43" class="collapse">
                    @inproceedings{mlg2018_43,<br/>
                    title={Temporal Analysis of Reddit Networks via Role Embeddings},<br/>
                    author={Siobhán Grayson and Derek Greene},<br/>
                    booktitle={Proceedings of the 14th International Workshop on Mining and Learning with Graphs (MLG)},<br/>
                    year={2018}<br/>
                    }
                    <hr/>
                    </div>

                    </p>

                    <p class="large text-muted">
                    <strong>Temporal Motifs in Heterogeneous Information Networks</strong> 
                    <button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#pid46">Abstract</button> 
                    <button class="btn btn-primary btn-xs" data-toggle="collapse" data-target="#bib46">BibTex</button> 
                    <a href="papers/MLG2018_paper_46.pdf" target=_blank class="btn btn-primary btn-xs" role="button">PDF</a> 
                    <br/>
                    <i>Yuchen Li, Zhengzhi Lou, Yu Shi and Jiawei Han</i><br/>

                    <div id="pid46" class="collapse">
                    <strong>Abstract:</strong> Network motifs are crucial building blocks of understanding and modeling complex networks for its capacity in characterizing higher-order interactions. Meanwhile, heterogeneous information networks (HINs) are ubiquitous in real-world applications, which often come with rich temporal information. We are hence motivated to study temporal motifs in the context of heterogeneous information networks. With examples from real-world datasets, we demonstrate HIN motifs can be armed with substantially more discriminability by incorporating temporal information. Furthermore, counting temporal HIN motif instances in large-scale networks is time consuming. We therefore develop efficient counting algorithm for the HIN motifs that are of the most interests in the literature. Empirical observations in the experiment showed that interesting motif instances can be identified from large-scale HINs thanks to the improved discriminability of temporal HIN motifs, and the proposed efficient counting algorithm enjoys linear complexity that is multiple orders of magnitude faster than the baseline method in four real-world HINs.
                    <br/><br/><strong>Keywords:</strong> heterogeneous information networks, network motifs, algorithms, graph mining
                    <hr/>
                    </div>

                    <div id="bib46" class="collapse">
                    @inproceedings{mlg2018_46,<br/>
                    title={Temporal Motifs in Heterogeneous Information Networks},<br/>
                    author={Yuchen Li, Zhengzhi Lou, Yu Shi and Jiawei Han},<br/>
                    booktitle={Proceedings of the 14th International Workshop on Mining and Learning with Graphs (MLG)},<br/>
                    year={2018}<br/>
                    }
                    <hr/>
                    </div>

                    </p>


                    ​


                  <!-- End Paper List -->
            </div>
          </div>
        </div>
    </section>

    <!-- Call for Papers Section -->
    <section id="call"> <!--class="bg-mid-gray"-->
        <div class="container">
            <div class="row">
                <div class="col-lg-12 text-center">
                    <h2 class="section-heading">Call for Papers</h2>
                    <!--h3 class="section-subheading text-muted">Lorem ipsum dolor sit amet consectetur.</h3-->
                </div>
            </div>
            <div class="row text-justify">
                <div class="col-md-12">
                    <p class="large text-muted">
                      This workshop is a forum for exchanging ideas and methods for mining and learning with graphs, developing new common understandings of the problems at hand, sharing of data sets where applicable, and leveraging existing knowledge from different disciplines. The goal is to bring together researchers from academia, industry, and government, to create a forum for discussing recent advances graph analysis. In doing so, we aim to better understand the overarching principles and the limitations of our current methods and to inspire research on new algorithms and techniques for mining and learning with graphs.
                    </p>
                    <p class="large text-muted">
                      To reflect the broad scope of work on mining and learning with graphs, we encourage submissions that span the spectrum from theoretical analysis to algorithms and implementation, to applications and empirical studies. As an example, the growth of user-generated content on blogs, microblogs, discussion forums, product reviews, etc., has given rise to a host of new opportunities for graph mining in the analysis of social media. We encourage submissions on theory, methods, and applications focusing on a broad range of graph-based approaches in various domains.
                    </p>
                    <p class="large text-muted">
                      Topics of interest include, but are not limited to:
                    </p>

                    <ul class="large text-muted">
                      <li><b>Theoretical aspects:</b>
                        <ul class="large text-muted">
                          <li>Computational or statistical learning theory related to graphs</li>
                          <li>Theoretical analysis of graph algorithms or models</li>
                          <li>Sampling and evaluation issues in graph algorithms</li>
                          <li>Analysis of dynamic graphs</li>
                        </ul>
                      </li>
                      <li><b>Algorithms and methods:</b>
                        <ul class="large text-muted">
                          <li>Graph mining</li>
                          <li>Probabilistic and graphical models for structured data</li>
                          <li>Heterogeneous/multi-model graph analysis</li>
                          <li>Network embedding models</li>
                          <li>Statistical models of graph structure</li>
                          <li>Combinatorial graph methods</li>
                          <li>Semi-supervised learning, active learning, transductive inference, and transfer learning in the context of graph</li>
                        </ul>
                      </li>
                      <li><b>Applications and analysis:</b>
                      <ul class="large text-muted">
                        <li>Analysis of social media</li>
                        <li>Analysis of biological networks</li>
                        <li>Knowledge graph construction</li>
                        <li>Large-scale analysis and modeling</li>
                      </ul>
                      </li>
                    </ul>

                   <p class="large text-muted">
                    We welcome many kinds of papers, such as, but not limited to:
                  </p>

                    <ul class="large text-muted">
                      <li>Novel research papers
                      </li><li>Demo papers
                      </li><li>Work-in-progress papers
                      </li><li>Visionary papers (white papers)
                      </li><li>Appraisal papers of existing methods and tools (e.g., lessons learned)
                      </li><li>Relevant work that has been previously published
                      </li><li>Work that will be presented at the main conference
                      </li>
                    </ul>

                    <p class="large text-muted">
                    Authors should <strong>clearly indicate</strong> in their abstracts the kinds of submissions that the papers belong to, to help reviewers better understand their contributions. <br/>
                    All papers will be peer reviewed, single-blinded. 
                    Submissions must be in PDF, <strong>no more than 8 pages long</strong> — shorter papers are welcome — and formatted according to the standard double-column <a href="http://www.acm.org/publications/proceedings-template#aL2" target=_blank>ACM Proceedings Style</a>. <br/>
                    The accepted papers will be published on the workshop’s website and will not be considered archival for resubmission purposes. <br/>
                    Authors whose papers are accepted to the workshop will have the opportunity to participate in a spotlight and poster session, and some set will also be chosen for oral presentation, <u><strong>and considered for $1,000 best paper award sponsored by Google and Kyndi</strong></u>.

                    </p>

                    <p class="large text-muted">
                      <strong>For paper submission, please proceed to the <a href="https://easychair.org/conferences/?conf=mlg2018" target=_blank>submission website</a>.</strong>
                    </p>

                    <p class="large text-muted">
                      <strong>Please send enquiries to chair@mlgworkshop.org.</strong>
                    </p>

                    <p class="large text-muted">                    
                      To receive updates about the current and future workshops and the Graph Mining community, please join the <a href="https://groups.google.com/d/forum/mlg-list" target=_blank>Mailing List</a>, or follow the <a href="https://twitter.com/mlgworkshop" target=_blank>Twitter Account</a>.
                    </p>
                </div>
            </div>
        </div>
    </section>

    <!-- Dates Section -->
    <section id="dates" class="bg-mid-gray">
        <div class="container">
            <div class="row">
                <div class="col-lg-12 text-center">
                    <h2 class="section-heading">Important Dates</h2>
                    <!--h3 class="section-subheading text-muted">Lorem ipsum dolor sit amet consectetur.</h3-->
                </div>
            </div>
            <div class="row">
              <div class="col-lg-4 text-left">
                &nbsp;
              </div>
            <div class="col-lg-6 text-left">
                <div class="col-md-12">
                      <p class="large text-muted">
                      <b>Paper Submission Open:</b> <strike>April 1, 2018</strike>
                    </p><p class="large text-muted">
                      <b>Paper Abstract Deadline:</b> <strike>May 8, 2018</strike>
                    </p><p class="large text-muted">
                      <b>Paper Submission Deadline:</b> <strike>May 15, 2018</strike>
                    </p><p class="large text-muted">
                      <b>Author Notification:</b> <strike>June 8, 2018</strike>
                    </p><p class="large text-muted">
                      <b>Camera Ready:</b> <strike>June 28, 2018</strike>
                    </p><p class="large text-muted">
                      <b>Workshop:</b> August 20, 2018
                      </p>
                </div>
            </div>
          </div>
        </div>
    </section>

  <!-- Organization Section -->
    <section id="organization"> <!--class="bg-mid-gray"-->
        <div class="container">
            <div class="row">
                <div class="col-lg-12 text-center">
                    <h2 class="section-heading">Workshop Organizers</h2>
                    <!--h3 class="section-subheading text-muted">Lorem ipsum dolor sit amet consectetur.</h3-->
                </div>
            </div>
            <div class="row">


                <div class="col-md-1">
                  &nbsp;                  
                </div>   

                <div class="col-sm-2">
                    <div class="team-member">
                        <img src="img/team/2_shobeir.jpg" class="img-responsive img-circle" alt="Shobeir Fakhraei">
                        <h4>Shobeir Fakhraei</h4>
                        <p class="text-muted">Research Scientist<br/>University of Southern California (ISI)</p>
                        <ul class="list-inline social-buttons-team">
                            <li><a href="http://www.cs.umd.edu/~shobeir/" target="_blank"><i class="fa fa-home"></i></a>
                            </li>
                            <li><a href="https://twitter.com/shobeirf" target=_blank><i class="fa fa-twitter"></i></a>
                            </li>
                            <li><a href="http://www.linkedin.com/in/shobeir" target=_blank><i class="fa fa-linkedin"></i></a>
                            </li>
                            <li><a target=_blank href="https://scholar.google.com/citations?user=6vJwj_QAAAAJ"><i class="fa fa-graduation-cap"></i></a>
                            </li>
                        </ul>
                    </div>
                </div>
                <div class="col-sm-2">
                    <div class="team-member">
                        <img src="img/team/3_danai.jpg" class="img-responsive img-circle" alt="Danai Koutra">
                        <h4>Danai Koutra</h4>
                        <p class="text-muted">Assistant Professor<br/>University of Michigan Ann Arbor</p>
                        <ul class="list-inline social-buttons-team">
                          <li><a href="http://web.eecs.umich.edu/~dkoutra/" target="_blank"><i class="fa fa-home"></i></a>
                          </li>
                          <li><a href="https://twitter.com/danaikoutra" target=_blank><i class="fa fa-twitter"></i></a>
                          </li>
                          <li><a href="https://www.linkedin.com/in/danai" target=_blank><i class="fa fa-linkedin"></i></a>
                          </li>
                          <li><a target=_blank href="https://scholar.google.com/citations?user=bDrA1-8AAAAJ"><i class="fa fa-graduation-cap"></i></a>
                          </li>
                        </ul>
                    </div>
                </div>
                <div class="col-sm-2">
                    <div class="team-member">
                        <img src="img/team/5_julian.jpg" class="img-responsive img-circle" alt="Julian McAuley">
                        <h4>Julian McAuley</h4>
                        <p class="text-muted">Assistant Professor<br/>University of California San Diego</p>
                        <ul class="list-inline social-buttons-team">
                          <li><a href="http://cseweb.ucsd.edu/~jmcauley/" target="_blank"><i class="fa fa-home"></i></a>
                          </li>
                          <li><a class="inactive" href="#organization"><i class="fa fa-twitter"></i></a>
                          </li>
                          <li><a href="https://www.linkedin.com/in/julianmcauley" target=_blank><i class="fa fa-linkedin"></i></a>
                          </li>
                          <li><a target=_blank href="https://scholar.google.com/citations?user=icbo4M0AAAAJ"><i class="fa fa-graduation-cap"></i></a>
                          </li>
                        </ul>
                    </div>
                </div>                
                <div class="col-sm-2">
                    <div class="team-member">
                        <img src="img/team/bryan.jpg" class="img-responsive img-circle" alt="Bryan Perozzi">
                        <h4>Bryan Perozzi</h4>
                        <p class="text-muted">Research Scientist<br/>Google Research<br/>&nbsp;</p>
                        <ul class="list-inline social-buttons-team">
                          <li><a href="http://www.perozzi.net/" target="_blank"><i class="fa fa-home"></i></a>
                          </li>
                          <li><a href="https://twitter.com/phanein" target=_blank><i class="fa fa-twitter"></i></a>
                          </li>
                          <li><a href="https://www.linkedin.com/in/bryanperozzi/" target=_blank><i class="fa fa-linkedin"></i></a>
                          </li>
                          <li><a target=_blank href="https://scholar.google.com/citations?user=rZgbMs4AAAAJ&hl=en&oi=ao"><i class="fa fa-graduation-cap"></i></a>
                          </li>
                        </ul>
                    </div>
                </div>
                <div class="col-sm-2">
                    <div class="team-member">
                        <img src="img/team/tim.jpg" class="img-responsive img-circle" alt="Tim Weninger">
                        <h4>Tim Weninger</h4>
                        <p class="text-muted">Assistant Professor<br/>University of Notre Dame</p>
                        <ul class="list-inline social-buttons-team">
                          <li><a target=_blank href="https://www3.nd.edu/~tweninge/"><i class="fa fa-home"></i></a>
                          </li>
                          <li><a target=_blank href="https://twitter.com/tim_weninger"><i class="fa fa-twitter"></i></a>
                          </li>
                          <li><a target=_blank href="https://www.linkedin.com/in/tim-weninger-b462277b/"><i class="fa fa-linkedin"></i></a>
                          </li>
                          <li><a target=_blank href="https://scholar.google.com/citations?user=V1js0MUAAAAJ&hl=en"><i class="fa fa-graduation-cap"></i></a>
                          </li>
                        </ul>
                    </div>

                <div class="col-md-1">
                  &nbsp;                  
                </div>   


                </div>
            </div>
            <div class="row" style="margin-top:60px;">
                <div class="col-lg-12 text-center">
                    <h2 class="section-heading">Program Committee</h2>
                    <!--h3 class="section-subheading text-muted">More will be announced soon!</h3-->
                    <div class="col-md-1">
                       &nbsp;
                    </div>
                    <div class="col-md-5 text-left">
                      <p class="large text-muted">
                        Aris Anagnostopoulos (Sapienza University of Rome)<BR/>
                        Ana Paula Appel (I.B.M.)<BR/>
                        Miguel Araujo (Feedzai)<BR/>
                        Arindam Banerjee (University of Minnesota)<BR/>
                        Christian Bauckhage (Fraunhofer IAIS)<BR/>
                        Ulf Brefeld (Leuphana Universität Lüneburg)<BR/>
                        Ivan Brugere (University of Illinois at Chicago)<BR/>
                        Aaron Clauset (University of Colorado at Boulder)<BR/>
                        Alessandro Epasto (Google)<BR/>
                        Emilio Ferrara (University of Southern California)<BR/>
                        Thomas Gärtner (University of Nottingham)<BR/>
                        David Gleich (Purdue University)<BR/>
                        Mohammad Hasan (Indiana U.–Purdue U. Indianapolis)<BR/>
                        Jake Hofman (Microsoft Research)<BR/>
                        Larry Holder (Washington State University)<BR/>
                        Bert Huang (Virginia Tech)<BR/>
                        Kristian Kersting (TU Darmstadt)<BR/>
                        Stefano Leucci (ETH Zurich)<BR/>                                                
                      </p>
                    </div>
                    <div class="col-md-5 text-left">
                      <p class="large text-muted">
                        Fred Morstatter (University of Southern California)<BR/>                                                
                        Vagelis Papalexakis (University of California Riverside)<BR/>
                        Ali Pinar (Sandia National Laboratories)<BR/>
                        Aditya Prakash (Virginia Tech)<BR/>
                        Arti Ramesh (Binghamton University)<BR/>
                        Jan Ramon (INRIA)<BR/>
                        Xiang Ren (University of Southern California)<BR/>
                        Neil Shah (Snap Inc.)<BR/>
                        Sucheta Soundarajan (Syracuse University)<BR/>
                        Yizhou Sun (University of California, Los Angeles)<BR/>
                        Acar Tamersoy (Symantec Research Labs)<BR/>
                        Jiliang Tang (Michigan State University)<BR/>
                        Hanghang Tong (Arizona State University)<BR/>
                        Stefan Wrobel (Fraunhofer IAIS)<BR/>
                        Xin-Zeng Wu (Information Sciences Institute)<BR/>
                        Zhongfei Zhang (Binghamton University)<BR/>
                        Elena Zheleva (University of Illinois at Chicago)<BR/>                        
                      </p>
                      </div>
                      <div class="col-md-1">
                         &nbsp;
                      </div>
                </div>
            </div>
        </div>
    </section>

    <!-- History Section -->
    <section id="history" class="bg-mid-gray">
        <div class="container">
            <div class="row">
                <div class="col-lg-12 text-center">
                    <h2 class="section-heading">Previous Workshops</h2>
                    <!--h3 class="section-subheading text-muted">Lorem ipsum dolor sit amet consectetur.</h3-->
                </div>
            </div>
            <div class="row">
                <div class="col-lg-4 text-left">
                  &nbsp;
                </div>

                <div class="col-lg-6 text-left">
                      <p class="large text-muted">
                        <a href="http://www.mlgworkshop.org/2017/" target=_blank  class="large text-muted">2017, Halifax, Nova Scotia, Canada (co-located with KDD)</a></br>
                        <a href="http://www.mlgworkshop.org/2016/" target=_blank  class="large text-muted">2016, San Francisco, USA (co-located with KDD)</a></br>
                        <a href="http://snap.stanford.edu/mlg2013/" target=_blank  class="large text-muted">2013, Chicago, USA (co-located with KDD)</a></br>
                        <a href="http://dtai.cs.kuleuven.be/events/mlg2012/" target=_blank  class="large text-muted">2012, Edinburgh, Scotland (co-located with ICML)</a></br>
                        <a href="http://www.cs.purdue.edu/mlg2011/" target=_blank  class="large text-muted">2011, San Diego, USA (co-located with KDD)</a></br>
                        <a href="http://www.cs.umd.edu/mlg2010/" target=_blank  class="large text-muted">2010, Washington, USA (co-located with KDD)</a></br>
                        <a href="http://dtai.cs.kuleuven.be/ilp-mlg-srl//" target=_blank  class="large text-muted">2009, Leuven, Belgium (co-located with SRL and ILP)</a></br>
                        <a href="http://research.ics.aalto.fi/events/MLG08/" target=_blank  class="large text-muted">2008, Helsinki, Finland (co-located with ICML)</a></br>
                        <a href="http://mlg07.dsi.unifi.it/" target=_blank  class="large text-muted">2007, Firenze, Italy</a></br>
                        <a href="http://www.inf.uni-konstanz.de/mlg2006/index.shtml" target=_blank  class="large text-muted">2006, Berlin, German (co-located with ECML and PKDD)</a></br>
                        <a href="#" class="large text-muted">2005, Porto, Portugal, October 7, 2005</a></br>
                        <a href="http://hms.liacs.nl/mgts2004/" target=_blank  class="large text-muted">2004, Pisa, Italy, September 24, 2004</a></br>
                        <a href="http://www.ar.sanken.osaka-u.ac.jp/MGTS-2003CFP.html" target=_blank  class="large text-muted">2003, Cavtat-Dubrovnik, Croatia</a></br>
                      </p>
                </div>
            </div>
        </div>
    </section>

    <!-- Sponsors Section -->
    <section id="Sponsors" class="bg-mid">
        <div class="container">
            <div class="row">
                <div class="col-lg-12 text-center">
                    <h2 class="section-heading">Sponsors</h2>
                    <!--h3 class="section-subheading text-muted">Lorem ipsum dolor sit amet consectetur.</h3-->
                </div>
            </div>
            <div class="row">
                <div class="col-lg-12 text-left">
                  &nbsp;<br/><br/>
                </div>
            </div>                
            <div class="row">
                <div class="col-lg-2 text-left">
                  &nbsp;
                </div>

                <div class="col-lg-4 text-left">
                    <img src="img/sponsors/Google_logo.jpg" alt="Google" width='250px'>
                </div>

                <div class="col-lg-4 text-right">
                    <img src="img/sponsors/Kyndi_logo.jpg" alt="Kyndi" width='300px'>
                </div>

                <div class="col-lg-2 text-left">
                    &nbsp;
                </div>
            </div>
        </div>
    </section>

    <!-- Footer -->
    <footer  class="bg-darkest-gray">
        <div class="container">
            <div class="row">
                <div class="col-md-4">
                    <span class="copyright" style="color:gray;">Copyright &copy; MLG Workshop 2018</span>
                </div>
                <div class="col-md-4">
                    <ul class="list-inline social-buttons">
                        <li><a href="https://twitter.com/mlgworkshop" target=_blank><i class="fa fa-twitter"></i></a>
                        </li>
                        <!--li><a href="#"><i class="fa fa-facebook"></i></a>
                        </li>
                        <li><a href="#"><i class="fa fa-linkedin"></i></a>
                        </li-->
                    </ul>
                </div>
                <!--div class="col-md-4">
                    <ul class="list-inline quicklinks">
                        <li><a href="#">Privacy Policy</a>
                        </li>
                        <li><a href="#">Terms of Use</a>
                        </li>
                    </ul>
                </div-->
            </div>
        </div>
    </footer>

    <!-- jQuery -->
    <script src="js/jquery.js"></script>

    <!-- Bootstrap Core JavaScript -->
    <script src="js/bootstrap.min.js"></script>

    <!-- Plugin JavaScript -->
    <script src="http://cdnjs.cloudflare.com/ajax/libs/jquery-easing/1.3/jquery.easing.min.js"></script>
    <script src="js/classie.js"></script>
    <script src="js/cbpAnimatedHeader.js"></script>

    <!-- Contact Form JavaScript -->
    <script src="js/jqBootstrapValidation.js"></script>
    <script src="js/contact_me.js"></script>

    <!-- Custom Theme JavaScript -->
    <script src="js/agency.js"></script>

</body>

</html>
